{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import pygame\n",
    "\n",
    "class RCMazeEnv(gym.Env):\n",
    "    def __init__(self, maze_size_x=10, maze_size_y=10):\n",
    "        self.maze_size_x = maze_size_x\n",
    "        self.maze_size_y = maze_size_y\n",
    "        self.maze = self.generate_maze()\n",
    "        self.car_position = (0, 0)\n",
    "        self.possible_actions = range(3)\n",
    "        self.car_orientation = 'N'\n",
    "        self.sensor_readings = {'front': 0, 'left': 0, 'right': 0}\n",
    "        self.steps = 0\n",
    "        self.previous_distance = 0\n",
    "        self.reset()\n",
    "\n",
    "    def generate_maze(self):\n",
    "        # For simplicity, create a static maze with walls\n",
    "        # '1' represents a wall, and '0' represents an open path\n",
    "        maze = np.zeros((self.maze_size_y, self.maze_size_x), dtype=int)\n",
    "        # Add walls to the maze (this can be customized)\n",
    "        maze[1::2, :] = 1\n",
    "        maze[:, 1::2] = 0\n",
    "        # Add goal\n",
    "        maze[-1, -1] = 0\n",
    "        \n",
    "        return maze\n",
    "\n",
    "    def reset(self):\n",
    "        self.car_position = (0, 0)\n",
    "        self.car_orientation = 'N'\n",
    "        self.update_sensor_readings()\n",
    "        self.steps = 0\n",
    "        self.previous_distance = 0\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.move_forward()\n",
    "        elif action == 1:\n",
    "            self.turn_left()\n",
    "        elif action == 2:\n",
    "            self.turn_right()\n",
    "        self.update_sensor_readings()\n",
    "        reward = self.compute_reward()\n",
    "        self.steps += 1\n",
    "        done = self.is_done()\n",
    "        return self.get_state(), reward, done\n",
    "\n",
    "    # def move_forward(self):\n",
    "    #     x, y = self.car_position\n",
    "    #     if self.car_orientation == 'N':\n",
    "    #         self.car_position = (x, max(y - 1, 0))\n",
    "    #     elif self.car_orientation == 'S':\n",
    "    #         self.car_position = (x, min(y + 1, self.maze_size_y - 1))\n",
    "    #     elif self.car_orientation == 'E':\n",
    "    #         self.car_position = (min(x + 1, self.maze_size_x - 1), y)\n",
    "    #     elif self.car_orientation == 'W':\n",
    "    #         self.car_position = (max(x - 1, 0), y)\n",
    "    \n",
    "    def move_forward(self):\n",
    "        x, y = self.car_position\n",
    "        if self.car_orientation == 'N' and y > 0 and self.maze[y - 1][x] != 1:\n",
    "            self.car_position = (x, y - 1)\n",
    "        elif self.car_orientation == 'S' and y < self.maze_size_y - 1 and self.maze[y + 1][x] != 1:\n",
    "            self.car_position = (x, y + 1)\n",
    "        elif self.car_orientation == 'E' and x < self.maze_size_x - 1 and self.maze[y][x + 1] != 1:\n",
    "            self.car_position = (x + 1, y)\n",
    "        elif self.car_orientation == 'W' and x > 0 and self.maze[y][x - 1] != 1:\n",
    "            self.car_position = (x - 1, y)\n",
    "        \n",
    "\n",
    "    def turn_left(self):\n",
    "        orientations = ['N', 'W', 'S', 'E']\n",
    "        idx = orientations.index(self.car_orientation)\n",
    "        self.car_orientation = orientations[(idx + 1) % 4]\n",
    "\n",
    "    def turn_right(self):\n",
    "        orientations = ['N', 'E', 'S', 'W']\n",
    "        idx = orientations.index(self.car_orientation)\n",
    "        self.car_orientation = orientations[(idx + 1) % 4]\n",
    "\n",
    "    def update_sensor_readings(self):\n",
    "        # Simple sensor implementation: counts steps to the nearest wall\n",
    "        self.sensor_readings['front'] = self.distance_to_wall('front')\n",
    "        self.sensor_readings['left'] = self.distance_to_wall('left')\n",
    "        self.sensor_readings['right'] = self.distance_to_wall('right')\n",
    "\n",
    "    def distance_to_wall(self, direction):\n",
    "        x, y = self.car_position\n",
    "        distance = 0\n",
    "        if direction == 'front':\n",
    "            if self.car_orientation == 'N':\n",
    "                while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                    distance += 1\n",
    "            # Similar logic for other orientations...\n",
    "        # Implement for left and right...\n",
    "        return distance\n",
    "\n",
    "    def compute_reward(self):\n",
    "        reward = 0\n",
    "\n",
    "        # Penalty for hitting walls or going out of bounds\n",
    "        if self.sensor_readings['front'] == 0 or self.sensor_readings['left'] == 0 or self.sensor_readings['right'] == 0:\n",
    "            reward -= 5\n",
    "\n",
    "        # Reward for reaching the goal\n",
    "        if self.car_position == (self.maze_size_x - 1, self.maze_size_y - 1):\n",
    "            reward += 100\n",
    "            return reward  # Return immediately as this is the terminal state\n",
    "\n",
    "        # Calculate reward based on reduced distance to goal\n",
    "        x, y = self.car_position\n",
    "        goal_x, goal_y = (self.maze_size_x - 1, self.maze_size_y - 1)\n",
    "        distance = abs(x - goal_x) + abs(y - goal_y)\n",
    "        \n",
    "\n",
    "        # Assuming previous_distance is stored after each move\n",
    "        if distance < self.previous_distance:\n",
    "            reward += 10  # Positive reward for moving closer to the goal\n",
    "        elif distance > self.previous_distance:\n",
    "            reward -= 5   # Negative reward for moving farther from the goal\n",
    "\n",
    "        # Update previous_distance for the next step\n",
    "        self.previous_distance = distance\n",
    "\n",
    "        return reward\n",
    "\n",
    "        \n",
    "\n",
    "    def is_done(self):\n",
    "        # Define when the episode ends\n",
    "        # ends when the car reaches the goal or it takes more than 100 steps\n",
    "        return self.car_position == (self.maze_size_x - 1, self.maze_size_y - 1)\n",
    "        \n",
    "        \n",
    "    def get_state(self):\n",
    "        return (self.car_position, self.car_orientation, self.sensor_readings)\n",
    "\n",
    "    # def render(self):\n",
    "    #     rendered_maze = np.array(self.maze, dtype=str)\n",
    "    #     x, y = self.car_position\n",
    "    #     rendered_maze[y][x] = 'C'  # Representing the car\n",
    "        \n",
    "    #     #print array\n",
    "    #     print(rendered_maze, '\\n') \n",
    "\n",
    "    \n",
    "    def init_pygame(self):\n",
    "        # Initialize Pygame and set up the display\n",
    "        pygame.init()\n",
    "        self.cell_size = 40  # Size of each cell in pixels\n",
    "        self.width = self.maze_size_x * self.cell_size\n",
    "        self.height = self.maze_size_y * self.cell_size\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "    def render(self):\n",
    "        # Render the environment using Pygame\n",
    "        for y in range(self.maze_size_y):\n",
    "            for x in range(self.maze_size_x):\n",
    "                rect = pygame.Rect(x * self.cell_size, y * self.cell_size, self.cell_size, self.cell_size)\n",
    "                if (x, y) == (self.maze_size_x - 1, self.maze_size_y - 1):  # Goal position\n",
    "                    color = (0, 255, 0)  # Green color for the goal\n",
    "                elif self.maze[y][x] == 0:\n",
    "                    color = (255, 255, 255)  # White color for empty space\n",
    "                else:\n",
    "                    color = (0, 0, 0)  # Black color for walls\n",
    "                pygame.draw.rect(self.screen, color, rect)\n",
    "\n",
    "        # Draw the car\n",
    "        car_x, car_y = self.car_position\n",
    "        car_rect = pygame.Rect(car_x * self.cell_size, car_y * self.cell_size, self.cell_size, self.cell_size)\n",
    "        pygame.draw.rect(self.screen, (255, 0, 0), car_rect)  # Red color for the car\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(60)  # Limit the frame rate to 60 FPS\n",
    "\n",
    "\n",
    "    def close_pygame(self):\n",
    "        # Close the Pygame window\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.1, possible_actions=3, min_epsilon=0.01, epsilon_decay=0.99):\n",
    "        self.q_table = {}\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.possible_actions = possible_actions\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        \n",
    "\n",
    "    def state_to_tuple(self, state):\n",
    "        \n",
    "        #((0, 0), 'N', {'front': 1, 'left': 0, 'right': 0})\n",
    "        # if like this convert to ((0, 0), 'N', (1, 0, 0))\n",
    "        if not isinstance(state[2], dict):\n",
    "            # print(state)\n",
    "            # print(state[2])\n",
    "            #take state[2] and make it from this (1, 0, 0) to this {'front': 1, 'left': 0, 'right': 0}\n",
    "            newState = {'front': state[2][0], 'left': state[2][1], 'right': state[2][2]}\n",
    "            # print(newState)\n",
    "            #create a new state with the [2] being the new dictionary\n",
    "            state = (state[0], state[1], newState)\n",
    "            \n",
    "        # Convert the state dictionary to a hashable tuple\n",
    "        # Adjust this based on the specific format of your state\n",
    "        position, orientation, sensor_readings = state\n",
    "        sensor_readings_tuple = tuple(sensor_readings.values())\n",
    "        return (position, orientation, sensor_readings_tuple)\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        state_tuple = self.state_to_tuple(state)\n",
    "        return self.q_table.get((state_tuple, action), 0)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(range(self.possible_actions))\n",
    "        else:\n",
    "            state_tuple = self.state_to_tuple(state)\n",
    "            q_values = [self.get_q_value(state_tuple, action) for action in range(self.possible_actions)]\n",
    "            max_q = max(q_values)\n",
    "            actions_with_max_q = [action for action, q in enumerate(q_values) if q == max_q]\n",
    "            return random.choice(actions_with_max_q)\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        state_tuple = self.state_to_tuple(state)\n",
    "        next_state_tuple = self.state_to_tuple(next_state)\n",
    "        max_q_next = max([self.get_q_value(next_state_tuple, next_action) for next_action in range(self.possible_actions)])\n",
    "        current_q = self.get_q_value(state_tuple, action)\n",
    "        new_q = current_q + self.alpha * (reward + self.gamma * max_q_next - current_q)\n",
    "        self.q_table[(state_tuple, action)] = new_q\n",
    "\n",
    "    def train(self, environment, num_episodes):\n",
    "        reward_history = []\n",
    "        for _ in range(num_episodes):\n",
    "            state = environment.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            while not done:\n",
    "                \n",
    "                action = self.choose_action(state)\n",
    "                next_state, reward, done = environment.step(action)\n",
    "                self.update_q_value(state, action, reward, next_state)\n",
    "                total_reward += reward\n",
    "                state = next_state\n",
    "\n",
    "            # Add the total reward for this episode to the history\n",
    "            reward_history.append(total_reward)\n",
    "\n",
    "            # Decay epsilon, but not below the minimum value\n",
    "            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "            # Print episode summary\n",
    "            print(\"Episode finished after {} timesteps\".format(environment.steps))\n",
    "            print(\"Total reward: {}, Epsilon: {:.3f}\".format(total_reward, self.epsilon))\n",
    "\n",
    "        return reward_history\n",
    "            \n",
    "    def test(self, env):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            env.render()\n",
    "            action = self.choose_action(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "\n",
    "        print(f\"Test Total Reward: {total_reward}\")\n",
    "\n",
    "# Example usage:\n",
    "# env = RCMazeEnv()\n",
    "# agent = QAgent()\n",
    "# agent.train(env, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 761 timesteps\n",
      "Total reward: -3140, Epsilon: 0.894\n",
      "Episode finished after 1292 timesteps\n",
      "Total reward: -5570, Epsilon: 0.887\n",
      "Episode finished after 683 timesteps\n",
      "Total reward: -2835, Epsilon: 0.881\n",
      "Episode finished after 312 timesteps\n",
      "Total reward: -1150, Epsilon: 0.875\n",
      "Episode finished after 428 timesteps\n",
      "Total reward: -1695, Epsilon: 0.869\n",
      "Episode finished after 261 timesteps\n",
      "Total reward: -945, Epsilon: 0.863\n",
      "Episode finished after 574 timesteps\n",
      "Total reward: -2330, Epsilon: 0.857\n",
      "Episode finished after 296 timesteps\n",
      "Total reward: -1080, Epsilon: 0.851\n",
      "Episode finished after 209 timesteps\n",
      "Total reward: -725, Epsilon: 0.845\n",
      "Episode finished after 243 timesteps\n",
      "Total reward: -895, Epsilon: 0.839\n",
      "Episode finished after 770 timesteps\n",
      "Total reward: -3245, Epsilon: 0.833\n",
      "Episode finished after 277 timesteps\n",
      "Total reward: -1000, Epsilon: 0.827\n",
      "Episode finished after 148 timesteps\n",
      "Total reward: -440, Epsilon: 0.821\n",
      "Episode finished after 384 timesteps\n",
      "Total reward: -1490, Epsilon: 0.816\n",
      "Episode finished after 728 timesteps\n",
      "Total reward: -3005, Epsilon: 0.810\n",
      "Episode finished after 190 timesteps\n",
      "Total reward: -625, Epsilon: 0.804\n",
      "Episode finished after 157 timesteps\n",
      "Total reward: -480, Epsilon: 0.799\n",
      "Episode finished after 302 timesteps\n",
      "Total reward: -1110, Epsilon: 0.793\n",
      "Episode finished after 267 timesteps\n",
      "Total reward: -970, Epsilon: 0.788\n",
      "Episode finished after 348 timesteps\n",
      "Total reward: -1310, Epsilon: 0.782\n",
      "Episode finished after 413 timesteps\n",
      "Total reward: -1590, Epsilon: 0.777\n",
      "Episode finished after 346 timesteps\n",
      "Total reward: -1230, Epsilon: 0.771\n",
      "Episode finished after 242 timesteps\n",
      "Total reward: -850, Epsilon: 0.766\n",
      "Episode finished after 82 timesteps\n",
      "Total reward: -130, Epsilon: 0.760\n",
      "Episode finished after 135 timesteps\n",
      "Total reward: -385, Epsilon: 0.755\n",
      "Episode finished after 107 timesteps\n",
      "Total reward: -245, Epsilon: 0.750\n",
      "Episode finished after 185 timesteps\n",
      "Total reward: -605, Epsilon: 0.745\n",
      "Episode finished after 152 timesteps\n",
      "Total reward: -425, Epsilon: 0.739\n",
      "Episode finished after 97 timesteps\n",
      "Total reward: -180, Epsilon: 0.734\n",
      "Episode finished after 144 timesteps\n",
      "Total reward: -400, Epsilon: 0.729\n",
      "Episode finished after 131 timesteps\n",
      "Total reward: -340, Epsilon: 0.724\n",
      "Episode finished after 93 timesteps\n",
      "Total reward: -165, Epsilon: 0.719\n",
      "Episode finished after 232 timesteps\n",
      "Total reward: -805, Epsilon: 0.714\n",
      "Episode finished after 94 timesteps\n",
      "Total reward: -200, Epsilon: 0.709\n",
      "Episode finished after 285 timesteps\n",
      "Total reward: -1045, Epsilon: 0.704\n",
      "Episode finished after 162 timesteps\n",
      "Total reward: -485, Epsilon: 0.699\n",
      "Episode finished after 142 timesteps\n",
      "Total reward: -410, Epsilon: 0.694\n",
      "Episode finished after 66 timesteps\n",
      "Total reward: -60, Epsilon: 0.689\n",
      "Episode finished after 175 timesteps\n",
      "Total reward: -540, Epsilon: 0.684\n",
      "Episode finished after 49 timesteps\n",
      "Total reward: 20, Epsilon: 0.680\n",
      "Episode finished after 143 timesteps\n",
      "Total reward: -395, Epsilon: 0.675\n",
      "Episode finished after 261 timesteps\n",
      "Total reward: -950, Epsilon: 0.670\n",
      "Episode finished after 148 timesteps\n",
      "Total reward: -425, Epsilon: 0.665\n",
      "Episode finished after 48 timesteps\n",
      "Total reward: 30, Epsilon: 0.661\n",
      "Episode finished after 105 timesteps\n",
      "Total reward: -225, Epsilon: 0.656\n",
      "Episode finished after 252 timesteps\n",
      "Total reward: -860, Epsilon: 0.651\n",
      "Episode finished after 156 timesteps\n",
      "Total reward: -430, Epsilon: 0.647\n",
      "Episode finished after 154 timesteps\n",
      "Total reward: -430, Epsilon: 0.642\n",
      "Episode finished after 92 timesteps\n",
      "Total reward: -185, Epsilon: 0.638\n",
      "Episode finished after 129 timesteps\n",
      "Total reward: -325, Epsilon: 0.633\n",
      "Episode finished after 107 timesteps\n",
      "Total reward: -235, Epsilon: 0.629\n",
      "Episode finished after 87 timesteps\n",
      "Total reward: -135, Epsilon: 0.625\n",
      "Episode finished after 49 timesteps\n",
      "Total reward: 25, Epsilon: 0.620\n",
      "Episode finished after 130 timesteps\n",
      "Total reward: -340, Epsilon: 0.616\n",
      "Episode finished after 49 timesteps\n",
      "Total reward: 25, Epsilon: 0.612\n",
      "Episode finished after 73 timesteps\n",
      "Total reward: -85, Epsilon: 0.607\n",
      "Episode finished after 65 timesteps\n",
      "Total reward: -45, Epsilon: 0.603\n",
      "Episode finished after 100 timesteps\n",
      "Total reward: -225, Epsilon: 0.599\n",
      "Episode finished after 85 timesteps\n",
      "Total reward: -145, Epsilon: 0.595\n",
      "Episode finished after 59 timesteps\n",
      "Total reward: -15, Epsilon: 0.590\n",
      "Episode finished after 185 timesteps\n",
      "Total reward: -590, Epsilon: 0.586\n",
      "Episode finished after 68 timesteps\n",
      "Total reward: -65, Epsilon: 0.582\n",
      "Episode finished after 76 timesteps\n",
      "Total reward: -90, Epsilon: 0.578\n",
      "Episode finished after 76 timesteps\n",
      "Total reward: -110, Epsilon: 0.574\n",
      "Episode finished after 112 timesteps\n",
      "Total reward: -245, Epsilon: 0.570\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.566\n",
      "Episode finished after 90 timesteps\n",
      "Total reward: -170, Epsilon: 0.562\n",
      "Episode finished after 112 timesteps\n",
      "Total reward: -250, Epsilon: 0.558\n",
      "Episode finished after 43 timesteps\n",
      "Total reward: 50, Epsilon: 0.554\n",
      "Episode finished after 106 timesteps\n",
      "Total reward: -225, Epsilon: 0.550\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 40, Epsilon: 0.547\n",
      "Episode finished after 104 timesteps\n",
      "Total reward: -215, Epsilon: 0.543\n",
      "Episode finished after 56 timesteps\n",
      "Total reward: -15, Epsilon: 0.539\n",
      "Episode finished after 99 timesteps\n",
      "Total reward: -205, Epsilon: 0.535\n",
      "Episode finished after 121 timesteps\n",
      "Total reward: -315, Epsilon: 0.531\n",
      "Episode finished after 118 timesteps\n",
      "Total reward: -300, Epsilon: 0.528\n",
      "Episode finished after 104 timesteps\n",
      "Total reward: -225, Epsilon: 0.524\n",
      "Episode finished after 141 timesteps\n",
      "Total reward: -390, Epsilon: 0.520\n",
      "Episode finished after 71 timesteps\n",
      "Total reward: -70, Epsilon: 0.517\n",
      "Episode finished after 148 timesteps\n",
      "Total reward: -420, Epsilon: 0.513\n",
      "Episode finished after 70 timesteps\n",
      "Total reward: -40, Epsilon: 0.509\n",
      "Episode finished after 122 timesteps\n",
      "Total reward: -300, Epsilon: 0.506\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.502\n",
      "Episode finished after 77 timesteps\n",
      "Total reward: -100, Epsilon: 0.499\n",
      "Episode finished after 55 timesteps\n",
      "Total reward: -5, Epsilon: 0.495\n",
      "Episode finished after 41 timesteps\n",
      "Total reward: 60, Epsilon: 0.492\n",
      "Episode finished after 107 timesteps\n",
      "Total reward: -255, Epsilon: 0.488\n",
      "Episode finished after 69 timesteps\n",
      "Total reward: -45, Epsilon: 0.485\n",
      "Episode finished after 150 timesteps\n",
      "Total reward: -435, Epsilon: 0.482\n",
      "Episode finished after 82 timesteps\n",
      "Total reward: -110, Epsilon: 0.478\n",
      "Episode finished after 88 timesteps\n",
      "Total reward: -135, Epsilon: 0.475\n",
      "Episode finished after 50 timesteps\n",
      "Total reward: 25, Epsilon: 0.472\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 65, Epsilon: 0.468\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.465\n",
      "Episode finished after 71 timesteps\n",
      "Total reward: -60, Epsilon: 0.462\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.459\n",
      "Episode finished after 105 timesteps\n",
      "Total reward: -225, Epsilon: 0.455\n",
      "Episode finished after 63 timesteps\n",
      "Total reward: -45, Epsilon: 0.452\n",
      "Episode finished after 49 timesteps\n",
      "Total reward: 25, Epsilon: 0.449\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 45, Epsilon: 0.446\n",
      "Episode finished after 65 timesteps\n",
      "Total reward: -40, Epsilon: 0.443\n",
      "Episode finished after 63 timesteps\n",
      "Total reward: -30, Epsilon: 0.440\n",
      "Episode finished after 41 timesteps\n",
      "Total reward: 60, Epsilon: 0.437\n",
      "Episode finished after 51 timesteps\n",
      "Total reward: 15, Epsilon: 0.433\n",
      "Episode finished after 56 timesteps\n",
      "Total reward: 5, Epsilon: 0.430\n",
      "Episode finished after 62 timesteps\n",
      "Total reward: -25, Epsilon: 0.427\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 75, Epsilon: 0.424\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 45, Epsilon: 0.421\n",
      "Episode finished after 51 timesteps\n",
      "Total reward: 25, Epsilon: 0.419\n",
      "Episode finished after 130 timesteps\n",
      "Total reward: -330, Epsilon: 0.416\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 65, Epsilon: 0.413\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.410\n",
      "Episode finished after 77 timesteps\n",
      "Total reward: -95, Epsilon: 0.407\n",
      "Episode finished after 46 timesteps\n",
      "Total reward: 35, Epsilon: 0.404\n",
      "Episode finished after 97 timesteps\n",
      "Total reward: -170, Epsilon: 0.401\n",
      "Episode finished after 61 timesteps\n",
      "Total reward: -15, Epsilon: 0.398\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.396\n",
      "Episode finished after 46 timesteps\n",
      "Total reward: 35, Epsilon: 0.393\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.390\n",
      "Episode finished after 43 timesteps\n",
      "Total reward: 50, Epsilon: 0.387\n",
      "Episode finished after 91 timesteps\n",
      "Total reward: -150, Epsilon: 0.385\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.382\n",
      "Episode finished after 44 timesteps\n",
      "Total reward: 45, Epsilon: 0.379\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.377\n",
      "Episode finished after 44 timesteps\n",
      "Total reward: 55, Epsilon: 0.374\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.371\n",
      "Episode finished after 75 timesteps\n",
      "Total reward: -65, Epsilon: 0.369\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 120, Epsilon: 0.366\n",
      "Episode finished after 74 timesteps\n",
      "Total reward: -85, Epsilon: 0.364\n",
      "Episode finished after 41 timesteps\n",
      "Total reward: 65, Epsilon: 0.361\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.359\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 65, Epsilon: 0.356\n",
      "Episode finished after 43 timesteps\n",
      "Total reward: 50, Epsilon: 0.354\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.351\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 75, Epsilon: 0.349\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.346\n",
      "Episode finished after 52 timesteps\n",
      "Total reward: 10, Epsilon: 0.344\n",
      "Episode finished after 46 timesteps\n",
      "Total reward: 45, Epsilon: 0.341\n",
      "Episode finished after 55 timesteps\n",
      "Total reward: 5, Epsilon: 0.339\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 55, Epsilon: 0.337\n",
      "Episode finished after 51 timesteps\n",
      "Total reward: 15, Epsilon: 0.334\n",
      "Episode finished after 41 timesteps\n",
      "Total reward: 60, Epsilon: 0.332\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.330\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 100, Epsilon: 0.327\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.325\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 85, Epsilon: 0.323\n",
      "Episode finished after 39 timesteps\n",
      "Total reward: 70, Epsilon: 0.320\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 75, Epsilon: 0.318\n",
      "Episode finished after 69 timesteps\n",
      "Total reward: -55, Epsilon: 0.316\n",
      "Episode finished after 42 timesteps\n",
      "Total reward: 60, Epsilon: 0.314\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 120, Epsilon: 0.312\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.309\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.307\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.305\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 65, Epsilon: 0.303\n",
      "Episode finished after 148 timesteps\n",
      "Total reward: -405, Epsilon: 0.301\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.299\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.297\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.295\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 40, Epsilon: 0.292\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 85, Epsilon: 0.290\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 85, Epsilon: 0.288\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.286\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 45, Epsilon: 0.284\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.282\n",
      "Episode finished after 80 timesteps\n",
      "Total reward: -100, Epsilon: 0.280\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.278\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.277\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 75, Epsilon: 0.275\n",
      "Episode finished after 67 timesteps\n",
      "Total reward: -60, Epsilon: 0.273\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.271\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.269\n",
      "Episode finished after 42 timesteps\n",
      "Total reward: 70, Epsilon: 0.267\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.265\n",
      "Episode finished after 47 timesteps\n",
      "Total reward: 35, Epsilon: 0.263\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.261\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.260\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 45, Epsilon: 0.258\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.256\n",
      "Episode finished after 87 timesteps\n",
      "Total reward: -145, Epsilon: 0.254\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 115, Epsilon: 0.252\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.251\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 90, Epsilon: 0.249\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.247\n",
      "Episode finished after 53 timesteps\n",
      "Total reward: 20, Epsilon: 0.245\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.244\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.242\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.240\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.239\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.237\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 140, Epsilon: 0.235\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.234\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.232\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.230\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.229\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.227\n",
      "Episode finished after 50 timesteps\n",
      "Total reward: 25, Epsilon: 0.226\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.224\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.222\n",
      "Episode finished after 54 timesteps\n",
      "Total reward: 15, Epsilon: 0.221\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.219\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.218\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 70, Epsilon: 0.216\n",
      "Episode finished after 42 timesteps\n",
      "Total reward: 60, Epsilon: 0.215\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 80, Epsilon: 0.213\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.212\n",
      "Episode finished after 46 timesteps\n",
      "Total reward: 50, Epsilon: 0.210\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.209\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.207\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.206\n",
      "Episode finished after 73 timesteps\n",
      "Total reward: -70, Epsilon: 0.204\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.203\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.202\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.200\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.199\n",
      "Episode finished after 48 timesteps\n",
      "Total reward: 25, Epsilon: 0.197\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.196\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 100, Epsilon: 0.195\n",
      "Episode finished after 65 timesteps\n",
      "Total reward: -10, Epsilon: 0.193\n",
      "Episode finished after 42 timesteps\n",
      "Total reward: 55, Epsilon: 0.192\n",
      "Episode finished after 51 timesteps\n",
      "Total reward: 25, Epsilon: 0.191\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.189\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.188\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.187\n",
      "Episode finished after 44 timesteps\n",
      "Total reward: 60, Epsilon: 0.185\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.184\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.183\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.181\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.180\n",
      "Episode finished after 39 timesteps\n",
      "Total reward: 75, Epsilon: 0.179\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.178\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 80, Epsilon: 0.176\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.175\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.174\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.173\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.172\n",
      "Episode finished after 75 timesteps\n",
      "Total reward: -75, Epsilon: 0.170\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.169\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.168\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.167\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 120, Epsilon: 0.166\n",
      "Episode finished after 42 timesteps\n",
      "Total reward: 60, Epsilon: 0.164\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.163\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.162\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.161\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.160\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.159\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.158\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.157\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.155\n",
      "Episode finished after 41 timesteps\n",
      "Total reward: 60, Epsilon: 0.154\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 80, Epsilon: 0.153\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.152\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.151\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.150\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 110, Epsilon: 0.149\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.148\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.147\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.146\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.145\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.144\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.143\n",
      "Episode finished after 54 timesteps\n",
      "Total reward: 20, Epsilon: 0.142\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.141\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 90, Epsilon: 0.140\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.139\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.138\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.137\n",
      "Episode finished after 46 timesteps\n",
      "Total reward: 45, Epsilon: 0.136\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.135\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 125, Epsilon: 0.134\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.133\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 80, Epsilon: 0.132\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.131\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.130\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.129\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.129\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.128\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.127\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.126\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.125\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.124\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.123\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.122\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.122\n",
      "Episode finished after 66 timesteps\n",
      "Total reward: -25, Epsilon: 0.121\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.120\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.119\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.118\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.117\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.117\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.116\n",
      "Episode finished after 47 timesteps\n",
      "Total reward: 45, Epsilon: 0.115\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.114\n",
      "Episode finished after 39 timesteps\n",
      "Total reward: 75, Epsilon: 0.113\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 110, Epsilon: 0.113\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.112\n",
      "Episode finished after 66 timesteps\n",
      "Total reward: -25, Epsilon: 0.111\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.110\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.109\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.109\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.108\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 80, Epsilon: 0.107\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.106\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.106\n",
      "Episode finished after 21 timesteps\n",
      "Total reward: 160, Epsilon: 0.105\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.104\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.103\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.103\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.102\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.101\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.101\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 42 timesteps\n",
      "Total reward: 55, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 21 timesteps\n",
      "Total reward: 160, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 80, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 21 timesteps\n",
      "Total reward: 160, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 45, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 80, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 66 timesteps\n",
      "Total reward: -50, Epsilon: 0.100\n",
      "Episode finished after 52 timesteps\n",
      "Total reward: 30, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 35 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 21 timesteps\n",
      "Total reward: 160, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 41 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 65, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 80, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 35 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 44 timesteps\n",
      "Total reward: 60, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 35 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 65, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 64 timesteps\n",
      "Total reward: -20, Epsilon: 0.100\n",
      "Episode finished after 95 timesteps\n",
      "Total reward: -145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 35 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 39 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 63 timesteps\n",
      "Total reward: -5, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 65, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 45, Epsilon: 0.100\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 80, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 43 timesteps\n",
      "Total reward: 55, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 21 timesteps\n",
      "Total reward: 160, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 72 timesteps\n",
      "Total reward: -60, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 55, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 62 timesteps\n",
      "Total reward: -10, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 56 timesteps\n",
      "Total reward: 0, Epsilon: 0.100\n",
      "Episode finished after 41 timesteps\n",
      "Total reward: 60, Epsilon: 0.100\n",
      "Episode finished after 108 timesteps\n",
      "Total reward: -235, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 65, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 60 timesteps\n",
      "Total reward: 0, Epsilon: 0.100\n",
      "Episode finished after 51 timesteps\n",
      "Total reward: 15, Epsilon: 0.100\n",
      "Episode finished after 39 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 21 timesteps\n",
      "Total reward: 160, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 21 timesteps\n",
      "Total reward: 160, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 35 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 41 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 43 timesteps\n",
      "Total reward: 55, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 73 timesteps\n",
      "Total reward: -75, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 52 timesteps\n",
      "Total reward: 15, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 103 timesteps\n",
      "Total reward: -195, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 35 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 21 timesteps\n",
      "Total reward: 160, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 89 timesteps\n",
      "Total reward: -120, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 42 timesteps\n",
      "Total reward: 55, Epsilon: 0.100\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 55 timesteps\n",
      "Total reward: -5, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 42 timesteps\n",
      "Total reward: 70, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 35 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 39 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 76 timesteps\n",
      "Total reward: -70, Epsilon: 0.100\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 46 timesteps\n",
      "Total reward: 50, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 50 timesteps\n",
      "Total reward: 20, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 25 timesteps\n",
      "Total reward: 140, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 55 timesteps\n",
      "Total reward: 10, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 56 timesteps\n",
      "Total reward: -10, Epsilon: 0.100\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 125 timesteps\n",
      "Total reward: -310, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 62 timesteps\n",
      "Total reward: -15, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 38 timesteps\n",
      "Total reward: 75, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 95, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 45 timesteps\n",
      "Total reward: 55, Epsilon: 0.100\n",
      "Episode finished after 48 timesteps\n",
      "Total reward: 30, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 37 timesteps\n",
      "Total reward: 80, Epsilon: 0.100\n",
      "Episode finished after 75 timesteps\n",
      "Total reward: -75, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 105, Epsilon: 0.100\n",
      "Episode finished after 21 timesteps\n",
      "Total reward: 160, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 42 timesteps\n",
      "Total reward: 60, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 90, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 118 timesteps\n",
      "Total reward: -265, Epsilon: 0.100\n",
      "Episode finished after 32 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 23 timesteps\n",
      "Total reward: 150, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 46 timesteps\n",
      "Total reward: 65, Epsilon: 0.100\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 70, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 28 timesteps\n",
      "Total reward: 125, Epsilon: 0.100\n",
      "Episode finished after 34 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 33 timesteps\n",
      "Total reward: 100, Epsilon: 0.100\n",
      "Episode finished after 36 timesteps\n",
      "Total reward: 85, Epsilon: 0.100\n",
      "Episode finished after 30 timesteps\n",
      "Total reward: 115, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 31 timesteps\n",
      "Total reward: 110, Epsilon: 0.100\n",
      "Episode finished after 52 timesteps\n",
      "Total reward: 40, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 29 timesteps\n",
      "Total reward: 120, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 40 timesteps\n",
      "Total reward: 65, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 24 timesteps\n",
      "Total reward: 145, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n",
      "Episode finished after 26 timesteps\n",
      "Total reward: 135, Epsilon: 0.100\n",
      "Episode finished after 22 timesteps\n",
      "Total reward: 155, Epsilon: 0.100\n",
      "Episode finished after 27 timesteps\n",
      "Total reward: 130, Epsilon: 0.100\n",
      "Episode finished after 20 timesteps\n",
      "Total reward: 165, Epsilon: 0.100\n"
     ]
    }
   ],
   "source": [
    "EPSILON = 0.9\n",
    "ALPHA = 0.1\n",
    "GAMMA = 0.6\n",
    "DECAY = 0.999\n",
    "MINEPSILON = 0.1\n",
    "DECAY_RATE = 0.993\n",
    "\n",
    "\n",
    "env = RCMazeEnv()\n",
    "agent = QAgent(alpha=ALPHA, gamma=GAMMA, epsilon=EPSILON, min_epsilon=MINEPSILON, epsilon_decay=DECAY_RATE)\n",
    "env.init_pygame()\n",
    "agent.train(env, 1000)\n",
    "env.close_pygame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Total Reward: 135\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "env = RCMazeEnv()\n",
    "\n",
    "env.init_pygame()\n",
    "\n",
    "# Example of running the environment\n",
    "agent.test(env)\n",
    "\n",
    "\n",
    "env.close_pygame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
