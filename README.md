# Exploring the Feasibility of Sim2Real Transfer in Reinforcement Learning

## Introduction

This research, conducted at Howest University, delves into the sim2real transfer of a Reinforcement Learning (RL) agent, focusing on maze navigation via a remote-controlled car. It bridges the gap between theoretical models and practical applications in AI and robotics.

### Research Paper

you can read the full research paper [here](./researchPaper.md) or in pdf format [here](./Paper.pdf)

## Author

**Lucas Driessens**  
Howest University of Applied Sciences  
Research Project, 2024-01-30

## Project Summary

Evaluating sim2real transfer feasibility, this study tackles virtual environments, RL techniques, and practical transition aspects. It employs a Double Deep Q-Network (DDQN) for agent training in a custom-designed virtual environment, culminating in real-world application through a robotic car setup.

## Methodology and Results

Using OpenAI Gym for environment simulation, the project features a DDQN algorithm for enhanced learning efficiency. The methodology includes agent design, model architecture, training parameters, and a unique reward system. Key results demonstrate the agent's improved performance and navigational capabilities in both simulated and real-world scenarios.

## Challenges and Solutions

Significant challenges, such as environment selection, RL technique optimization, and sim2real discrepancies, were addressed through innovative solutions like algorithmic adjustments, hardware modifications, and sensor data normalization, showcasing the project's iterative and problem-solving approach.

## Real-World Applications and Limitations

The research underscores the potential of RL in autonomous navigation, with implications for autonomous vehicles and robotics. However, sensor discrepancies and movement replication challenges highlight the limitations and the need for further research.

## Conclusion and Acknowledgments

This project illustrates the complexities and potentials of sim2real transfer in RL, contributing valuable insights for future applications in robotics and AI. Special thanks to coach Gevaert Wouter for his guidance and support.
