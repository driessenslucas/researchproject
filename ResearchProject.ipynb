{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import pygame\n",
    "\n",
    "class RCMazeEnv(gym.Env):\n",
    "    def __init__(self, maze_size_x=12, maze_size_y=12):\n",
    "        self.maze_size_x = maze_size_x\n",
    "        self.maze_size_y = maze_size_y\n",
    "        self.maze = self.generate_maze()\n",
    "        self.car_position = (1, 1)\n",
    "        self.possible_actions = range(3)\n",
    "        self.car_orientation = 'N'\n",
    "        self.sensor_readings = {'front': 0, 'left': 0, 'right': 0}\n",
    "        self.steps = 0\n",
    "        self.previous_distance = 0\n",
    "        self.goal = (10, 10)\n",
    "        self.previous_steps = 0\n",
    "        self.reset()\n",
    "\n",
    "            \n",
    "    def generate_maze(self):\n",
    "        # For simplicity, create a static maze with walls\n",
    "        # '1' represents a wall, and '0' represents an open path\n",
    "        maze = np.zeros((self.maze_size_y, self.maze_size_x), dtype=int)\n",
    "        # Add walls to the maze (this can be customized)\n",
    "\n",
    "        layout = [\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
    "                [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1],\n",
    "                [1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1],\n",
    "                [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "        \n",
    "     \n",
    "        maze = np.array(layout)\n",
    "\n",
    "        return maze\n",
    "\n",
    "    def reset(self):\n",
    "        self.car_position = (1, 1)\n",
    "        self.car_orientation = 'N'\n",
    "        self.update_sensor_readings()\n",
    "        self.steps = 0\n",
    "        self.previous_distance = 0\n",
    "        self.previous_steps = 0\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.move_forward()\n",
    "        elif action == 1:\n",
    "            self.turn_left()\n",
    "        elif action == 2:\n",
    "            self.turn_right()\n",
    "        self.update_sensor_readings()\n",
    "        reward = self.compute_reward()\n",
    "        self.steps += 1\n",
    "        done = self.is_done()\n",
    "        return self.get_state(), reward, done\n",
    "\n",
    "    \n",
    "    def move_forward(self):\n",
    "        x, y = self.car_position\n",
    "        if self.car_orientation == 'N' and y > 0 and self.maze[y - 1][x] != 1:\n",
    "            self.car_position = (x, y - 1)\n",
    "        elif self.car_orientation == 'S' and y < self.maze_size_y - 1 and self.maze[y + 1][x] != 1:\n",
    "            self.car_position = (x, y + 1)\n",
    "        elif self.car_orientation == 'E' and x < self.maze_size_x - 1 and self.maze[y][x + 1] != 1:\n",
    "            self.car_position = (x + 1, y)\n",
    "        elif self.car_orientation == 'W' and x > 0 and self.maze[y][x - 1] != 1:\n",
    "            self.car_position = (x - 1, y)\n",
    "        \n",
    "\n",
    "    def turn_left(self):\n",
    "        orientations = ['N', 'W', 'S', 'E']\n",
    "        idx = orientations.index(self.car_orientation)\n",
    "        self.car_orientation = orientations[(idx + 1) % 4]\n",
    "\n",
    "    def turn_right(self):\n",
    "        orientations = ['N', 'E', 'S', 'W']\n",
    "        idx = orientations.index(self.car_orientation)\n",
    "        self.car_orientation = orientations[(idx + 1) % 4]\n",
    "\n",
    "    def update_sensor_readings(self):\n",
    "        # Simple sensor implementation: counts steps to the nearest wall\n",
    "        self.sensor_readings['front'] = self.distance_to_wall('front')\n",
    "        self.sensor_readings['left'] = self.distance_to_wall('left')\n",
    "        self.sensor_readings['right'] = self.distance_to_wall('right')\n",
    "\n",
    "    def distance_to_wall(self, direction):\n",
    "        x, y = self.car_position\n",
    "        distance = 0\n",
    "        max_distance = self.maze_size_x if direction in ['left', 'right'] else self.maze_size_y\n",
    "\n",
    "        \n",
    "        if direction == 'front':\n",
    "            if self.car_orientation == 'N':\n",
    "                while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'S':\n",
    "                while y + distance < self.maze_size_y and self.maze[y + distance][x] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'E':\n",
    "                while x + distance < self.maze_size_x and self.maze[y][x + distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'W':\n",
    "                while x - distance >= 0 and self.maze[y][x - distance] != 1:\n",
    "                    distance += 1\n",
    "        elif direction == 'left':\n",
    "            if self.car_orientation == 'N':\n",
    "                while x - distance >= 0 and self.maze[y][x - distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'S':\n",
    "                while x + distance < self.maze_size_x and self.maze[y][x + distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'E':\n",
    "                while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'W':\n",
    "                while y + distance < self.maze_size_y and self.maze[y + distance][x] != 1:\n",
    "                    distance += 1\n",
    "        elif direction == 'right':\n",
    "            if self.car_orientation == 'N':\n",
    "                while x + distance < self.maze_size_x and self.maze[y][x + distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'S':\n",
    "                while x - distance >= 0 and self.maze[y][x - distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'E':\n",
    "                while y + distance < self.maze_size_y and self.maze[y + distance][x] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'W':\n",
    "                while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                    distance += 1\n",
    "        \n",
    "            # Normalize the measured distance\n",
    "        normalized_distance = (max_distance - distance - 1) / (max_distance - 1)\n",
    "\n",
    "        # Ensure the value is within the range [0, 1]\n",
    "        normalized_distance = max(0, min(normalized_distance, 1))\n",
    "\n",
    "        return normalized_distance\n",
    "    \n",
    "    def compute_reward(self):\n",
    "        # # Initialize reward\n",
    "        reward = 0\n",
    "\n",
    "        # # Check for collision or out of bounds\n",
    "        if any(self.sensor_readings[direction] == 0 for direction in ['front', 'left', 'right']):\n",
    "            reward -= 20\n",
    "\n",
    "        # # Check if goal is reached\n",
    "        if self.car_position == self.goal:\n",
    "            reward += 100\n",
    "            # Additional penalty if it takes too many steps to reach the goal\n",
    "            if self.steps > 750:\n",
    "                reward -= 200\n",
    "            return reward  # Return immediately as this is the terminal state\n",
    "\n",
    "        # Calculate the Euclidean distance to the goal\n",
    "        distance_to_goal = ((self.car_position[0] - self.goal[0]) ** 2 + (self.car_position[1] - self.goal[1]) ** 2) ** 0.5\n",
    "\n",
    "        # Define a maximum reward when the car is at the goal\n",
    "        max_reward_at_goal = 50\n",
    "\n",
    "        # Reward based on proximity to the goal\n",
    "        reward += max_reward_at_goal / (distance_to_goal + 1)  # Adding 1 to avoid division by zero\n",
    "\n",
    "        # # Reward or penalize based on movement towards or away from the goal\n",
    "        if distance_to_goal < self.previous_distance:\n",
    "            reward += 50  # Positive reward for moving closer to the goal\n",
    "        elif distance_to_goal > self.previous_distance:\n",
    "            reward -= 25  # Negative reward for moving farther from the goal\n",
    "\n",
    "\n",
    "        # Penalize for each step taken to encourage efficiency\n",
    "        reward -= 2\n",
    "\n",
    "        # # Update the previous_distance for the next step\n",
    "        self.previous_distance = distance_to_goal\n",
    "        return reward\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def is_done(self):\n",
    "        # Define when the episode ends\n",
    "        # ends when the car reaches the goal or it takes more than 3000 steps \n",
    "        return self.car_position == self.goal or self.steps > 3000\n",
    "        \n",
    "        \n",
    "    def get_state(self):\n",
    "        return (self.car_position, self.car_orientation, self.sensor_readings)\n",
    "\n",
    "    # def render(self):\n",
    "    #     rendered_maze = np.array(self.maze, dtype=str)\n",
    "    #     x, y = self.car_position\n",
    "    #     rendered_maze[y][x] = 'C'  # Representing the car\n",
    "        \n",
    "    #     #print array\n",
    "    #     print(rendered_maze, '\\n') \n",
    "\n",
    "    \n",
    "    def init_pygame(self):\n",
    "        # Initialize Pygame and set up the display\n",
    "        pygame.init()\n",
    "        self.cell_size = 40  # Size of each cell in pixels\n",
    "        self.maze_size_x = 12  # Assuming the maze size_x is 12\n",
    "        self.maze_size_y = 12  # Assuming the maze size_y is 12\n",
    "        self.width = 600\n",
    "        self.height = 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "    def render(self):\n",
    "        # Render the environment using Pygame\n",
    "        for y in range(self.maze_size_y):\n",
    "            for x in range(self.maze_size_x):\n",
    "                rect = pygame.Rect(x * self.cell_size, y * self.cell_size, self.cell_size, self.cell_size)\n",
    "                if (x, y) == self.goal:  # Goal position\n",
    "                    color = (0, 255, 0)  # Green color for the goal\n",
    "                elif self.maze[y][x] == 0:\n",
    "                    color = (255, 255, 255)  # White color for empty space\n",
    "                else:\n",
    "                    color = (0, 0, 0)  # Black color for walls\n",
    "                pygame.draw.rect(self.screen, color, rect)\n",
    "\n",
    "        # Draw the car\n",
    "        car_x, car_y = self.car_position\n",
    "        car_rect = pygame.Rect(car_x * self.cell_size, car_y * self.cell_size, self.cell_size, self.cell_size)\n",
    "        pygame.draw.rect(self.screen, (255, 0, 0), car_rect)  # Red color for the car\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(60)  # Limit the frame rate to 60 FPS\n",
    "\n",
    "\n",
    "    def close_pygame(self):\n",
    "        # Close the Pygame window\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.1, possible_actions=3, min_epsilon=0.01, epsilon_decay=0.99):\n",
    "        self.q_table = {}\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.possible_actions = possible_actions\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        \n",
    "\n",
    "    def state_to_tuple(self, state):\n",
    "        if not isinstance(state[2], dict):\n",
    "            #take state[2] and cast the state from this (1, 0, 0) to this {'front': 1, 'left': 0, 'right': 0}\n",
    "            newState = {'front': state[2][0], 'left': state[2][1], 'right': state[2][2]}\n",
    "            #create a new state with the [2] being the new dictionary\n",
    "            state = (state[0], state[1], newState)\n",
    "            \n",
    "        # Convert the state dictionary to a hashable tuple\n",
    "        position, orientation, sensor_readings = state\n",
    "        sensor_readings_tuple = tuple(sensor_readings.values())\n",
    "        return (position, orientation, sensor_readings_tuple)\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        state_tuple = self.state_to_tuple(state)\n",
    "        return self.q_table.get((state_tuple, action), 0)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(range(self.possible_actions))\n",
    "        else:\n",
    "            state_tuple = self.state_to_tuple(state)\n",
    "            q_values = [self.get_q_value(state_tuple, action) for action in range(self.possible_actions)]\n",
    "            max_q = max(q_values)\n",
    "            actions_with_max_q = [action for action, q in enumerate(q_values) if q == max_q]\n",
    "            return random.choice(actions_with_max_q)\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        state_tuple = self.state_to_tuple(state)\n",
    "        next_state_tuple = self.state_to_tuple(next_state)\n",
    "        max_q_next = max([self.get_q_value(next_state_tuple, next_action) for next_action in range(self.possible_actions)])\n",
    "        current_q = self.get_q_value(state_tuple, action)\n",
    "        new_q = current_q + self.alpha * (reward + self.gamma * max_q_next - current_q)\n",
    "        self.q_table[(state_tuple, action)] = new_q\n",
    "\n",
    "    def train(self, environment, num_episodes):\n",
    "        reward_history = []\n",
    "        for _ in range(num_episodes):\n",
    "            state = environment.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            while not done:\n",
    "                # environment.render()\n",
    "                action = self.choose_action(state)\n",
    "                next_state, reward, done = environment.step(action)\n",
    "                self.update_q_value(state, action, reward, next_state)\n",
    "                total_reward += reward\n",
    "                state = next_state\n",
    "\n",
    "            # Add the total reward for this episode to the history\n",
    "            reward_history.append(total_reward)\n",
    "\n",
    "            # Decay epsilon, but not below the minimum value\n",
    "            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "            # Print episode summary\n",
    "            print(\"Episode {} finished after {} timesteps\".format(_ ,environment.steps))\n",
    "            print(\"Total reward: {}, Epsilon: {:.3f}\".format(total_reward, self.epsilon))\n",
    "\n",
    "        return reward_history\n",
    "            \n",
    "    def test(self, env):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            env.render()\n",
    "            action = self.choose_action(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "\n",
    "        print(f\"Test Total Reward: {total_reward}\")\n",
    "\n",
    "# Example usage:\n",
    "# env = RCMazeEnv()\n",
    "# agent = QAgent()\n",
    "# agent.train(env, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 finished after 377 timesteps\n",
      "Total reward: 3611.910906924458, Epsilon: 0.900\n",
      "Episode 1 finished after 290 timesteps\n",
      "Total reward: 2670.070670213377, Epsilon: 0.900\n",
      "Episode 2 finished after 2213 timesteps\n",
      "Total reward: 14551.565386375196, Epsilon: 0.900\n",
      "Episode 3 finished after 1160 timesteps\n",
      "Total reward: 6720.595670143414, Epsilon: 0.900\n",
      "Episode 4 finished after 2591 timesteps\n",
      "Total reward: 13833.468144716137, Epsilon: 0.900\n",
      "Episode 5 finished after 3001 timesteps\n",
      "Total reward: 15020.246194388274, Epsilon: 0.899\n",
      "Episode 6 finished after 1473 timesteps\n",
      "Total reward: 8644.60585610632, Epsilon: 0.899\n",
      "Episode 7 finished after 477 timesteps\n",
      "Total reward: 3529.528257258595, Epsilon: 0.899\n",
      "Episode 8 finished after 1423 timesteps\n",
      "Total reward: 11837.981331829027, Epsilon: 0.899\n",
      "Episode 9 finished after 2439 timesteps\n",
      "Total reward: 13976.504609341604, Epsilon: 0.899\n",
      "Episode 10 finished after 343 timesteps\n",
      "Total reward: 3314.674301180361, Epsilon: 0.899\n",
      "Episode 11 finished after 3001 timesteps\n",
      "Total reward: 15202.7261811611, Epsilon: 0.899\n",
      "Episode 12 finished after 850 timesteps\n",
      "Total reward: 4669.949212156491, Epsilon: 0.899\n",
      "Episode 13 finished after 2456 timesteps\n",
      "Total reward: 14538.4424653438, Epsilon: 0.899\n",
      "Episode 14 finished after 467 timesteps\n",
      "Total reward: 3948.354542079919, Epsilon: 0.899\n",
      "Episode 15 finished after 853 timesteps\n",
      "Total reward: 5066.226905877464, Epsilon: 0.899\n",
      "Episode 16 finished after 2721 timesteps\n",
      "Total reward: 16514.684859610756, Epsilon: 0.898\n",
      "Episode 17 finished after 1256 timesteps\n",
      "Total reward: 6842.815609757448, Epsilon: 0.898\n",
      "Episode 18 finished after 622 timesteps\n",
      "Total reward: 4329.253064079881, Epsilon: 0.898\n",
      "Episode 19 finished after 1655 timesteps\n",
      "Total reward: 11674.531780698473, Epsilon: 0.898\n",
      "Episode 20 finished after 3001 timesteps\n",
      "Total reward: 15034.056836693153, Epsilon: 0.898\n",
      "Episode 21 finished after 583 timesteps\n",
      "Total reward: 4822.797429021505, Epsilon: 0.898\n",
      "Episode 22 finished after 2854 timesteps\n",
      "Total reward: 13592.837483489557, Epsilon: 0.898\n",
      "Episode 23 finished after 337 timesteps\n",
      "Total reward: 3378.099854820711, Epsilon: 0.898\n",
      "Episode 24 finished after 1269 timesteps\n",
      "Total reward: 7766.9906366826235, Epsilon: 0.898\n",
      "Episode 25 finished after 2536 timesteps\n",
      "Total reward: 12880.735972739278, Epsilon: 0.898\n",
      "Episode 26 finished after 3001 timesteps\n",
      "Total reward: 14581.367369882417, Epsilon: 0.898\n",
      "Episode 27 finished after 811 timesteps\n",
      "Total reward: 5099.366557660853, Epsilon: 0.897\n",
      "Episode 28 finished after 482 timesteps\n",
      "Total reward: 3507.4861373967574, Epsilon: 0.897\n",
      "Episode 29 finished after 1634 timesteps\n",
      "Total reward: 8432.091368133879, Epsilon: 0.897\n",
      "Episode 30 finished after 1605 timesteps\n",
      "Total reward: 11035.072508400393, Epsilon: 0.897\n",
      "Episode 31 finished after 473 timesteps\n",
      "Total reward: 3603.2696084498407, Epsilon: 0.897\n",
      "Episode 32 finished after 2275 timesteps\n",
      "Total reward: 13774.52030574594, Epsilon: 0.897\n",
      "Episode 33 finished after 1836 timesteps\n",
      "Total reward: 10738.33199032685, Epsilon: 0.897\n",
      "Episode 34 finished after 1480 timesteps\n",
      "Total reward: 9700.609950634102, Epsilon: 0.897\n",
      "Episode 35 finished after 411 timesteps\n",
      "Total reward: 3695.87465917528, Epsilon: 0.897\n",
      "Episode 36 finished after 3001 timesteps\n",
      "Total reward: 13506.788958779951, Epsilon: 0.897\n",
      "Episode 37 finished after 1503 timesteps\n",
      "Total reward: 9001.276648879619, Epsilon: 0.897\n",
      "Episode 38 finished after 890 timesteps\n",
      "Total reward: 5440.094093564346, Epsilon: 0.896\n",
      "Episode 39 finished after 2565 timesteps\n",
      "Total reward: 14478.32437760658, Epsilon: 0.896\n",
      "Episode 40 finished after 1011 timesteps\n",
      "Total reward: 5886.722433121991, Epsilon: 0.896\n",
      "Episode 41 finished after 1024 timesteps\n",
      "Total reward: 5617.9787405308525, Epsilon: 0.896\n",
      "Episode 42 finished after 2533 timesteps\n",
      "Total reward: 13868.581945355045, Epsilon: 0.896\n",
      "Episode 43 finished after 993 timesteps\n",
      "Total reward: 7237.172631088376, Epsilon: 0.896\n",
      "Episode 44 finished after 3001 timesteps\n",
      "Total reward: 17463.906822844874, Epsilon: 0.896\n",
      "Episode 45 finished after 808 timesteps\n",
      "Total reward: 5275.4172604617215, Epsilon: 0.896\n",
      "Episode 46 finished after 2630 timesteps\n",
      "Total reward: 15403.998011359026, Epsilon: 0.896\n",
      "Episode 47 finished after 3001 timesteps\n",
      "Total reward: 15202.668689400543, Epsilon: 0.896\n",
      "Episode 48 finished after 841 timesteps\n",
      "Total reward: 4928.958901649891, Epsilon: 0.896\n",
      "Episode 49 finished after 588 timesteps\n",
      "Total reward: 4183.388150509056, Epsilon: 0.896\n",
      "Episode 50 finished after 3001 timesteps\n",
      "Total reward: 13477.564272736283, Epsilon: 0.895\n",
      "Episode 51 finished after 1626 timesteps\n",
      "Total reward: 10809.126614675892, Epsilon: 0.895\n",
      "Episode 52 finished after 639 timesteps\n",
      "Total reward: 4076.1877207526936, Epsilon: 0.895\n",
      "Episode 53 finished after 3001 timesteps\n",
      "Total reward: 16485.049391021756, Epsilon: 0.895\n",
      "Episode 54 finished after 853 timesteps\n",
      "Total reward: 5546.8356674068355, Epsilon: 0.895\n",
      "Episode 55 finished after 1975 timesteps\n",
      "Total reward: 11798.947591966458, Epsilon: 0.895\n",
      "Episode 56 finished after 1214 timesteps\n",
      "Total reward: 10532.928588642839, Epsilon: 0.895\n",
      "Episode 57 finished after 1861 timesteps\n",
      "Total reward: 15563.302389948185, Epsilon: 0.895\n",
      "Episode 58 finished after 2112 timesteps\n",
      "Total reward: 11013.358164887219, Epsilon: 0.895\n",
      "Episode 59 finished after 569 timesteps\n",
      "Total reward: 4176.7289024804595, Epsilon: 0.895\n",
      "Episode 60 finished after 165 timesteps\n",
      "Total reward: 1873.482907041456, Epsilon: 0.895\n",
      "Episode 61 finished after 1247 timesteps\n",
      "Total reward: 7391.682014647145, Epsilon: 0.894\n",
      "Episode 62 finished after 3001 timesteps\n",
      "Total reward: 17259.20934941189, Epsilon: 0.894\n",
      "Episode 63 finished after 954 timesteps\n",
      "Total reward: 7282.9204637551575, Epsilon: 0.894\n",
      "Episode 64 finished after 2800 timesteps\n",
      "Total reward: 15974.751513820107, Epsilon: 0.894\n",
      "Episode 65 finished after 2067 timesteps\n",
      "Total reward: 13339.764151812826, Epsilon: 0.894\n",
      "Episode 66 finished after 225 timesteps\n",
      "Total reward: 2324.0943259048922, Epsilon: 0.894\n",
      "Episode 67 finished after 1596 timesteps\n",
      "Total reward: 7969.767978543762, Epsilon: 0.894\n",
      "Episode 68 finished after 901 timesteps\n",
      "Total reward: 4591.765570586189, Epsilon: 0.894\n",
      "Episode 69 finished after 1496 timesteps\n",
      "Total reward: 7675.543071143643, Epsilon: 0.894\n",
      "Episode 70 finished after 735 timesteps\n",
      "Total reward: 4848.925954731649, Epsilon: 0.894\n",
      "Episode 71 finished after 1376 timesteps\n",
      "Total reward: 7871.765355503937, Epsilon: 0.894\n",
      "Episode 72 finished after 724 timesteps\n",
      "Total reward: 5216.245702171969, Epsilon: 0.893\n",
      "Episode 73 finished after 2183 timesteps\n",
      "Total reward: 13252.543915831473, Epsilon: 0.893\n",
      "Episode 74 finished after 1953 timesteps\n",
      "Total reward: 10174.94883289909, Epsilon: 0.893\n",
      "Episode 75 finished after 87 timesteps\n",
      "Total reward: 1544.1743395387, Epsilon: 0.893\n",
      "Episode 76 finished after 1031 timesteps\n",
      "Total reward: 7042.767236780485, Epsilon: 0.893\n",
      "Episode 77 finished after 546 timesteps\n",
      "Total reward: 4585.96869520206, Epsilon: 0.893\n",
      "Episode 78 finished after 2580 timesteps\n",
      "Total reward: 14639.152062556843, Epsilon: 0.893\n",
      "Episode 79 finished after 3001 timesteps\n",
      "Total reward: 14769.566409083716, Epsilon: 0.893\n",
      "Episode 80 finished after 416 timesteps\n",
      "Total reward: 2970.8052056471133, Epsilon: 0.893\n",
      "Episode 81 finished after 1803 timesteps\n",
      "Total reward: 12240.083894461384, Epsilon: 0.893\n",
      "Episode 82 finished after 1212 timesteps\n",
      "Total reward: 6938.741720069861, Epsilon: 0.893\n",
      "Episode 83 finished after 501 timesteps\n",
      "Total reward: 4618.8117676181655, Epsilon: 0.892\n",
      "Episode 84 finished after 1052 timesteps\n",
      "Total reward: 7874.0836610602355, Epsilon: 0.892\n",
      "Episode 85 finished after 2080 timesteps\n",
      "Total reward: 13866.347190709705, Epsilon: 0.892\n",
      "Episode 86 finished after 580 timesteps\n",
      "Total reward: 3863.1409066341726, Epsilon: 0.892\n",
      "Episode 87 finished after 1337 timesteps\n",
      "Total reward: 7899.14076317066, Epsilon: 0.892\n",
      "Episode 88 finished after 1056 timesteps\n",
      "Total reward: 5798.31682196514, Epsilon: 0.892\n",
      "Episode 89 finished after 943 timesteps\n",
      "Total reward: 5283.702059594936, Epsilon: 0.892\n",
      "Episode 90 finished after 920 timesteps\n",
      "Total reward: 6474.003959985522, Epsilon: 0.892\n",
      "Episode 91 finished after 2501 timesteps\n",
      "Total reward: 14452.338643851199, Epsilon: 0.892\n",
      "Episode 92 finished after 828 timesteps\n",
      "Total reward: 5120.971873373143, Epsilon: 0.892\n",
      "Episode 93 finished after 1353 timesteps\n",
      "Total reward: 7807.550896821684, Epsilon: 0.892\n",
      "Episode 94 finished after 581 timesteps\n",
      "Total reward: 3885.2525134338725, Epsilon: 0.891\n",
      "Episode 95 finished after 866 timesteps\n",
      "Total reward: 6116.73399340468, Epsilon: 0.891\n",
      "Episode 96 finished after 3001 timesteps\n",
      "Total reward: 14306.186758956706, Epsilon: 0.891\n",
      "Episode 97 finished after 1267 timesteps\n",
      "Total reward: 7904.901965013727, Epsilon: 0.891\n",
      "Episode 98 finished after 2109 timesteps\n",
      "Total reward: 17982.80274342323, Epsilon: 0.891\n",
      "Episode 99 finished after 3001 timesteps\n",
      "Total reward: 14533.624150868907, Epsilon: 0.891\n",
      "Episode 100 finished after 688 timesteps\n",
      "Total reward: 4399.885546155622, Epsilon: 0.891\n",
      "Episode 101 finished after 1843 timesteps\n",
      "Total reward: 11021.764356873839, Epsilon: 0.891\n",
      "Episode 102 finished after 1136 timesteps\n",
      "Total reward: 6791.9109909655435, Epsilon: 0.891\n",
      "Episode 103 finished after 536 timesteps\n",
      "Total reward: 4092.574927813154, Epsilon: 0.891\n",
      "Episode 104 finished after 2534 timesteps\n",
      "Total reward: 19098.790307723197, Epsilon: 0.891\n",
      "Episode 105 finished after 3001 timesteps\n",
      "Total reward: 13256.11754968542, Epsilon: 0.891\n",
      "Episode 106 finished after 3001 timesteps\n",
      "Total reward: 15605.388805884873, Epsilon: 0.890\n",
      "Episode 107 finished after 2271 timesteps\n",
      "Total reward: 14614.959896972641, Epsilon: 0.890\n",
      "Episode 108 finished after 3001 timesteps\n",
      "Total reward: 20080.685920249594, Epsilon: 0.890\n",
      "Episode 109 finished after 3001 timesteps\n",
      "Total reward: 18182.78678344166, Epsilon: 0.890\n",
      "Episode 110 finished after 1248 timesteps\n",
      "Total reward: 7841.62222267462, Epsilon: 0.890\n",
      "Episode 111 finished after 3001 timesteps\n",
      "Total reward: 15446.93088549554, Epsilon: 0.890\n",
      "Episode 112 finished after 651 timesteps\n",
      "Total reward: 5925.643448495884, Epsilon: 0.890\n",
      "Episode 113 finished after 2865 timesteps\n",
      "Total reward: 14391.808793319233, Epsilon: 0.890\n",
      "Episode 114 finished after 259 timesteps\n",
      "Total reward: 2017.8470475539423, Epsilon: 0.890\n",
      "Episode 115 finished after 1236 timesteps\n",
      "Total reward: 6120.33810415608, Epsilon: 0.890\n",
      "Episode 116 finished after 3001 timesteps\n",
      "Total reward: 15739.390635163316, Epsilon: 0.890\n",
      "Episode 117 finished after 2149 timesteps\n",
      "Total reward: 11197.072164740652, Epsilon: 0.889\n",
      "Episode 118 finished after 599 timesteps\n",
      "Total reward: 4477.2823382500255, Epsilon: 0.889\n",
      "Episode 119 finished after 1378 timesteps\n",
      "Total reward: 8541.891779068945, Epsilon: 0.889\n",
      "Episode 120 finished after 1005 timesteps\n",
      "Total reward: 6984.876217032864, Epsilon: 0.889\n",
      "Episode 121 finished after 2468 timesteps\n",
      "Total reward: 12751.273780133988, Epsilon: 0.889\n",
      "Episode 122 finished after 1239 timesteps\n",
      "Total reward: 6244.263054711734, Epsilon: 0.889\n",
      "Episode 123 finished after 3001 timesteps\n",
      "Total reward: 17577.769819808433, Epsilon: 0.889\n",
      "Episode 124 finished after 1133 timesteps\n",
      "Total reward: 7417.48923569557, Epsilon: 0.889\n",
      "Episode 125 finished after 640 timesteps\n",
      "Total reward: 4785.278439612879, Epsilon: 0.889\n",
      "Episode 126 finished after 1219 timesteps\n",
      "Total reward: 6955.9206075536795, Epsilon: 0.889\n",
      "Episode 127 finished after 842 timesteps\n",
      "Total reward: 6453.686748687022, Epsilon: 0.889\n",
      "Episode 128 finished after 2287 timesteps\n",
      "Total reward: 14846.668427256334, Epsilon: 0.888\n",
      "Episode 129 finished after 2016 timesteps\n",
      "Total reward: 10852.266650635045, Epsilon: 0.888\n",
      "Episode 130 finished after 3001 timesteps\n",
      "Total reward: 14714.712828870835, Epsilon: 0.888\n",
      "Episode 131 finished after 3001 timesteps\n",
      "Total reward: 14870.352347459097, Epsilon: 0.888\n",
      "Episode 132 finished after 3001 timesteps\n",
      "Total reward: 16353.476596266135, Epsilon: 0.888\n",
      "Episode 133 finished after 1198 timesteps\n",
      "Total reward: 6261.974892745603, Epsilon: 0.888\n",
      "Episode 134 finished after 2024 timesteps\n",
      "Total reward: 11937.887188374196, Epsilon: 0.888\n",
      "Episode 135 finished after 735 timesteps\n",
      "Total reward: 6185.838397210409, Epsilon: 0.888\n",
      "Episode 136 finished after 1361 timesteps\n",
      "Total reward: 8006.5824936649715, Epsilon: 0.888\n",
      "Episode 137 finished after 878 timesteps\n",
      "Total reward: 5531.201271180531, Epsilon: 0.888\n",
      "Episode 138 finished after 3001 timesteps\n",
      "Total reward: 17324.558499393144, Epsilon: 0.888\n",
      "Episode 139 finished after 1379 timesteps\n",
      "Total reward: 8972.229189404896, Epsilon: 0.887\n",
      "Episode 140 finished after 1506 timesteps\n",
      "Total reward: 8693.517105787241, Epsilon: 0.887\n",
      "Episode 141 finished after 2130 timesteps\n",
      "Total reward: 12127.136849048195, Epsilon: 0.887\n",
      "Episode 142 finished after 558 timesteps\n",
      "Total reward: 4789.146591724661, Epsilon: 0.887\n",
      "Episode 143 finished after 503 timesteps\n",
      "Total reward: 3942.881411180422, Epsilon: 0.887\n",
      "Episode 144 finished after 664 timesteps\n",
      "Total reward: 3928.0787465331196, Epsilon: 0.887\n",
      "Episode 145 finished after 3001 timesteps\n",
      "Total reward: 13885.73925694643, Epsilon: 0.887\n",
      "Episode 146 finished after 962 timesteps\n",
      "Total reward: 6908.087283592578, Epsilon: 0.887\n",
      "Episode 147 finished after 357 timesteps\n",
      "Total reward: 2800.8657369681305, Epsilon: 0.887\n",
      "Episode 148 finished after 1941 timesteps\n",
      "Total reward: 11505.104202595941, Epsilon: 0.887\n",
      "Episode 149 finished after 3001 timesteps\n",
      "Total reward: 16462.155982897526, Epsilon: 0.887\n",
      "Episode 150 finished after 959 timesteps\n",
      "Total reward: 6288.707193647056, Epsilon: 0.887\n",
      "Episode 151 finished after 861 timesteps\n",
      "Total reward: 6123.781532445044, Epsilon: 0.886\n",
      "Episode 152 finished after 684 timesteps\n",
      "Total reward: 4654.347166898174, Epsilon: 0.886\n",
      "Episode 153 finished after 532 timesteps\n",
      "Total reward: 3445.643370780211, Epsilon: 0.886\n",
      "Episode 154 finished after 809 timesteps\n",
      "Total reward: 5722.769913043458, Epsilon: 0.886\n",
      "Episode 155 finished after 711 timesteps\n",
      "Total reward: 5226.602715670664, Epsilon: 0.886\n",
      "Episode 156 finished after 3001 timesteps\n",
      "Total reward: 15262.410994708154, Epsilon: 0.886\n",
      "Episode 157 finished after 2239 timesteps\n",
      "Total reward: 11442.240145575175, Epsilon: 0.886\n",
      "Episode 158 finished after 90 timesteps\n",
      "Total reward: 1393.466894205325, Epsilon: 0.886\n",
      "Episode 159 finished after 2566 timesteps\n",
      "Total reward: 13003.862400048527, Epsilon: 0.886\n",
      "Episode 160 finished after 1947 timesteps\n",
      "Total reward: 9721.384834559938, Epsilon: 0.886\n",
      "Episode 161 finished after 386 timesteps\n",
      "Total reward: 2810.9822505184247, Epsilon: 0.886\n",
      "Episode 162 finished after 3001 timesteps\n",
      "Total reward: 19548.735802000756, Epsilon: 0.885\n",
      "Episode 163 finished after 1753 timesteps\n",
      "Total reward: 9868.50226900508, Epsilon: 0.885\n",
      "Episode 164 finished after 185 timesteps\n",
      "Total reward: 2175.0769303511815, Epsilon: 0.885\n",
      "Episode 165 finished after 3001 timesteps\n",
      "Total reward: 15005.7272301983, Epsilon: 0.885\n",
      "Episode 166 finished after 484 timesteps\n",
      "Total reward: 3574.2797078735284, Epsilon: 0.885\n",
      "Episode 167 finished after 1693 timesteps\n",
      "Total reward: 10006.532627149896, Epsilon: 0.885\n",
      "Episode 168 finished after 893 timesteps\n",
      "Total reward: 5097.846843114834, Epsilon: 0.885\n",
      "Episode 169 finished after 410 timesteps\n",
      "Total reward: 3179.2140401603997, Epsilon: 0.885\n",
      "Episode 170 finished after 2291 timesteps\n",
      "Total reward: 16329.121096373983, Epsilon: 0.885\n",
      "Episode 171 finished after 854 timesteps\n",
      "Total reward: 5334.866639255541, Epsilon: 0.885\n",
      "Episode 172 finished after 1058 timesteps\n",
      "Total reward: 8851.130896787914, Epsilon: 0.885\n",
      "Episode 173 finished after 2374 timesteps\n",
      "Total reward: 17705.06594163448, Epsilon: 0.884\n",
      "Episode 174 finished after 3001 timesteps\n",
      "Total reward: 16499.428035122437, Epsilon: 0.884\n",
      "Episode 175 finished after 3001 timesteps\n",
      "Total reward: 16525.671676501082, Epsilon: 0.884\n",
      "Episode 176 finished after 725 timesteps\n",
      "Total reward: 4823.579832440483, Epsilon: 0.884\n",
      "Episode 177 finished after 553 timesteps\n",
      "Total reward: 5474.939565877854, Epsilon: 0.884\n",
      "Episode 178 finished after 482 timesteps\n",
      "Total reward: 3757.9792043234606, Epsilon: 0.884\n",
      "Episode 179 finished after 1366 timesteps\n",
      "Total reward: 10061.190353299082, Epsilon: 0.884\n",
      "Episode 180 finished after 2527 timesteps\n",
      "Total reward: 15081.022702454451, Epsilon: 0.884\n",
      "Episode 181 finished after 647 timesteps\n",
      "Total reward: 4623.493386555834, Epsilon: 0.884\n",
      "Episode 182 finished after 841 timesteps\n",
      "Total reward: 5881.697096750131, Epsilon: 0.884\n",
      "Episode 183 finished after 712 timesteps\n",
      "Total reward: 4643.784080773229, Epsilon: 0.884\n",
      "Episode 184 finished after 2928 timesteps\n",
      "Total reward: 15734.20506751909, Epsilon: 0.884\n",
      "Episode 185 finished after 3001 timesteps\n",
      "Total reward: 17378.267673983508, Epsilon: 0.883\n",
      "Episode 186 finished after 1946 timesteps\n",
      "Total reward: 13420.717725403074, Epsilon: 0.883\n",
      "Episode 187 finished after 2815 timesteps\n",
      "Total reward: 14193.391725032934, Epsilon: 0.883\n",
      "Episode 188 finished after 2127 timesteps\n",
      "Total reward: 10950.158946816855, Epsilon: 0.883\n",
      "Episode 189 finished after 3001 timesteps\n",
      "Total reward: 14113.627588684405, Epsilon: 0.883\n",
      "Episode 190 finished after 213 timesteps\n",
      "Total reward: 2099.9969854187257, Epsilon: 0.883\n",
      "Episode 191 finished after 1877 timesteps\n",
      "Total reward: 10172.564780389033, Epsilon: 0.883\n",
      "Episode 192 finished after 3001 timesteps\n",
      "Total reward: 14442.70389756701, Epsilon: 0.883\n",
      "Episode 193 finished after 1332 timesteps\n",
      "Total reward: 6686.6539755489985, Epsilon: 0.883\n",
      "Episode 194 finished after 1126 timesteps\n",
      "Total reward: 7227.3215923281, Epsilon: 0.883\n",
      "Episode 195 finished after 1004 timesteps\n",
      "Total reward: 7602.7238832310795, Epsilon: 0.883\n",
      "Episode 196 finished after 750 timesteps\n",
      "Total reward: 5683.997316111861, Epsilon: 0.882\n",
      "Episode 197 finished after 1103 timesteps\n",
      "Total reward: 6737.010115895688, Epsilon: 0.882\n",
      "Episode 198 finished after 1141 timesteps\n",
      "Total reward: 8150.358048378475, Epsilon: 0.882\n",
      "Episode 199 finished after 3001 timesteps\n",
      "Total reward: 14183.913807426963, Epsilon: 0.882\n",
      "Episode 200 finished after 862 timesteps\n",
      "Total reward: 5135.241442018963, Epsilon: 0.882\n",
      "Episode 201 finished after 2705 timesteps\n",
      "Total reward: 17904.23562100603, Epsilon: 0.882\n",
      "Episode 202 finished after 1704 timesteps\n",
      "Total reward: 9660.842575172303, Epsilon: 0.882\n",
      "Episode 203 finished after 598 timesteps\n",
      "Total reward: 4331.969128553314, Epsilon: 0.882\n",
      "Episode 204 finished after 3001 timesteps\n",
      "Total reward: 18939.76482236559, Epsilon: 0.882\n",
      "Episode 205 finished after 588 timesteps\n",
      "Total reward: 4427.347751113346, Epsilon: 0.882\n",
      "Episode 206 finished after 1202 timesteps\n",
      "Total reward: 6934.328730351005, Epsilon: 0.882\n",
      "Episode 207 finished after 3001 timesteps\n",
      "Total reward: 15742.302503457184, Epsilon: 0.881\n",
      "Episode 208 finished after 1853 timesteps\n",
      "Total reward: 10918.965377036177, Epsilon: 0.881\n",
      "Episode 209 finished after 1068 timesteps\n",
      "Total reward: 5905.015643035413, Epsilon: 0.881\n",
      "Episode 210 finished after 1962 timesteps\n",
      "Total reward: 10537.652437012119, Epsilon: 0.881\n",
      "Episode 211 finished after 2030 timesteps\n",
      "Total reward: 10590.649161602887, Epsilon: 0.881\n",
      "Episode 212 finished after 2157 timesteps\n",
      "Total reward: 11901.347394471226, Epsilon: 0.881\n",
      "Episode 213 finished after 1397 timesteps\n",
      "Total reward: 7338.987709726261, Epsilon: 0.881\n",
      "Episode 214 finished after 2989 timesteps\n",
      "Total reward: 16058.73644488606, Epsilon: 0.881\n",
      "Episode 215 finished after 1016 timesteps\n",
      "Total reward: 6788.6246242758725, Epsilon: 0.881\n",
      "Episode 216 finished after 1448 timesteps\n",
      "Total reward: 7855.9223605541765, Epsilon: 0.881\n",
      "Episode 217 finished after 347 timesteps\n",
      "Total reward: 2871.9733927674465, Epsilon: 0.881\n",
      "Episode 218 finished after 3001 timesteps\n",
      "Total reward: 19349.97966391161, Epsilon: 0.881\n",
      "Episode 219 finished after 1977 timesteps\n",
      "Total reward: 12590.55714935132, Epsilon: 0.880\n",
      "Episode 220 finished after 2600 timesteps\n",
      "Total reward: 13851.688697529906, Epsilon: 0.880\n",
      "Episode 221 finished after 908 timesteps\n",
      "Total reward: 6654.526370041148, Epsilon: 0.880\n",
      "Episode 222 finished after 402 timesteps\n",
      "Total reward: 3272.7720030675237, Epsilon: 0.880\n",
      "Episode 223 finished after 1114 timesteps\n",
      "Total reward: 6568.519646846183, Epsilon: 0.880\n",
      "Episode 224 finished after 3001 timesteps\n",
      "Total reward: 13694.150970511686, Epsilon: 0.880\n",
      "Episode 225 finished after 323 timesteps\n",
      "Total reward: 2805.1262163464253, Epsilon: 0.880\n",
      "Episode 226 finished after 1523 timesteps\n",
      "Total reward: 8435.644180244826, Epsilon: 0.880\n",
      "Episode 227 finished after 1983 timesteps\n",
      "Total reward: 11408.27071068356, Epsilon: 0.880\n",
      "Episode 228 finished after 550 timesteps\n",
      "Total reward: 4827.8326791163245, Epsilon: 0.880\n",
      "Episode 229 finished after 1285 timesteps\n",
      "Total reward: 7954.4883891347645, Epsilon: 0.880\n",
      "Episode 230 finished after 2390 timesteps\n",
      "Total reward: 14229.247574655828, Epsilon: 0.879\n",
      "Episode 231 finished after 1232 timesteps\n",
      "Total reward: 7702.0818397774265, Epsilon: 0.879\n",
      "Episode 232 finished after 3001 timesteps\n",
      "Total reward: 15358.925743168043, Epsilon: 0.879\n",
      "Episode 233 finished after 939 timesteps\n",
      "Total reward: 7785.278344551004, Epsilon: 0.879\n",
      "Episode 234 finished after 1068 timesteps\n",
      "Total reward: 7248.557153259719, Epsilon: 0.879\n",
      "Episode 235 finished after 308 timesteps\n",
      "Total reward: 2424.172857298977, Epsilon: 0.879\n",
      "Episode 236 finished after 805 timesteps\n",
      "Total reward: 4197.485186834005, Epsilon: 0.879\n",
      "Episode 237 finished after 1753 timesteps\n",
      "Total reward: 10035.48370571224, Epsilon: 0.879\n",
      "Episode 238 finished after 1819 timesteps\n",
      "Total reward: 10573.486167700812, Epsilon: 0.879\n",
      "Episode 239 finished after 2444 timesteps\n",
      "Total reward: 14686.591493669861, Epsilon: 0.879\n",
      "Episode 240 finished after 1152 timesteps\n",
      "Total reward: 7393.149566407877, Epsilon: 0.879\n",
      "Episode 241 finished after 3001 timesteps\n",
      "Total reward: 16306.110872366486, Epsilon: 0.878\n",
      "Episode 242 finished after 1979 timesteps\n",
      "Total reward: 10687.49764217867, Epsilon: 0.878\n",
      "Episode 243 finished after 1775 timesteps\n",
      "Total reward: 11821.086275018592, Epsilon: 0.878\n",
      "Episode 244 finished after 3001 timesteps\n",
      "Total reward: 13264.208139728436, Epsilon: 0.878\n",
      "Episode 245 finished after 2204 timesteps\n",
      "Total reward: 13689.988822170815, Epsilon: 0.878\n",
      "Episode 246 finished after 1258 timesteps\n",
      "Total reward: 6409.544854053875, Epsilon: 0.878\n",
      "Episode 247 finished after 1163 timesteps\n",
      "Total reward: 7569.836303217681, Epsilon: 0.878\n",
      "Episode 248 finished after 889 timesteps\n",
      "Total reward: 5164.689727723921, Epsilon: 0.878\n",
      "Episode 249 finished after 2760 timesteps\n",
      "Total reward: 13300.910989649281, Epsilon: 0.878\n",
      "Episode 250 finished after 1682 timesteps\n",
      "Total reward: 9421.199959906338, Epsilon: 0.878\n",
      "Episode 251 finished after 1627 timesteps\n",
      "Total reward: 10885.371643862594, Epsilon: 0.878\n",
      "Episode 252 finished after 1388 timesteps\n",
      "Total reward: 6637.994064530084, Epsilon: 0.878\n",
      "Episode 253 finished after 3001 timesteps\n",
      "Total reward: 19350.49536809509, Epsilon: 0.877\n",
      "Episode 254 finished after 1478 timesteps\n",
      "Total reward: 10064.975771150663, Epsilon: 0.877\n",
      "Episode 255 finished after 994 timesteps\n",
      "Total reward: 5502.76716039932, Epsilon: 0.877\n",
      "Episode 256 finished after 2065 timesteps\n",
      "Total reward: 11885.383555501074, Epsilon: 0.877\n",
      "Episode 257 finished after 686 timesteps\n",
      "Total reward: 5699.344882539129, Epsilon: 0.877\n",
      "Episode 258 finished after 485 timesteps\n",
      "Total reward: 3224.501062536285, Epsilon: 0.877\n",
      "Episode 259 finished after 3001 timesteps\n",
      "Total reward: 15673.749195335273, Epsilon: 0.877\n",
      "Episode 260 finished after 2835 timesteps\n",
      "Total reward: 14201.669191714036, Epsilon: 0.877\n",
      "Episode 261 finished after 689 timesteps\n",
      "Total reward: 5550.572144462873, Epsilon: 0.877\n",
      "Episode 262 finished after 324 timesteps\n",
      "Total reward: 3506.516759322232, Epsilon: 0.877\n",
      "Episode 263 finished after 3001 timesteps\n",
      "Total reward: 14022.80868689841, Epsilon: 0.877\n",
      "Episode 264 finished after 3001 timesteps\n",
      "Total reward: 15087.922092795165, Epsilon: 0.876\n",
      "Episode 265 finished after 1846 timesteps\n",
      "Total reward: 11536.078674705566, Epsilon: 0.876\n",
      "Episode 266 finished after 951 timesteps\n",
      "Total reward: 6880.848641265819, Epsilon: 0.876\n",
      "Episode 267 finished after 3001 timesteps\n",
      "Total reward: 16778.628094644882, Epsilon: 0.876\n",
      "Episode 268 finished after 2973 timesteps\n",
      "Total reward: 16996.49266969965, Epsilon: 0.876\n",
      "Episode 269 finished after 1233 timesteps\n",
      "Total reward: 6841.414717239667, Epsilon: 0.876\n",
      "Episode 270 finished after 935 timesteps\n",
      "Total reward: 6297.850553707083, Epsilon: 0.876\n",
      "Episode 271 finished after 1037 timesteps\n",
      "Total reward: 6858.375986161093, Epsilon: 0.876\n",
      "Episode 272 finished after 492 timesteps\n",
      "Total reward: 3661.2351590735507, Epsilon: 0.876\n",
      "Episode 273 finished after 2918 timesteps\n",
      "Total reward: 15471.941216554691, Epsilon: 0.876\n",
      "Episode 274 finished after 3001 timesteps\n",
      "Total reward: 14508.222671447025, Epsilon: 0.876\n",
      "Episode 275 finished after 428 timesteps\n",
      "Total reward: 2917.552147910903, Epsilon: 0.875\n",
      "Episode 276 finished after 1973 timesteps\n",
      "Total reward: 10863.266670472292, Epsilon: 0.875\n",
      "Episode 277 finished after 2520 timesteps\n",
      "Total reward: 15381.65499528314, Epsilon: 0.875\n",
      "Episode 278 finished after 3001 timesteps\n",
      "Total reward: 17093.644637603087, Epsilon: 0.875\n",
      "Episode 279 finished after 2882 timesteps\n",
      "Total reward: 17407.112308400003, Epsilon: 0.875\n",
      "Episode 280 finished after 544 timesteps\n",
      "Total reward: 4779.621084135463, Epsilon: 0.875\n",
      "Episode 281 finished after 322 timesteps\n",
      "Total reward: 2254.602253653899, Epsilon: 0.875\n",
      "Episode 282 finished after 381 timesteps\n",
      "Total reward: 2950.383208241953, Epsilon: 0.875\n",
      "Episode 283 finished after 1689 timesteps\n",
      "Total reward: 10436.792499845375, Epsilon: 0.875\n",
      "Episode 284 finished after 1198 timesteps\n",
      "Total reward: 7510.844171020293, Epsilon: 0.875\n",
      "Episode 285 finished after 3001 timesteps\n",
      "Total reward: 15050.986546331413, Epsilon: 0.875\n",
      "Episode 286 finished after 1795 timesteps\n",
      "Total reward: 10218.881362557571, Epsilon: 0.875\n",
      "Episode 287 finished after 2686 timesteps\n",
      "Total reward: 13957.478643529501, Epsilon: 0.874\n",
      "Episode 288 finished after 1051 timesteps\n",
      "Total reward: 5995.962777112378, Epsilon: 0.874\n",
      "Episode 289 finished after 892 timesteps\n",
      "Total reward: 5390.043166087903, Epsilon: 0.874\n",
      "Episode 290 finished after 3001 timesteps\n",
      "Total reward: 17148.271546055155, Epsilon: 0.874\n",
      "Episode 291 finished after 406 timesteps\n",
      "Total reward: 3862.2396682975573, Epsilon: 0.874\n",
      "Episode 292 finished after 2907 timesteps\n",
      "Total reward: 15185.285861521463, Epsilon: 0.874\n",
      "Episode 293 finished after 2302 timesteps\n",
      "Total reward: 14558.75938971557, Epsilon: 0.874\n",
      "Episode 294 finished after 2158 timesteps\n",
      "Total reward: 12395.866593835963, Epsilon: 0.874\n",
      "Episode 295 finished after 3001 timesteps\n",
      "Total reward: 21266.745655484538, Epsilon: 0.874\n",
      "Episode 296 finished after 3001 timesteps\n",
      "Total reward: 15196.032395558688, Epsilon: 0.874\n",
      "Episode 297 finished after 853 timesteps\n",
      "Total reward: 5284.571314835232, Epsilon: 0.874\n",
      "Episode 298 finished after 1218 timesteps\n",
      "Total reward: 7306.583024104694, Epsilon: 0.873\n",
      "Episode 299 finished after 837 timesteps\n",
      "Total reward: 5027.330117068325, Epsilon: 0.873\n",
      "Episode 300 finished after 2633 timesteps\n",
      "Total reward: 13973.94412233178, Epsilon: 0.873\n",
      "Episode 301 finished after 853 timesteps\n",
      "Total reward: 6651.17645772752, Epsilon: 0.873\n",
      "Episode 302 finished after 617 timesteps\n",
      "Total reward: 4570.139454658586, Epsilon: 0.873\n",
      "Episode 303 finished after 340 timesteps\n",
      "Total reward: 2627.637271767315, Epsilon: 0.873\n",
      "Episode 304 finished after 687 timesteps\n",
      "Total reward: 5830.921763549383, Epsilon: 0.873\n",
      "Episode 305 finished after 2995 timesteps\n",
      "Total reward: 16240.00997741488, Epsilon: 0.873\n",
      "Episode 306 finished after 1229 timesteps\n",
      "Total reward: 8190.323012661418, Epsilon: 0.873\n",
      "Episode 307 finished after 2873 timesteps\n",
      "Total reward: 14890.267237414706, Epsilon: 0.873\n",
      "Episode 308 finished after 714 timesteps\n",
      "Total reward: 6661.024922987495, Epsilon: 0.873\n",
      "Episode 309 finished after 1347 timesteps\n",
      "Total reward: 8542.361382710253, Epsilon: 0.873\n",
      "Episode 310 finished after 489 timesteps\n",
      "Total reward: 3558.8101511109244, Epsilon: 0.872\n",
      "Episode 311 finished after 1118 timesteps\n",
      "Total reward: 7892.074755829695, Epsilon: 0.872\n",
      "Episode 312 finished after 442 timesteps\n",
      "Total reward: 3378.935876561314, Epsilon: 0.872\n",
      "Episode 313 finished after 2166 timesteps\n",
      "Total reward: 12711.945472980133, Epsilon: 0.872\n",
      "Episode 314 finished after 1240 timesteps\n",
      "Total reward: 8093.518598517865, Epsilon: 0.872\n",
      "Episode 315 finished after 699 timesteps\n",
      "Total reward: 5318.7579651171145, Epsilon: 0.872\n",
      "Episode 316 finished after 3001 timesteps\n",
      "Total reward: 16617.48137953139, Epsilon: 0.872\n",
      "Episode 317 finished after 912 timesteps\n",
      "Total reward: 6901.215223212965, Epsilon: 0.872\n",
      "Episode 318 finished after 356 timesteps\n",
      "Total reward: 2760.590058084767, Epsilon: 0.872\n",
      "Episode 319 finished after 1038 timesteps\n",
      "Total reward: 6420.847306984926, Epsilon: 0.872\n",
      "Episode 320 finished after 2127 timesteps\n",
      "Total reward: 12363.22223809638, Epsilon: 0.872\n",
      "Episode 321 finished after 3001 timesteps\n",
      "Total reward: 17511.02221971517, Epsilon: 0.871\n",
      "Episode 322 finished after 256 timesteps\n",
      "Total reward: 2192.2144240530065, Epsilon: 0.871\n",
      "Episode 323 finished after 751 timesteps\n",
      "Total reward: 5011.503586104473, Epsilon: 0.871\n",
      "Episode 324 finished after 3001 timesteps\n",
      "Total reward: 17990.608524294224, Epsilon: 0.871\n",
      "Episode 325 finished after 3001 timesteps\n",
      "Total reward: 14682.755548669951, Epsilon: 0.871\n",
      "Episode 326 finished after 1183 timesteps\n",
      "Total reward: 6273.180809044064, Epsilon: 0.871\n",
      "Episode 327 finished after 1507 timesteps\n",
      "Total reward: 10386.167317899955, Epsilon: 0.871\n",
      "Episode 328 finished after 3001 timesteps\n",
      "Total reward: 15218.084456270008, Epsilon: 0.871\n",
      "Episode 329 finished after 1326 timesteps\n",
      "Total reward: 6726.63436952795, Epsilon: 0.871\n",
      "Episode 330 finished after 2786 timesteps\n",
      "Total reward: 14898.42730519646, Epsilon: 0.871\n",
      "Episode 331 finished after 689 timesteps\n",
      "Total reward: 6250.280949445799, Epsilon: 0.871\n",
      "Episode 332 finished after 344 timesteps\n",
      "Total reward: 2861.191211607608, Epsilon: 0.871\n",
      "Episode 333 finished after 336 timesteps\n",
      "Total reward: 2573.5973375122667, Epsilon: 0.870\n",
      "Episode 334 finished after 666 timesteps\n",
      "Total reward: 4919.252084990758, Epsilon: 0.870\n",
      "Episode 335 finished after 963 timesteps\n",
      "Total reward: 7669.140641516623, Epsilon: 0.870\n",
      "Episode 336 finished after 2373 timesteps\n",
      "Total reward: 11926.277678476745, Epsilon: 0.870\n",
      "Episode 337 finished after 3001 timesteps\n",
      "Total reward: 15870.189584827385, Epsilon: 0.870\n",
      "Episode 338 finished after 916 timesteps\n",
      "Total reward: 6153.298636713712, Epsilon: 0.870\n",
      "Episode 339 finished after 1877 timesteps\n",
      "Total reward: 12581.843352588236, Epsilon: 0.870\n",
      "Episode 340 finished after 1532 timesteps\n",
      "Total reward: 9192.193558647376, Epsilon: 0.870\n",
      "Episode 341 finished after 2331 timesteps\n",
      "Total reward: 14195.27131219755, Epsilon: 0.870\n",
      "Episode 342 finished after 2451 timesteps\n",
      "Total reward: 15466.572108207874, Epsilon: 0.870\n",
      "Episode 343 finished after 678 timesteps\n",
      "Total reward: 4811.10827601031, Epsilon: 0.870\n",
      "Episode 344 finished after 3001 timesteps\n",
      "Total reward: 16606.05808815555, Epsilon: 0.869\n",
      "Episode 345 finished after 852 timesteps\n",
      "Total reward: 4436.986380371978, Epsilon: 0.869\n",
      "Episode 346 finished after 3001 timesteps\n",
      "Total reward: 18165.41827963089, Epsilon: 0.869\n",
      "Episode 347 finished after 2918 timesteps\n",
      "Total reward: 15655.405843645789, Epsilon: 0.869\n",
      "Episode 348 finished after 3001 timesteps\n",
      "Total reward: 15230.760429945238, Epsilon: 0.869\n",
      "Episode 349 finished after 1924 timesteps\n",
      "Total reward: 9682.461245316004, Epsilon: 0.869\n",
      "Episode 350 finished after 1435 timesteps\n",
      "Total reward: 8573.7625256802, Epsilon: 0.869\n",
      "Episode 351 finished after 1360 timesteps\n",
      "Total reward: 6686.806910093881, Epsilon: 0.869\n",
      "Episode 352 finished after 2196 timesteps\n",
      "Total reward: 14706.149991801423, Epsilon: 0.869\n",
      "Episode 353 finished after 328 timesteps\n",
      "Total reward: 3204.641671052874, Epsilon: 0.869\n",
      "Episode 354 finished after 1406 timesteps\n",
      "Total reward: 10480.49533104935, Epsilon: 0.869\n",
      "Episode 355 finished after 3001 timesteps\n",
      "Total reward: 14236.103728900156, Epsilon: 0.869\n",
      "Episode 356 finished after 1042 timesteps\n",
      "Total reward: 8712.228542255949, Epsilon: 0.868\n",
      "Episode 357 finished after 463 timesteps\n",
      "Total reward: 4178.796568619613, Epsilon: 0.868\n",
      "Episode 358 finished after 930 timesteps\n",
      "Total reward: 6762.4192090576025, Epsilon: 0.868\n",
      "Episode 359 finished after 3001 timesteps\n",
      "Total reward: 16027.025028270346, Epsilon: 0.868\n",
      "Episode 360 finished after 1235 timesteps\n",
      "Total reward: 6996.615429649956, Epsilon: 0.868\n",
      "Episode 361 finished after 483 timesteps\n",
      "Total reward: 4919.619134027135, Epsilon: 0.868\n",
      "Episode 362 finished after 3001 timesteps\n",
      "Total reward: 16550.301532232756, Epsilon: 0.868\n",
      "Episode 363 finished after 817 timesteps\n",
      "Total reward: 4707.689304618614, Epsilon: 0.868\n",
      "Episode 364 finished after 798 timesteps\n",
      "Total reward: 6640.469961959046, Epsilon: 0.868\n",
      "Episode 365 finished after 761 timesteps\n",
      "Total reward: 5477.1022362680305, Epsilon: 0.868\n",
      "Episode 366 finished after 3001 timesteps\n",
      "Total reward: 17203.37809569968, Epsilon: 0.868\n",
      "Episode 367 finished after 1370 timesteps\n",
      "Total reward: 7133.223586022938, Epsilon: 0.867\n",
      "Episode 368 finished after 455 timesteps\n",
      "Total reward: 4793.333265433119, Epsilon: 0.867\n",
      "Episode 369 finished after 1204 timesteps\n",
      "Total reward: 8051.100289273934, Epsilon: 0.867\n",
      "Episode 370 finished after 3001 timesteps\n",
      "Total reward: 16659.54399263553, Epsilon: 0.867\n",
      "Episode 371 finished after 2433 timesteps\n",
      "Total reward: 12483.396324712403, Epsilon: 0.867\n",
      "Episode 372 finished after 1089 timesteps\n",
      "Total reward: 7347.972709719441, Epsilon: 0.867\n",
      "Episode 373 finished after 147 timesteps\n",
      "Total reward: 1693.3259659109517, Epsilon: 0.867\n",
      "Episode 374 finished after 3001 timesteps\n",
      "Total reward: 14669.958007248668, Epsilon: 0.867\n",
      "Episode 375 finished after 3001 timesteps\n",
      "Total reward: 15052.560527211848, Epsilon: 0.867\n",
      "Episode 376 finished after 2073 timesteps\n",
      "Total reward: 10519.643112871589, Epsilon: 0.867\n",
      "Episode 377 finished after 3001 timesteps\n",
      "Total reward: 13100.96410900855, Epsilon: 0.867\n",
      "Episode 378 finished after 1387 timesteps\n",
      "Total reward: 7201.792369510385, Epsilon: 0.867\n",
      "Episode 379 finished after 926 timesteps\n",
      "Total reward: 6634.794702341675, Epsilon: 0.866\n",
      "Episode 380 finished after 1630 timesteps\n",
      "Total reward: 10026.347885990881, Epsilon: 0.866\n",
      "Episode 381 finished after 401 timesteps\n",
      "Total reward: 4496.016872039509, Epsilon: 0.866\n",
      "Episode 382 finished after 3001 timesteps\n",
      "Total reward: 17556.644305257294, Epsilon: 0.866\n",
      "Episode 383 finished after 2258 timesteps\n",
      "Total reward: 11922.404082716732, Epsilon: 0.866\n",
      "Episode 384 finished after 1051 timesteps\n",
      "Total reward: 6814.342221302221, Epsilon: 0.866\n",
      "Episode 385 finished after 965 timesteps\n",
      "Total reward: 5661.446679036208, Epsilon: 0.866\n",
      "Episode 386 finished after 1420 timesteps\n",
      "Total reward: 8881.401597256016, Epsilon: 0.866\n",
      "Episode 387 finished after 1676 timesteps\n",
      "Total reward: 13518.103505249732, Epsilon: 0.866\n",
      "Episode 388 finished after 1474 timesteps\n",
      "Total reward: 9224.124180762867, Epsilon: 0.866\n",
      "Episode 389 finished after 2822 timesteps\n",
      "Total reward: 15868.044472946154, Epsilon: 0.866\n",
      "Episode 390 finished after 2403 timesteps\n",
      "Total reward: 13982.975192163907, Epsilon: 0.865\n",
      "Episode 391 finished after 3001 timesteps\n",
      "Total reward: 19636.863838035708, Epsilon: 0.865\n",
      "Episode 392 finished after 794 timesteps\n",
      "Total reward: 6342.79663861576, Epsilon: 0.865\n",
      "Episode 393 finished after 650 timesteps\n",
      "Total reward: 4564.916599147072, Epsilon: 0.865\n",
      "Episode 394 finished after 1444 timesteps\n",
      "Total reward: 8609.795568489759, Epsilon: 0.865\n",
      "Episode 395 finished after 1970 timesteps\n",
      "Total reward: 11960.219422673732, Epsilon: 0.865\n",
      "Episode 396 finished after 1980 timesteps\n",
      "Total reward: 12171.588256270867, Epsilon: 0.865\n",
      "Episode 397 finished after 1626 timesteps\n",
      "Total reward: 8432.797683592751, Epsilon: 0.865\n",
      "Episode 398 finished after 3001 timesteps\n",
      "Total reward: 16484.037860353055, Epsilon: 0.865\n",
      "Episode 399 finished after 3001 timesteps\n",
      "Total reward: 16910.94833062545, Epsilon: 0.865\n",
      "Episode 400 finished after 1111 timesteps\n",
      "Total reward: 6146.80756844739, Epsilon: 0.865\n",
      "Episode 401 finished after 428 timesteps\n",
      "Total reward: 3295.396039983111, Epsilon: 0.865\n",
      "Episode 402 finished after 1571 timesteps\n",
      "Total reward: 8675.33333980092, Epsilon: 0.864\n",
      "Episode 403 finished after 3001 timesteps\n",
      "Total reward: 16831.923408593226, Epsilon: 0.864\n",
      "Episode 404 finished after 485 timesteps\n",
      "Total reward: 4513.922564713107, Epsilon: 0.864\n",
      "Episode 405 finished after 3001 timesteps\n",
      "Total reward: 15611.654623157932, Epsilon: 0.864\n",
      "Episode 406 finished after 3001 timesteps\n",
      "Total reward: 14828.192492305272, Epsilon: 0.864\n",
      "Episode 407 finished after 3001 timesteps\n",
      "Total reward: 14573.081875127, Epsilon: 0.864\n",
      "Episode 408 finished after 703 timesteps\n",
      "Total reward: 4679.400636425892, Epsilon: 0.864\n",
      "Episode 409 finished after 1544 timesteps\n",
      "Total reward: 8852.4891263827, Epsilon: 0.864\n",
      "Episode 410 finished after 1050 timesteps\n",
      "Total reward: 7359.074620199683, Epsilon: 0.864\n",
      "Episode 411 finished after 1064 timesteps\n",
      "Total reward: 5986.46448653501, Epsilon: 0.864\n",
      "Episode 412 finished after 954 timesteps\n",
      "Total reward: 7106.504046337193, Epsilon: 0.864\n",
      "Episode 413 finished after 1748 timesteps\n",
      "Total reward: 9174.775306932723, Epsilon: 0.863\n",
      "Episode 414 finished after 3001 timesteps\n",
      "Total reward: 16570.91939335753, Epsilon: 0.863\n",
      "Episode 415 finished after 2451 timesteps\n",
      "Total reward: 14052.898229934379, Epsilon: 0.863\n",
      "Episode 416 finished after 2102 timesteps\n",
      "Total reward: 11900.750307126025, Epsilon: 0.863\n",
      "Episode 417 finished after 757 timesteps\n",
      "Total reward: 4017.4321846858147, Epsilon: 0.863\n",
      "Episode 418 finished after 2765 timesteps\n",
      "Total reward: 15655.338035577872, Epsilon: 0.863\n",
      "Episode 419 finished after 2725 timesteps\n",
      "Total reward: 19849.494375201735, Epsilon: 0.863\n",
      "Episode 420 finished after 255 timesteps\n",
      "Total reward: 2414.0589170017447, Epsilon: 0.863\n",
      "Episode 421 finished after 1099 timesteps\n",
      "Total reward: 6802.557710832873, Epsilon: 0.863\n",
      "Episode 422 finished after 2392 timesteps\n",
      "Total reward: 16545.17891263683, Epsilon: 0.863\n",
      "Episode 423 finished after 159 timesteps\n",
      "Total reward: 1911.0068169073459, Epsilon: 0.863\n",
      "Episode 424 finished after 1367 timesteps\n",
      "Total reward: 8217.389535576645, Epsilon: 0.863\n",
      "Episode 425 finished after 2906 timesteps\n",
      "Total reward: 16367.872410197444, Epsilon: 0.862\n",
      "Episode 426 finished after 368 timesteps\n",
      "Total reward: 3503.0289998530893, Epsilon: 0.862\n",
      "Episode 427 finished after 1135 timesteps\n",
      "Total reward: 6135.691545272473, Epsilon: 0.862\n",
      "Episode 428 finished after 775 timesteps\n",
      "Total reward: 5501.159456179296, Epsilon: 0.862\n",
      "Episode 429 finished after 220 timesteps\n",
      "Total reward: 2113.826754882335, Epsilon: 0.862\n",
      "Episode 430 finished after 2893 timesteps\n",
      "Total reward: 17965.267369031124, Epsilon: 0.862\n",
      "Episode 431 finished after 1518 timesteps\n",
      "Total reward: 7392.290792626321, Epsilon: 0.862\n",
      "Episode 432 finished after 2066 timesteps\n",
      "Total reward: 12540.536576435627, Epsilon: 0.862\n",
      "Episode 433 finished after 3001 timesteps\n",
      "Total reward: 14868.942848513569, Epsilon: 0.862\n",
      "Episode 434 finished after 1720 timesteps\n",
      "Total reward: 12851.788638473825, Epsilon: 0.862\n",
      "Episode 435 finished after 1439 timesteps\n",
      "Total reward: 8149.407958074433, Epsilon: 0.862\n",
      "Episode 436 finished after 3001 timesteps\n",
      "Total reward: 14347.567565091611, Epsilon: 0.862\n",
      "Episode 437 finished after 3001 timesteps\n",
      "Total reward: 16145.589281498778, Epsilon: 0.861\n",
      "Episode 438 finished after 1183 timesteps\n",
      "Total reward: 8791.610736656125, Epsilon: 0.861\n",
      "Episode 439 finished after 1637 timesteps\n",
      "Total reward: 9025.547019468182, Epsilon: 0.861\n",
      "Episode 440 finished after 2182 timesteps\n",
      "Total reward: 12305.280957378971, Epsilon: 0.861\n",
      "Episode 441 finished after 2322 timesteps\n",
      "Total reward: 14590.157184593158, Epsilon: 0.861\n",
      "Episode 442 finished after 3001 timesteps\n",
      "Total reward: 17696.021394928128, Epsilon: 0.861\n",
      "Episode 443 finished after 1614 timesteps\n",
      "Total reward: 11377.181954251751, Epsilon: 0.861\n",
      "Episode 444 finished after 705 timesteps\n",
      "Total reward: 5767.1185828043845, Epsilon: 0.861\n",
      "Episode 445 finished after 252 timesteps\n",
      "Total reward: 2568.1959775557375, Epsilon: 0.861\n",
      "Episode 446 finished after 1640 timesteps\n",
      "Total reward: 10402.266619434113, Epsilon: 0.861\n",
      "Episode 447 finished after 1087 timesteps\n",
      "Total reward: 5991.529059249708, Epsilon: 0.861\n",
      "Episode 448 finished after 3001 timesteps\n",
      "Total reward: 17995.930749200248, Epsilon: 0.860\n",
      "Episode 449 finished after 2515 timesteps\n",
      "Total reward: 13206.993801381455, Epsilon: 0.860\n",
      "Episode 450 finished after 1311 timesteps\n",
      "Total reward: 8901.888068551387, Epsilon: 0.860\n",
      "Episode 451 finished after 1958 timesteps\n",
      "Total reward: 11587.791737287538, Epsilon: 0.860\n",
      "Episode 452 finished after 3001 timesteps\n",
      "Total reward: 16305.066372870939, Epsilon: 0.860\n",
      "Episode 453 finished after 3001 timesteps\n",
      "Total reward: 14916.571230847694, Epsilon: 0.860\n",
      "Episode 454 finished after 3001 timesteps\n",
      "Total reward: 16530.565459145073, Epsilon: 0.860\n",
      "Episode 455 finished after 184 timesteps\n",
      "Total reward: 2107.884162089713, Epsilon: 0.860\n",
      "Episode 456 finished after 587 timesteps\n",
      "Total reward: 4245.605998412817, Epsilon: 0.860\n",
      "Episode 457 finished after 316 timesteps\n",
      "Total reward: 2945.4702901782452, Epsilon: 0.860\n",
      "Episode 458 finished after 3001 timesteps\n",
      "Total reward: 13416.594584036433, Epsilon: 0.860\n",
      "Episode 459 finished after 442 timesteps\n",
      "Total reward: 3120.6491810559482, Epsilon: 0.860\n",
      "Episode 460 finished after 3001 timesteps\n",
      "Total reward: 14823.12661254519, Epsilon: 0.859\n",
      "Episode 461 finished after 938 timesteps\n",
      "Total reward: 5285.103202833202, Epsilon: 0.859\n",
      "Episode 462 finished after 2862 timesteps\n",
      "Total reward: 20531.185119531816, Epsilon: 0.859\n",
      "Episode 463 finished after 2119 timesteps\n",
      "Total reward: 12570.354918367795, Epsilon: 0.859\n",
      "Episode 464 finished after 3001 timesteps\n",
      "Total reward: 18925.726024498654, Epsilon: 0.859\n",
      "Episode 465 finished after 3001 timesteps\n",
      "Total reward: 17472.375157980616, Epsilon: 0.859\n",
      "Episode 466 finished after 1350 timesteps\n",
      "Total reward: 8553.233083102325, Epsilon: 0.859\n",
      "Episode 467 finished after 1244 timesteps\n",
      "Total reward: 6342.810259905457, Epsilon: 0.859\n",
      "Episode 468 finished after 558 timesteps\n",
      "Total reward: 3816.9448216297583, Epsilon: 0.859\n",
      "Episode 469 finished after 2391 timesteps\n",
      "Total reward: 11269.086196453012, Epsilon: 0.859\n",
      "Episode 470 finished after 1080 timesteps\n",
      "Total reward: 6922.758415815574, Epsilon: 0.859\n",
      "Episode 471 finished after 1465 timesteps\n",
      "Total reward: 8413.198075902972, Epsilon: 0.859\n",
      "Episode 472 finished after 3001 timesteps\n",
      "Total reward: 15031.374072031287, Epsilon: 0.858\n",
      "Episode 473 finished after 1154 timesteps\n",
      "Total reward: 6616.432866042864, Epsilon: 0.858\n",
      "Episode 474 finished after 3001 timesteps\n",
      "Total reward: 17167.274676840778, Epsilon: 0.858\n",
      "Episode 475 finished after 1382 timesteps\n",
      "Total reward: 8683.663578628237, Epsilon: 0.858\n",
      "Episode 476 finished after 3001 timesteps\n",
      "Total reward: 16358.499295679427, Epsilon: 0.858\n",
      "Episode 477 finished after 926 timesteps\n",
      "Total reward: 6372.19870901233, Epsilon: 0.858\n",
      "Episode 478 finished after 3001 timesteps\n",
      "Total reward: 16063.984515012571, Epsilon: 0.858\n",
      "Episode 479 finished after 613 timesteps\n",
      "Total reward: 4279.542717123147, Epsilon: 0.858\n",
      "Episode 480 finished after 745 timesteps\n",
      "Total reward: 4405.9681187054175, Epsilon: 0.858\n",
      "Episode 481 finished after 1861 timesteps\n",
      "Total reward: 9359.239716071026, Epsilon: 0.858\n",
      "Episode 482 finished after 2468 timesteps\n",
      "Total reward: 14008.088186020914, Epsilon: 0.858\n",
      "Episode 483 finished after 3001 timesteps\n",
      "Total reward: 13861.44921130694, Epsilon: 0.857\n",
      "Episode 484 finished after 3001 timesteps\n",
      "Total reward: 16909.697361629973, Epsilon: 0.857\n",
      "Episode 485 finished after 3001 timesteps\n",
      "Total reward: 16495.120014753258, Epsilon: 0.857\n",
      "Episode 486 finished after 1532 timesteps\n",
      "Total reward: 10502.63570883305, Epsilon: 0.857\n",
      "Episode 487 finished after 576 timesteps\n",
      "Total reward: 4771.171057926122, Epsilon: 0.857\n",
      "Episode 488 finished after 2657 timesteps\n",
      "Total reward: 15842.584053996368, Epsilon: 0.857\n",
      "Episode 489 finished after 2074 timesteps\n",
      "Total reward: 12622.073158413968, Epsilon: 0.857\n",
      "Episode 490 finished after 3001 timesteps\n",
      "Total reward: 15471.776995357413, Epsilon: 0.857\n",
      "Episode 491 finished after 1224 timesteps\n",
      "Total reward: 7206.853668394692, Epsilon: 0.857\n",
      "Episode 492 finished after 1194 timesteps\n",
      "Total reward: 7706.933777843664, Epsilon: 0.857\n",
      "Episode 493 finished after 727 timesteps\n",
      "Total reward: 4952.980415511563, Epsilon: 0.857\n",
      "Episode 494 finished after 687 timesteps\n",
      "Total reward: 4987.733787446874, Epsilon: 0.857\n",
      "Episode 495 finished after 1078 timesteps\n",
      "Total reward: 6305.684183360862, Epsilon: 0.856\n",
      "Episode 496 finished after 3001 timesteps\n",
      "Total reward: 19630.020637424233, Epsilon: 0.856\n",
      "Episode 497 finished after 456 timesteps\n",
      "Total reward: 3626.1224827924693, Epsilon: 0.856\n",
      "Episode 498 finished after 552 timesteps\n",
      "Total reward: 5949.393671618594, Epsilon: 0.856\n",
      "Episode 499 finished after 768 timesteps\n",
      "Total reward: 6393.233966820086, Epsilon: 0.856\n",
      "Episode 500 finished after 1013 timesteps\n",
      "Total reward: 5885.568495268254, Epsilon: 0.856\n",
      "Episode 501 finished after 3001 timesteps\n",
      "Total reward: 18536.739429088593, Epsilon: 0.856\n",
      "Episode 502 finished after 955 timesteps\n",
      "Total reward: 6110.180911458913, Epsilon: 0.856\n",
      "Episode 503 finished after 875 timesteps\n",
      "Total reward: 4961.750176203909, Epsilon: 0.856\n",
      "Episode 504 finished after 918 timesteps\n",
      "Total reward: 5685.674572029301, Epsilon: 0.856\n",
      "Episode 505 finished after 1036 timesteps\n",
      "Total reward: 7210.426380707379, Epsilon: 0.856\n",
      "Episode 506 finished after 711 timesteps\n",
      "Total reward: 5271.86022783348, Epsilon: 0.856\n",
      "Episode 507 finished after 3001 timesteps\n",
      "Total reward: 14807.398760287184, Epsilon: 0.855\n",
      "Episode 508 finished after 2467 timesteps\n",
      "Total reward: 14856.589606211362, Epsilon: 0.855\n",
      "Episode 509 finished after 3001 timesteps\n",
      "Total reward: 16051.754950925044, Epsilon: 0.855\n",
      "Episode 510 finished after 494 timesteps\n",
      "Total reward: 4194.906916663613, Epsilon: 0.855\n",
      "Episode 511 finished after 783 timesteps\n",
      "Total reward: 5094.923573521604, Epsilon: 0.855\n",
      "Episode 512 finished after 1535 timesteps\n",
      "Total reward: 8225.492067135669, Epsilon: 0.855\n",
      "Episode 513 finished after 2984 timesteps\n",
      "Total reward: 18294.17853616567, Epsilon: 0.855\n",
      "Episode 514 finished after 459 timesteps\n",
      "Total reward: 3446.8533106700993, Epsilon: 0.855\n",
      "Episode 515 finished after 1622 timesteps\n",
      "Total reward: 10308.20879274517, Epsilon: 0.855\n",
      "Episode 516 finished after 3001 timesteps\n",
      "Total reward: 15688.978288792612, Epsilon: 0.855\n",
      "Episode 517 finished after 1064 timesteps\n",
      "Total reward: 7781.2863858391775, Epsilon: 0.855\n",
      "Episode 518 finished after 3001 timesteps\n",
      "Total reward: 16472.979594730623, Epsilon: 0.854\n",
      "Episode 519 finished after 2640 timesteps\n",
      "Total reward: 14892.808881821773, Epsilon: 0.854\n",
      "Episode 520 finished after 2335 timesteps\n",
      "Total reward: 13531.423188615063, Epsilon: 0.854\n",
      "Episode 521 finished after 3001 timesteps\n",
      "Total reward: 15351.129068813454, Epsilon: 0.854\n",
      "Episode 522 finished after 1600 timesteps\n",
      "Total reward: 11328.06381509515, Epsilon: 0.854\n",
      "Episode 523 finished after 2515 timesteps\n",
      "Total reward: 13570.053667195998, Epsilon: 0.854\n",
      "Episode 524 finished after 1518 timesteps\n",
      "Total reward: 9765.822843686998, Epsilon: 0.854\n",
      "Episode 525 finished after 1143 timesteps\n",
      "Total reward: 8159.00757133363, Epsilon: 0.854\n",
      "Episode 526 finished after 1718 timesteps\n",
      "Total reward: 10118.789803335896, Epsilon: 0.854\n",
      "Episode 527 finished after 3001 timesteps\n",
      "Total reward: 14767.848331633602, Epsilon: 0.854\n",
      "Episode 528 finished after 1665 timesteps\n",
      "Total reward: 9198.09582793788, Epsilon: 0.854\n",
      "Episode 529 finished after 3001 timesteps\n",
      "Total reward: 15278.32027821135, Epsilon: 0.854\n",
      "Episode 530 finished after 328 timesteps\n",
      "Total reward: 2906.3666753153257, Epsilon: 0.853\n",
      "Episode 531 finished after 1431 timesteps\n",
      "Total reward: 8503.855253443078, Epsilon: 0.853\n",
      "Episode 532 finished after 664 timesteps\n",
      "Total reward: 4092.5013956956855, Epsilon: 0.853\n",
      "Episode 533 finished after 3001 timesteps\n",
      "Total reward: 14811.33818196058, Epsilon: 0.853\n",
      "Episode 534 finished after 3001 timesteps\n",
      "Total reward: 15327.957764196826, Epsilon: 0.853\n",
      "Episode 535 finished after 2918 timesteps\n",
      "Total reward: 15194.720948902159, Epsilon: 0.853\n",
      "Episode 536 finished after 380 timesteps\n",
      "Total reward: 2955.7311648101977, Epsilon: 0.853\n",
      "Episode 537 finished after 1445 timesteps\n",
      "Total reward: 10598.699609868558, Epsilon: 0.853\n",
      "Episode 538 finished after 1158 timesteps\n",
      "Total reward: 6647.655684043364, Epsilon: 0.853\n",
      "Episode 539 finished after 1275 timesteps\n",
      "Total reward: 8241.622555111026, Epsilon: 0.853\n",
      "Episode 540 finished after 514 timesteps\n",
      "Total reward: 4075.779383820712, Epsilon: 0.853\n",
      "Episode 541 finished after 3001 timesteps\n",
      "Total reward: 15531.846355663718, Epsilon: 0.853\n",
      "Episode 542 finished after 1361 timesteps\n",
      "Total reward: 7892.452115328024, Epsilon: 0.852\n",
      "Episode 543 finished after 1778 timesteps\n",
      "Total reward: 11147.215410603796, Epsilon: 0.852\n",
      "Episode 544 finished after 527 timesteps\n",
      "Total reward: 4134.126212946151, Epsilon: 0.852\n",
      "Episode 545 finished after 765 timesteps\n",
      "Total reward: 6635.444233377326, Epsilon: 0.852\n",
      "Episode 546 finished after 537 timesteps\n",
      "Total reward: 3468.8638935341455, Epsilon: 0.852\n",
      "Episode 547 finished after 1312 timesteps\n",
      "Total reward: 8146.425495022944, Epsilon: 0.852\n",
      "Episode 548 finished after 3001 timesteps\n",
      "Total reward: 19802.307189752304, Epsilon: 0.852\n",
      "Episode 549 finished after 1626 timesteps\n",
      "Total reward: 11792.407571488795, Epsilon: 0.852\n",
      "Episode 550 finished after 1270 timesteps\n",
      "Total reward: 7062.212935993318, Epsilon: 0.852\n",
      "Episode 551 finished after 606 timesteps\n",
      "Total reward: 4618.422516793466, Epsilon: 0.852\n",
      "Episode 552 finished after 972 timesteps\n",
      "Total reward: 5453.47823830144, Epsilon: 0.852\n",
      "Episode 553 finished after 957 timesteps\n",
      "Total reward: 6224.137293228257, Epsilon: 0.851\n",
      "Episode 554 finished after 3001 timesteps\n",
      "Total reward: 17804.29036038975, Epsilon: 0.851\n",
      "Episode 555 finished after 2966 timesteps\n",
      "Total reward: 17227.25398218568, Epsilon: 0.851\n",
      "Episode 556 finished after 1558 timesteps\n",
      "Total reward: 8780.511233244295, Epsilon: 0.851\n",
      "Episode 557 finished after 3001 timesteps\n",
      "Total reward: 18105.57755777207, Epsilon: 0.851\n",
      "Episode 558 finished after 1289 timesteps\n",
      "Total reward: 7094.266338650238, Epsilon: 0.851\n",
      "Episode 559 finished after 1673 timesteps\n",
      "Total reward: 11547.420936523946, Epsilon: 0.851\n",
      "Episode 560 finished after 336 timesteps\n",
      "Total reward: 3044.4746887422903, Epsilon: 0.851\n",
      "Episode 561 finished after 3001 timesteps\n",
      "Total reward: 16100.692784938954, Epsilon: 0.851\n",
      "Episode 562 finished after 88 timesteps\n",
      "Total reward: 1482.5163028638754, Epsilon: 0.851\n",
      "Episode 563 finished after 1012 timesteps\n",
      "Total reward: 6766.0070937516975, Epsilon: 0.851\n",
      "Episode 564 finished after 1621 timesteps\n",
      "Total reward: 12328.310139031364, Epsilon: 0.851\n",
      "Episode 565 finished after 283 timesteps\n",
      "Total reward: 2237.4422807525684, Epsilon: 0.850\n",
      "Episode 566 finished after 517 timesteps\n",
      "Total reward: 3656.9996730997573, Epsilon: 0.850\n",
      "Episode 567 finished after 3001 timesteps\n",
      "Total reward: 16046.303714692664, Epsilon: 0.850\n",
      "Episode 568 finished after 774 timesteps\n",
      "Total reward: 4898.121714600639, Epsilon: 0.850\n",
      "Episode 569 finished after 936 timesteps\n",
      "Total reward: 5275.879823083785, Epsilon: 0.850\n",
      "Episode 570 finished after 2679 timesteps\n",
      "Total reward: 17053.350571738018, Epsilon: 0.850\n",
      "Episode 571 finished after 2907 timesteps\n",
      "Total reward: 15391.976845919704, Epsilon: 0.850\n",
      "Episode 572 finished after 3001 timesteps\n",
      "Total reward: 17910.64124729783, Epsilon: 0.850\n",
      "Episode 573 finished after 1395 timesteps\n",
      "Total reward: 8175.33412950305, Epsilon: 0.850\n",
      "Episode 574 finished after 3001 timesteps\n",
      "Total reward: 15744.567193167, Epsilon: 0.850\n",
      "Episode 575 finished after 1547 timesteps\n",
      "Total reward: 9700.340097452567, Epsilon: 0.850\n",
      "Episode 576 finished after 2839 timesteps\n",
      "Total reward: 17443.353564389996, Epsilon: 0.850\n",
      "Episode 577 finished after 591 timesteps\n",
      "Total reward: 4605.513035525597, Epsilon: 0.849\n",
      "Episode 578 finished after 120 timesteps\n",
      "Total reward: 1594.4458703725486, Epsilon: 0.849\n",
      "Episode 579 finished after 1568 timesteps\n",
      "Total reward: 8035.198339052088, Epsilon: 0.849\n",
      "Episode 580 finished after 518 timesteps\n",
      "Total reward: 4262.865035161238, Epsilon: 0.849\n",
      "Episode 581 finished after 772 timesteps\n",
      "Total reward: 3999.045975166032, Epsilon: 0.849\n",
      "Episode 582 finished after 3001 timesteps\n",
      "Total reward: 14390.965361229522, Epsilon: 0.849\n",
      "Episode 583 finished after 1421 timesteps\n",
      "Total reward: 8976.5078598637, Epsilon: 0.849\n",
      "Episode 584 finished after 3001 timesteps\n",
      "Total reward: 19068.54671577156, Epsilon: 0.849\n",
      "Episode 585 finished after 3001 timesteps\n",
      "Total reward: 14121.370560674812, Epsilon: 0.849\n",
      "Episode 586 finished after 2611 timesteps\n",
      "Total reward: 12761.31130023313, Epsilon: 0.849\n",
      "Episode 587 finished after 666 timesteps\n",
      "Total reward: 5048.534869884237, Epsilon: 0.849\n",
      "Episode 588 finished after 2043 timesteps\n",
      "Total reward: 13313.4681489811, Epsilon: 0.849\n",
      "Episode 589 finished after 3001 timesteps\n",
      "Total reward: 16672.519145173625, Epsilon: 0.848\n",
      "Episode 590 finished after 3001 timesteps\n",
      "Total reward: 14355.516223316612, Epsilon: 0.848\n",
      "Episode 591 finished after 3001 timesteps\n",
      "Total reward: 14801.517081838245, Epsilon: 0.848\n",
      "Episode 592 finished after 1183 timesteps\n",
      "Total reward: 7804.28656970768, Epsilon: 0.848\n",
      "Episode 593 finished after 535 timesteps\n",
      "Total reward: 4268.3254234049, Epsilon: 0.848\n",
      "Episode 594 finished after 3001 timesteps\n",
      "Total reward: 17432.803366523014, Epsilon: 0.848\n",
      "Episode 595 finished after 2737 timesteps\n",
      "Total reward: 14075.889575493686, Epsilon: 0.848\n",
      "Episode 596 finished after 934 timesteps\n",
      "Total reward: 5440.853935589977, Epsilon: 0.848\n",
      "Episode 597 finished after 580 timesteps\n",
      "Total reward: 4525.744173996763, Epsilon: 0.848\n",
      "Episode 598 finished after 744 timesteps\n",
      "Total reward: 5183.213006113575, Epsilon: 0.848\n",
      "Episode 599 finished after 551 timesteps\n",
      "Total reward: 5607.381619528603, Epsilon: 0.848\n",
      "Episode 600 finished after 3001 timesteps\n",
      "Total reward: 13424.578877526916, Epsilon: 0.848\n",
      "Episode 601 finished after 1472 timesteps\n",
      "Total reward: 9850.203615856664, Epsilon: 0.847\n",
      "Episode 602 finished after 3001 timesteps\n",
      "Total reward: 15576.079370167789, Epsilon: 0.847\n",
      "Episode 603 finished after 756 timesteps\n",
      "Total reward: 4390.929686809684, Epsilon: 0.847\n",
      "Episode 604 finished after 3001 timesteps\n",
      "Total reward: 14937.381940286694, Epsilon: 0.847\n",
      "Episode 605 finished after 1309 timesteps\n",
      "Total reward: 8739.011891095994, Epsilon: 0.847\n",
      "Episode 606 finished after 3001 timesteps\n",
      "Total reward: 13466.468241656503, Epsilon: 0.847\n",
      "Episode 607 finished after 2914 timesteps\n",
      "Total reward: 15717.86259485128, Epsilon: 0.847\n",
      "Episode 608 finished after 2358 timesteps\n",
      "Total reward: 13292.039000834582, Epsilon: 0.847\n",
      "Episode 609 finished after 1745 timesteps\n",
      "Total reward: 13777.735840696669, Epsilon: 0.847\n",
      "Episode 610 finished after 769 timesteps\n",
      "Total reward: 4663.943101302764, Epsilon: 0.847\n",
      "Episode 611 finished after 1345 timesteps\n",
      "Total reward: 6543.404079549713, Epsilon: 0.847\n",
      "Episode 612 finished after 1208 timesteps\n",
      "Total reward: 8424.82260298273, Epsilon: 0.846\n",
      "Episode 613 finished after 1046 timesteps\n",
      "Total reward: 7613.560390099033, Epsilon: 0.846\n",
      "Episode 614 finished after 1603 timesteps\n",
      "Total reward: 10251.801777217823, Epsilon: 0.846\n",
      "Episode 615 finished after 812 timesteps\n",
      "Total reward: 5011.466257272271, Epsilon: 0.846\n",
      "Episode 616 finished after 922 timesteps\n",
      "Total reward: 5054.429088252596, Epsilon: 0.846\n",
      "Episode 617 finished after 1882 timesteps\n",
      "Total reward: 10798.727653706457, Epsilon: 0.846\n",
      "Episode 618 finished after 2972 timesteps\n",
      "Total reward: 19354.002913530898, Epsilon: 0.846\n",
      "Episode 619 finished after 1527 timesteps\n",
      "Total reward: 9551.049723848151, Epsilon: 0.846\n",
      "Episode 620 finished after 1071 timesteps\n",
      "Total reward: 6666.230763522392, Epsilon: 0.846\n",
      "Episode 621 finished after 3001 timesteps\n",
      "Total reward: 17017.95888939442, Epsilon: 0.846\n",
      "Episode 622 finished after 3001 timesteps\n",
      "Total reward: 16055.571762071, Epsilon: 0.846\n",
      "Episode 623 finished after 3001 timesteps\n",
      "Total reward: 18726.734915413264, Epsilon: 0.846\n",
      "Episode 624 finished after 2436 timesteps\n",
      "Total reward: 16265.153827928501, Epsilon: 0.845\n",
      "Episode 625 finished after 545 timesteps\n",
      "Total reward: 4752.575655750247, Epsilon: 0.845\n",
      "Episode 626 finished after 1558 timesteps\n",
      "Total reward: 9295.735127098244, Epsilon: 0.845\n",
      "Episode 627 finished after 1421 timesteps\n",
      "Total reward: 8340.25722881056, Epsilon: 0.845\n",
      "Episode 628 finished after 3001 timesteps\n",
      "Total reward: 15088.008987337254, Epsilon: 0.845\n",
      "Episode 629 finished after 1786 timesteps\n",
      "Total reward: 10690.645198873512, Epsilon: 0.845\n",
      "Episode 630 finished after 2937 timesteps\n",
      "Total reward: 15757.751835216033, Epsilon: 0.845\n",
      "Episode 631 finished after 840 timesteps\n",
      "Total reward: 5586.045515648212, Epsilon: 0.845\n",
      "Episode 632 finished after 3001 timesteps\n",
      "Total reward: 14946.261740454469, Epsilon: 0.845\n",
      "Episode 633 finished after 2815 timesteps\n",
      "Total reward: 14811.035257561036, Epsilon: 0.845\n",
      "Episode 634 finished after 3001 timesteps\n",
      "Total reward: 15018.210762046603, Epsilon: 0.845\n",
      "Episode 635 finished after 998 timesteps\n",
      "Total reward: 5905.914278671374, Epsilon: 0.845\n",
      "Episode 636 finished after 1527 timesteps\n",
      "Total reward: 9599.454555618084, Epsilon: 0.844\n",
      "Episode 637 finished after 2684 timesteps\n",
      "Total reward: 14247.257295804777, Epsilon: 0.844\n",
      "Episode 638 finished after 1840 timesteps\n",
      "Total reward: 10129.881163168799, Epsilon: 0.844\n",
      "Episode 639 finished after 3001 timesteps\n",
      "Total reward: 16180.164124027802, Epsilon: 0.844\n",
      "Episode 640 finished after 1234 timesteps\n",
      "Total reward: 9493.890745103889, Epsilon: 0.844\n",
      "Episode 641 finished after 960 timesteps\n",
      "Total reward: 5059.568571238338, Epsilon: 0.844\n",
      "Episode 642 finished after 475 timesteps\n",
      "Total reward: 3061.839638112221, Epsilon: 0.844\n",
      "Episode 643 finished after 845 timesteps\n",
      "Total reward: 5316.274024277586, Epsilon: 0.844\n",
      "Episode 644 finished after 866 timesteps\n",
      "Total reward: 6901.765991928536, Epsilon: 0.844\n",
      "Episode 645 finished after 1823 timesteps\n",
      "Total reward: 10478.146478187156, Epsilon: 0.844\n",
      "Episode 646 finished after 527 timesteps\n",
      "Total reward: 3956.1373820157996, Epsilon: 0.844\n",
      "Episode 647 finished after 3001 timesteps\n",
      "Total reward: 15604.073862718134, Epsilon: 0.844\n",
      "Episode 648 finished after 3001 timesteps\n",
      "Total reward: 15544.132430175918, Epsilon: 0.843\n",
      "Episode 649 finished after 1994 timesteps\n",
      "Total reward: 12709.716963517236, Epsilon: 0.843\n",
      "Episode 650 finished after 3001 timesteps\n",
      "Total reward: 13471.304209152619, Epsilon: 0.843\n",
      "Episode 651 finished after 916 timesteps\n",
      "Total reward: 6090.231960041502, Epsilon: 0.843\n",
      "Episode 652 finished after 1624 timesteps\n",
      "Total reward: 9473.501032710292, Epsilon: 0.843\n",
      "Episode 653 finished after 3001 timesteps\n",
      "Total reward: 15054.48974190365, Epsilon: 0.843\n",
      "Episode 654 finished after 672 timesteps\n",
      "Total reward: 4186.108568914069, Epsilon: 0.843\n",
      "Episode 655 finished after 2312 timesteps\n",
      "Total reward: 10831.355392429175, Epsilon: 0.843\n",
      "Episode 656 finished after 749 timesteps\n",
      "Total reward: 5500.777968297377, Epsilon: 0.843\n",
      "Episode 657 finished after 503 timesteps\n",
      "Total reward: 3586.5730369954276, Epsilon: 0.843\n",
      "Episode 658 finished after 616 timesteps\n",
      "Total reward: 4183.948956508222, Epsilon: 0.843\n",
      "Episode 659 finished after 1574 timesteps\n",
      "Total reward: 11198.48982806542, Epsilon: 0.843\n",
      "Episode 660 finished after 3001 timesteps\n",
      "Total reward: 14688.40710039453, Epsilon: 0.842\n",
      "Episode 661 finished after 737 timesteps\n",
      "Total reward: 6938.205730225464, Epsilon: 0.842\n",
      "Episode 662 finished after 3001 timesteps\n",
      "Total reward: 14339.193123250567, Epsilon: 0.842\n",
      "Episode 663 finished after 283 timesteps\n",
      "Total reward: 2387.022437905486, Epsilon: 0.842\n",
      "Episode 664 finished after 635 timesteps\n",
      "Total reward: 4364.275622075873, Epsilon: 0.842\n",
      "Episode 665 finished after 583 timesteps\n",
      "Total reward: 5656.191525893493, Epsilon: 0.842\n",
      "Episode 666 finished after 910 timesteps\n",
      "Total reward: 6086.964815714682, Epsilon: 0.842\n",
      "Episode 667 finished after 2453 timesteps\n",
      "Total reward: 13716.237302426345, Epsilon: 0.842\n",
      "Episode 668 finished after 2213 timesteps\n",
      "Total reward: 10884.26982302, Epsilon: 0.842\n",
      "Episode 669 finished after 2014 timesteps\n",
      "Total reward: 14112.357471924683, Epsilon: 0.842\n",
      "Episode 670 finished after 363 timesteps\n",
      "Total reward: 3109.0064350764237, Epsilon: 0.842\n",
      "Episode 671 finished after 1578 timesteps\n",
      "Total reward: 9094.99126507535, Epsilon: 0.842\n",
      "Episode 672 finished after 1742 timesteps\n",
      "Total reward: 8885.028122792923, Epsilon: 0.841\n",
      "Episode 673 finished after 2953 timesteps\n",
      "Total reward: 15394.527668357186, Epsilon: 0.841\n",
      "Episode 674 finished after 594 timesteps\n",
      "Total reward: 3767.4383268636243, Epsilon: 0.841\n",
      "Episode 675 finished after 1153 timesteps\n",
      "Total reward: 9270.791584807257, Epsilon: 0.841\n",
      "Episode 676 finished after 3001 timesteps\n",
      "Total reward: 15534.986282153646, Epsilon: 0.841\n",
      "Episode 677 finished after 3001 timesteps\n",
      "Total reward: 16848.216394214272, Epsilon: 0.841\n",
      "Episode 678 finished after 1166 timesteps\n",
      "Total reward: 6763.865988399551, Epsilon: 0.841\n",
      "Episode 679 finished after 744 timesteps\n",
      "Total reward: 4319.991911130175, Epsilon: 0.841\n",
      "Episode 680 finished after 684 timesteps\n",
      "Total reward: 5581.65171508947, Epsilon: 0.841\n",
      "Episode 681 finished after 2810 timesteps\n",
      "Total reward: 15106.71883419019, Epsilon: 0.841\n",
      "Episode 682 finished after 1515 timesteps\n",
      "Total reward: 8399.984573516509, Epsilon: 0.841\n",
      "Episode 683 finished after 331 timesteps\n",
      "Total reward: 3038.6799765703463, Epsilon: 0.840\n",
      "Episode 684 finished after 1130 timesteps\n",
      "Total reward: 6065.7568885670335, Epsilon: 0.840\n",
      "Episode 685 finished after 358 timesteps\n",
      "Total reward: 2568.5310967582786, Epsilon: 0.840\n",
      "Episode 686 finished after 489 timesteps\n",
      "Total reward: 3885.7461439259077, Epsilon: 0.840\n",
      "Episode 687 finished after 2425 timesteps\n",
      "Total reward: 14642.782262558158, Epsilon: 0.840\n",
      "Episode 688 finished after 1488 timesteps\n",
      "Total reward: 7972.116486918106, Epsilon: 0.840\n",
      "Episode 689 finished after 2138 timesteps\n",
      "Total reward: 11901.255353480075, Epsilon: 0.840\n",
      "Episode 690 finished after 520 timesteps\n",
      "Total reward: 4570.068717801718, Epsilon: 0.840\n",
      "Episode 691 finished after 3001 timesteps\n",
      "Total reward: 16489.736337318187, Epsilon: 0.840\n",
      "Episode 692 finished after 582 timesteps\n",
      "Total reward: 5164.04468600633, Epsilon: 0.840\n",
      "Episode 693 finished after 430 timesteps\n",
      "Total reward: 3034.8876544273967, Epsilon: 0.840\n",
      "Episode 694 finished after 3001 timesteps\n",
      "Total reward: 16620.695684346807, Epsilon: 0.840\n",
      "Episode 695 finished after 614 timesteps\n",
      "Total reward: 3853.975585384705, Epsilon: 0.839\n",
      "Episode 696 finished after 575 timesteps\n",
      "Total reward: 4224.001112742715, Epsilon: 0.839\n",
      "Episode 697 finished after 1035 timesteps\n",
      "Total reward: 9153.81816411788, Epsilon: 0.839\n",
      "Episode 698 finished after 1559 timesteps\n",
      "Total reward: 10013.046479812574, Epsilon: 0.839\n",
      "Episode 699 finished after 2502 timesteps\n",
      "Total reward: 13970.777466578882, Epsilon: 0.839\n",
      "Episode 700 finished after 2645 timesteps\n",
      "Total reward: 14553.837681429986, Epsilon: 0.839\n",
      "Episode 701 finished after 1993 timesteps\n",
      "Total reward: 11754.362729309607, Epsilon: 0.839\n",
      "Episode 702 finished after 728 timesteps\n",
      "Total reward: 5161.473830405558, Epsilon: 0.839\n",
      "Episode 703 finished after 2545 timesteps\n",
      "Total reward: 13220.408760164177, Epsilon: 0.839\n",
      "Episode 704 finished after 3001 timesteps\n",
      "Total reward: 13947.265969625749, Epsilon: 0.839\n",
      "Episode 705 finished after 1172 timesteps\n",
      "Total reward: 8580.487345442305, Epsilon: 0.839\n",
      "Episode 706 finished after 1619 timesteps\n",
      "Total reward: 9627.299786460982, Epsilon: 0.839\n",
      "Episode 707 finished after 1059 timesteps\n",
      "Total reward: 6162.178845850131, Epsilon: 0.838\n",
      "Episode 708 finished after 3001 timesteps\n",
      "Total reward: 14578.152745404386, Epsilon: 0.838\n",
      "Episode 709 finished after 360 timesteps\n",
      "Total reward: 2666.3711515612877, Epsilon: 0.838\n",
      "Episode 710 finished after 2241 timesteps\n",
      "Total reward: 13494.386483837385, Epsilon: 0.838\n",
      "Episode 711 finished after 1129 timesteps\n",
      "Total reward: 5712.347040595672, Epsilon: 0.838\n",
      "Episode 712 finished after 2037 timesteps\n",
      "Total reward: 10953.417988776077, Epsilon: 0.838\n",
      "Episode 713 finished after 1373 timesteps\n",
      "Total reward: 10825.373467842293, Epsilon: 0.838\n",
      "Episode 714 finished after 504 timesteps\n",
      "Total reward: 3388.5002913939543, Epsilon: 0.838\n",
      "Episode 715 finished after 3001 timesteps\n",
      "Total reward: 14139.728626072458, Epsilon: 0.838\n",
      "Episode 716 finished after 3001 timesteps\n",
      "Total reward: 15271.169514826825, Epsilon: 0.838\n",
      "Episode 717 finished after 103 timesteps\n",
      "Total reward: 1348.712405495011, Epsilon: 0.838\n",
      "Episode 718 finished after 3001 timesteps\n",
      "Total reward: 13941.079997019, Epsilon: 0.838\n",
      "Episode 719 finished after 2890 timesteps\n",
      "Total reward: 17942.125947308126, Epsilon: 0.837\n",
      "Episode 720 finished after 715 timesteps\n",
      "Total reward: 4818.718764917589, Epsilon: 0.837\n",
      "Episode 721 finished after 333 timesteps\n",
      "Total reward: 2512.6565844257907, Epsilon: 0.837\n",
      "Episode 722 finished after 1855 timesteps\n",
      "Total reward: 11366.927197576704, Epsilon: 0.837\n",
      "Episode 723 finished after 912 timesteps\n",
      "Total reward: 5716.57199417657, Epsilon: 0.837\n",
      "Episode 724 finished after 1743 timesteps\n",
      "Total reward: 8855.119858908074, Epsilon: 0.837\n",
      "Episode 725 finished after 3001 timesteps\n",
      "Total reward: 15166.871120568723, Epsilon: 0.837\n",
      "Episode 726 finished after 1930 timesteps\n",
      "Total reward: 10328.910970572379, Epsilon: 0.837\n",
      "Episode 727 finished after 554 timesteps\n",
      "Total reward: 3661.1833261602496, Epsilon: 0.837\n",
      "Episode 728 finished after 1171 timesteps\n",
      "Total reward: 9328.940016731623, Epsilon: 0.837\n",
      "Episode 729 finished after 2885 timesteps\n",
      "Total reward: 15248.878675595055, Epsilon: 0.837\n",
      "Episode 730 finished after 496 timesteps\n",
      "Total reward: 4187.539438889351, Epsilon: 0.837\n",
      "Episode 731 finished after 2448 timesteps\n",
      "Total reward: 13780.441465956652, Epsilon: 0.836\n",
      "Episode 732 finished after 3001 timesteps\n",
      "Total reward: 14847.985038045732, Epsilon: 0.836\n",
      "Episode 733 finished after 942 timesteps\n",
      "Total reward: 6540.153096620658, Epsilon: 0.836\n",
      "Episode 734 finished after 1011 timesteps\n",
      "Total reward: 6809.414186925837, Epsilon: 0.836\n",
      "Episode 735 finished after 1042 timesteps\n",
      "Total reward: 7021.690491438801, Epsilon: 0.836\n",
      "Episode 736 finished after 1834 timesteps\n",
      "Total reward: 13997.560117182416, Epsilon: 0.836\n",
      "Episode 737 finished after 597 timesteps\n",
      "Total reward: 4524.088221094765, Epsilon: 0.836\n",
      "Episode 738 finished after 3001 timesteps\n",
      "Total reward: 19219.0203361728, Epsilon: 0.836\n",
      "Episode 739 finished after 1569 timesteps\n",
      "Total reward: 8679.133284813648, Epsilon: 0.836\n",
      "Episode 740 finished after 3001 timesteps\n",
      "Total reward: 17228.375955025578, Epsilon: 0.836\n",
      "Episode 741 finished after 846 timesteps\n",
      "Total reward: 6810.2947952006625, Epsilon: 0.836\n",
      "Episode 742 finished after 425 timesteps\n",
      "Total reward: 3105.2102715534293, Epsilon: 0.836\n",
      "Episode 743 finished after 1973 timesteps\n",
      "Total reward: 10425.12062469434, Epsilon: 0.835\n",
      "Episode 744 finished after 594 timesteps\n",
      "Total reward: 4319.916921075908, Epsilon: 0.835\n",
      "Episode 745 finished after 1893 timesteps\n",
      "Total reward: 13304.484879204552, Epsilon: 0.835\n",
      "Episode 746 finished after 1376 timesteps\n",
      "Total reward: 8165.0628766823575, Epsilon: 0.835\n",
      "Episode 747 finished after 1406 timesteps\n",
      "Total reward: 9799.056263304392, Epsilon: 0.835\n",
      "Episode 748 finished after 1762 timesteps\n",
      "Total reward: 9400.599114206401, Epsilon: 0.835\n",
      "Episode 749 finished after 2328 timesteps\n",
      "Total reward: 13241.61676909302, Epsilon: 0.835\n",
      "Episode 750 finished after 3001 timesteps\n",
      "Total reward: 18930.786184761415, Epsilon: 0.835\n",
      "Episode 751 finished after 2041 timesteps\n",
      "Total reward: 11576.731468744443, Epsilon: 0.835\n",
      "Episode 752 finished after 1321 timesteps\n",
      "Total reward: 11011.505922534183, Epsilon: 0.835\n",
      "Episode 753 finished after 1494 timesteps\n",
      "Total reward: 8939.202110917764, Epsilon: 0.835\n",
      "Episode 754 finished after 3001 timesteps\n",
      "Total reward: 14302.312372487599, Epsilon: 0.835\n",
      "Episode 755 finished after 3001 timesteps\n",
      "Total reward: 12718.979585950538, Epsilon: 0.834\n",
      "Episode 756 finished after 2700 timesteps\n",
      "Total reward: 14916.364626829736, Epsilon: 0.834\n",
      "Episode 757 finished after 3001 timesteps\n",
      "Total reward: 13691.024496535256, Epsilon: 0.834\n",
      "Episode 758 finished after 3001 timesteps\n",
      "Total reward: 17331.45176626868, Epsilon: 0.834\n",
      "Episode 759 finished after 1093 timesteps\n",
      "Total reward: 7179.6541885692895, Epsilon: 0.834\n",
      "Episode 760 finished after 709 timesteps\n",
      "Total reward: 4740.481810643866, Epsilon: 0.834\n",
      "Episode 761 finished after 1960 timesteps\n",
      "Total reward: 12011.965438632173, Epsilon: 0.834\n",
      "Episode 762 finished after 1741 timesteps\n",
      "Total reward: 9963.74452678128, Epsilon: 0.834\n",
      "Episode 763 finished after 613 timesteps\n",
      "Total reward: 6726.938302326454, Epsilon: 0.834\n",
      "Episode 764 finished after 362 timesteps\n",
      "Total reward: 2831.31700261475, Epsilon: 0.834\n",
      "Episode 765 finished after 1640 timesteps\n",
      "Total reward: 8899.242208840878, Epsilon: 0.834\n",
      "Episode 766 finished after 319 timesteps\n",
      "Total reward: 2863.951747701428, Epsilon: 0.834\n",
      "Episode 767 finished after 1064 timesteps\n",
      "Total reward: 6766.996531912004, Epsilon: 0.833\n",
      "Episode 768 finished after 1277 timesteps\n",
      "Total reward: 9697.637460339918, Epsilon: 0.833\n",
      "Episode 769 finished after 1063 timesteps\n",
      "Total reward: 8032.829069346134, Epsilon: 0.833\n",
      "Episode 770 finished after 905 timesteps\n",
      "Total reward: 5011.760135424345, Epsilon: 0.833\n",
      "Episode 771 finished after 782 timesteps\n",
      "Total reward: 6130.5770121340975, Epsilon: 0.833\n",
      "Episode 772 finished after 404 timesteps\n",
      "Total reward: 3707.055268445209, Epsilon: 0.833\n",
      "Episode 773 finished after 1795 timesteps\n",
      "Total reward: 10474.63704412311, Epsilon: 0.833\n",
      "Episode 774 finished after 2572 timesteps\n",
      "Total reward: 17067.407959906806, Epsilon: 0.833\n",
      "Episode 775 finished after 2756 timesteps\n",
      "Total reward: 14724.758822736096, Epsilon: 0.833\n",
      "Episode 776 finished after 1132 timesteps\n",
      "Total reward: 8101.403592836959, Epsilon: 0.833\n",
      "Episode 777 finished after 2139 timesteps\n",
      "Total reward: 11672.722539788952, Epsilon: 0.833\n",
      "Episode 778 finished after 977 timesteps\n",
      "Total reward: 6488.177666296422, Epsilon: 0.833\n",
      "Episode 779 finished after 651 timesteps\n",
      "Total reward: 4373.433417036961, Epsilon: 0.832\n",
      "Episode 780 finished after 857 timesteps\n",
      "Total reward: 5417.441462663786, Epsilon: 0.832\n",
      "Episode 781 finished after 665 timesteps\n",
      "Total reward: 5256.099819653885, Epsilon: 0.832\n",
      "Episode 782 finished after 1400 timesteps\n",
      "Total reward: 9100.827696496714, Epsilon: 0.832\n",
      "Episode 783 finished after 3001 timesteps\n",
      "Total reward: 14843.786011302487, Epsilon: 0.832\n",
      "Episode 784 finished after 1631 timesteps\n",
      "Total reward: 9888.151738753842, Epsilon: 0.832\n",
      "Episode 785 finished after 3001 timesteps\n",
      "Total reward: 15377.26774223502, Epsilon: 0.832\n",
      "Episode 786 finished after 439 timesteps\n",
      "Total reward: 3387.803709045277, Epsilon: 0.832\n",
      "Episode 787 finished after 1790 timesteps\n",
      "Total reward: 9152.785590964402, Epsilon: 0.832\n",
      "Episode 788 finished after 229 timesteps\n",
      "Total reward: 2416.023327228875, Epsilon: 0.832\n",
      "Episode 789 finished after 3001 timesteps\n",
      "Total reward: 20900.94765652209, Epsilon: 0.832\n",
      "Episode 790 finished after 1078 timesteps\n",
      "Total reward: 8052.616114944211, Epsilon: 0.832\n",
      "Episode 791 finished after 3001 timesteps\n",
      "Total reward: 14666.233617949814, Epsilon: 0.831\n",
      "Episode 792 finished after 3001 timesteps\n",
      "Total reward: 15699.020344665372, Epsilon: 0.831\n",
      "Episode 793 finished after 2114 timesteps\n",
      "Total reward: 14575.323830544019, Epsilon: 0.831\n",
      "Episode 794 finished after 2131 timesteps\n",
      "Total reward: 11177.704551062763, Epsilon: 0.831\n",
      "Episode 795 finished after 2418 timesteps\n",
      "Total reward: 12320.041472895831, Epsilon: 0.831\n",
      "Episode 796 finished after 3001 timesteps\n",
      "Total reward: 16245.604148088973, Epsilon: 0.831\n",
      "Episode 797 finished after 3001 timesteps\n",
      "Total reward: 14173.930899021723, Epsilon: 0.831\n",
      "Episode 798 finished after 627 timesteps\n",
      "Total reward: 4410.593580702356, Epsilon: 0.831\n",
      "Episode 799 finished after 1300 timesteps\n",
      "Total reward: 8807.560885963412, Epsilon: 0.831\n",
      "Episode 800 finished after 2559 timesteps\n",
      "Total reward: 15974.224227743973, Epsilon: 0.831\n",
      "Episode 801 finished after 2133 timesteps\n",
      "Total reward: 15028.935934633291, Epsilon: 0.831\n",
      "Episode 802 finished after 2369 timesteps\n",
      "Total reward: 14077.929793011304, Epsilon: 0.831\n",
      "Episode 803 finished after 2097 timesteps\n",
      "Total reward: 13342.058210731588, Epsilon: 0.830\n",
      "Episode 804 finished after 1070 timesteps\n",
      "Total reward: 6416.632317632069, Epsilon: 0.830\n",
      "Episode 805 finished after 699 timesteps\n",
      "Total reward: 5105.305510291125, Epsilon: 0.830\n",
      "Episode 806 finished after 1455 timesteps\n",
      "Total reward: 7389.305678373916, Epsilon: 0.830\n",
      "Episode 807 finished after 1462 timesteps\n",
      "Total reward: 8095.802513144419, Epsilon: 0.830\n",
      "Episode 808 finished after 2236 timesteps\n",
      "Total reward: 11781.114154849676, Epsilon: 0.830\n",
      "Episode 809 finished after 552 timesteps\n",
      "Total reward: 3968.0669069586256, Epsilon: 0.830\n",
      "Episode 810 finished after 3001 timesteps\n",
      "Total reward: 15285.51375079482, Epsilon: 0.830\n",
      "Episode 811 finished after 972 timesteps\n",
      "Total reward: 5915.062346861996, Epsilon: 0.830\n",
      "Episode 812 finished after 1332 timesteps\n",
      "Total reward: 7987.403395808946, Epsilon: 0.830\n",
      "Episode 813 finished after 2007 timesteps\n",
      "Total reward: 10309.406499369767, Epsilon: 0.830\n",
      "Episode 814 finished after 3001 timesteps\n",
      "Total reward: 14846.93278155375, Epsilon: 0.830\n",
      "Episode 815 finished after 625 timesteps\n",
      "Total reward: 6214.072062559798, Epsilon: 0.829\n",
      "Episode 816 finished after 1369 timesteps\n",
      "Total reward: 7702.535793891774, Epsilon: 0.829\n",
      "Episode 817 finished after 1039 timesteps\n",
      "Total reward: 5419.346276827429, Epsilon: 0.829\n",
      "Episode 818 finished after 1262 timesteps\n",
      "Total reward: 9292.884956165262, Epsilon: 0.829\n",
      "Episode 819 finished after 2290 timesteps\n",
      "Total reward: 12719.975232128407, Epsilon: 0.829\n",
      "Episode 820 finished after 383 timesteps\n",
      "Total reward: 3649.4826821534466, Epsilon: 0.829\n",
      "Episode 821 finished after 1825 timesteps\n",
      "Total reward: 10764.382388846458, Epsilon: 0.829\n",
      "Episode 822 finished after 2888 timesteps\n",
      "Total reward: 17217.286769881724, Epsilon: 0.829\n",
      "Episode 823 finished after 1068 timesteps\n",
      "Total reward: 7069.079037569346, Epsilon: 0.829\n",
      "Episode 824 finished after 1149 timesteps\n",
      "Total reward: 6770.025074045538, Epsilon: 0.829\n",
      "Episode 825 finished after 1273 timesteps\n",
      "Total reward: 6986.113117755203, Epsilon: 0.829\n",
      "Episode 826 finished after 770 timesteps\n",
      "Total reward: 5487.811184503452, Epsilon: 0.829\n",
      "Episode 827 finished after 806 timesteps\n",
      "Total reward: 4989.7834714675455, Epsilon: 0.828\n",
      "Episode 828 finished after 134 timesteps\n",
      "Total reward: 1554.4788198640658, Epsilon: 0.828\n",
      "Episode 829 finished after 1951 timesteps\n",
      "Total reward: 11464.3862599941, Epsilon: 0.828\n",
      "Episode 830 finished after 2289 timesteps\n",
      "Total reward: 11732.9111542417, Epsilon: 0.828\n",
      "Episode 831 finished after 508 timesteps\n",
      "Total reward: 4536.2948345874365, Epsilon: 0.828\n",
      "Episode 832 finished after 1457 timesteps\n",
      "Total reward: 8321.440071515355, Epsilon: 0.828\n",
      "Episode 833 finished after 2138 timesteps\n",
      "Total reward: 13819.708665861677, Epsilon: 0.828\n",
      "Episode 834 finished after 2179 timesteps\n",
      "Total reward: 12116.139229224562, Epsilon: 0.828\n",
      "Episode 835 finished after 2308 timesteps\n",
      "Total reward: 13602.199506296982, Epsilon: 0.828\n",
      "Episode 836 finished after 3001 timesteps\n",
      "Total reward: 16247.01408766965, Epsilon: 0.828\n",
      "Episode 837 finished after 3001 timesteps\n",
      "Total reward: 17551.538408105745, Epsilon: 0.828\n",
      "Episode 838 finished after 3001 timesteps\n",
      "Total reward: 14750.785733241864, Epsilon: 0.828\n",
      "Episode 839 finished after 3001 timesteps\n",
      "Total reward: 18247.413048930266, Epsilon: 0.827\n",
      "Episode 840 finished after 641 timesteps\n",
      "Total reward: 3975.2284818130524, Epsilon: 0.827\n",
      "Episode 841 finished after 510 timesteps\n",
      "Total reward: 3746.4692238330886, Epsilon: 0.827\n",
      "Episode 842 finished after 1233 timesteps\n",
      "Total reward: 10013.957798293854, Epsilon: 0.827\n",
      "Episode 843 finished after 504 timesteps\n",
      "Total reward: 3586.0645059800754, Epsilon: 0.827\n",
      "Episode 844 finished after 3001 timesteps\n",
      "Total reward: 17976.70922311072, Epsilon: 0.827\n",
      "Episode 845 finished after 3001 timesteps\n",
      "Total reward: 17499.211911763112, Epsilon: 0.827\n",
      "Episode 846 finished after 1902 timesteps\n",
      "Total reward: 9936.99552792486, Epsilon: 0.827\n",
      "Episode 847 finished after 2761 timesteps\n",
      "Total reward: 12722.220262014247, Epsilon: 0.827\n",
      "Episode 848 finished after 2840 timesteps\n",
      "Total reward: 14732.9765677144, Epsilon: 0.827\n",
      "Episode 849 finished after 619 timesteps\n",
      "Total reward: 6225.81805188964, Epsilon: 0.827\n",
      "Episode 850 finished after 3001 timesteps\n",
      "Total reward: 14687.37930040571, Epsilon: 0.827\n",
      "Episode 851 finished after 603 timesteps\n",
      "Total reward: 4855.515529538946, Epsilon: 0.826\n",
      "Episode 852 finished after 653 timesteps\n",
      "Total reward: 4987.556413998751, Epsilon: 0.826\n",
      "Episode 853 finished after 1008 timesteps\n",
      "Total reward: 6521.791044654452, Epsilon: 0.826\n",
      "Episode 854 finished after 575 timesteps\n",
      "Total reward: 3496.7690612587508, Epsilon: 0.826\n",
      "Episode 855 finished after 1968 timesteps\n",
      "Total reward: 11294.734886717817, Epsilon: 0.826\n",
      "Episode 856 finished after 2152 timesteps\n",
      "Total reward: 10352.487496782369, Epsilon: 0.826\n",
      "Episode 857 finished after 3001 timesteps\n",
      "Total reward: 13863.15745238078, Epsilon: 0.826\n",
      "Episode 858 finished after 499 timesteps\n",
      "Total reward: 3517.347560784822, Epsilon: 0.826\n",
      "Episode 859 finished after 2505 timesteps\n",
      "Total reward: 13414.026596402444, Epsilon: 0.826\n",
      "Episode 860 finished after 1863 timesteps\n",
      "Total reward: 10407.510766880621, Epsilon: 0.826\n",
      "Episode 861 finished after 1410 timesteps\n",
      "Total reward: 8204.666064430203, Epsilon: 0.826\n",
      "Episode 862 finished after 3001 timesteps\n",
      "Total reward: 14746.9977353557, Epsilon: 0.826\n",
      "Episode 863 finished after 748 timesteps\n",
      "Total reward: 6243.085864004466, Epsilon: 0.826\n",
      "Episode 864 finished after 3001 timesteps\n",
      "Total reward: 17589.9909654584, Epsilon: 0.825\n",
      "Episode 865 finished after 3001 timesteps\n",
      "Total reward: 14359.728545365862, Epsilon: 0.825\n",
      "Episode 866 finished after 2572 timesteps\n",
      "Total reward: 12856.050351010846, Epsilon: 0.825\n",
      "Episode 867 finished after 3001 timesteps\n",
      "Total reward: 14427.064398224249, Epsilon: 0.825\n",
      "Episode 868 finished after 1737 timesteps\n",
      "Total reward: 14607.997789559928, Epsilon: 0.825\n",
      "Episode 869 finished after 801 timesteps\n",
      "Total reward: 6396.2433488637835, Epsilon: 0.825\n",
      "Episode 870 finished after 733 timesteps\n",
      "Total reward: 4932.881714338984, Epsilon: 0.825\n",
      "Episode 871 finished after 1727 timesteps\n",
      "Total reward: 12611.86423654859, Epsilon: 0.825\n",
      "Episode 872 finished after 1797 timesteps\n",
      "Total reward: 10113.709749552781, Epsilon: 0.825\n",
      "Episode 873 finished after 407 timesteps\n",
      "Total reward: 3682.4484518319773, Epsilon: 0.825\n",
      "Episode 874 finished after 1427 timesteps\n",
      "Total reward: 8946.797929159595, Epsilon: 0.825\n",
      "Episode 875 finished after 1867 timesteps\n",
      "Total reward: 14847.651098444683, Epsilon: 0.825\n",
      "Episode 876 finished after 1937 timesteps\n",
      "Total reward: 10059.17955793481, Epsilon: 0.824\n",
      "Episode 877 finished after 1164 timesteps\n",
      "Total reward: 6685.27423673631, Epsilon: 0.824\n",
      "Episode 878 finished after 264 timesteps\n",
      "Total reward: 2525.2319757404985, Epsilon: 0.824\n",
      "Episode 879 finished after 3001 timesteps\n",
      "Total reward: 16464.085039957805, Epsilon: 0.824\n",
      "Episode 880 finished after 2302 timesteps\n",
      "Total reward: 12214.327162640297, Epsilon: 0.824\n",
      "Episode 881 finished after 223 timesteps\n",
      "Total reward: 2143.267884203601, Epsilon: 0.824\n",
      "Episode 882 finished after 3001 timesteps\n",
      "Total reward: 15383.28522792329, Epsilon: 0.824\n",
      "Episode 883 finished after 3001 timesteps\n",
      "Total reward: 17172.611926994112, Epsilon: 0.824\n",
      "Episode 884 finished after 1797 timesteps\n",
      "Total reward: 10037.928640514303, Epsilon: 0.824\n",
      "Episode 885 finished after 197 timesteps\n",
      "Total reward: 1831.1509874083217, Epsilon: 0.824\n",
      "Episode 886 finished after 2231 timesteps\n",
      "Total reward: 11722.268872581899, Epsilon: 0.824\n",
      "Episode 887 finished after 443 timesteps\n",
      "Total reward: 3102.913655537445, Epsilon: 0.824\n",
      "Episode 888 finished after 483 timesteps\n",
      "Total reward: 3160.9625511808295, Epsilon: 0.823\n",
      "Episode 889 finished after 3001 timesteps\n",
      "Total reward: 14302.53350362375, Epsilon: 0.823\n",
      "Episode 890 finished after 644 timesteps\n",
      "Total reward: 5590.307596658372, Epsilon: 0.823\n",
      "Episode 891 finished after 3001 timesteps\n",
      "Total reward: 14421.490935243506, Epsilon: 0.823\n",
      "Episode 892 finished after 2519 timesteps\n",
      "Total reward: 13534.922964338974, Epsilon: 0.823\n",
      "Episode 893 finished after 1988 timesteps\n",
      "Total reward: 10405.127778026112, Epsilon: 0.823\n",
      "Episode 894 finished after 1057 timesteps\n",
      "Total reward: 5627.786411323227, Epsilon: 0.823\n",
      "Episode 895 finished after 2105 timesteps\n",
      "Total reward: 12601.354671245768, Epsilon: 0.823\n",
      "Episode 896 finished after 3001 timesteps\n",
      "Total reward: 14938.628428934488, Epsilon: 0.823\n",
      "Episode 897 finished after 1689 timesteps\n",
      "Total reward: 9590.254974011226, Epsilon: 0.823\n",
      "Episode 898 finished after 1743 timesteps\n",
      "Total reward: 10168.509387621423, Epsilon: 0.823\n",
      "Episode 899 finished after 3001 timesteps\n",
      "Total reward: 14170.358779357106, Epsilon: 0.823\n",
      "Episode 900 finished after 1308 timesteps\n",
      "Total reward: 7991.940392825252, Epsilon: 0.822\n",
      "Episode 901 finished after 191 timesteps\n",
      "Total reward: 1935.154734988392, Epsilon: 0.822\n",
      "Episode 902 finished after 3001 timesteps\n",
      "Total reward: 17172.322039425253, Epsilon: 0.822\n",
      "Episode 903 finished after 3001 timesteps\n",
      "Total reward: 14694.419822898433, Epsilon: 0.822\n",
      "Episode 904 finished after 1252 timesteps\n",
      "Total reward: 7764.692243773855, Epsilon: 0.822\n",
      "Episode 905 finished after 816 timesteps\n",
      "Total reward: 5797.463332309993, Epsilon: 0.822\n",
      "Episode 906 finished after 1057 timesteps\n",
      "Total reward: 9424.418530102404, Epsilon: 0.822\n",
      "Episode 907 finished after 635 timesteps\n",
      "Total reward: 4336.71257195456, Epsilon: 0.822\n",
      "Episode 908 finished after 487 timesteps\n",
      "Total reward: 4153.734385594256, Epsilon: 0.822\n",
      "Episode 909 finished after 1590 timesteps\n",
      "Total reward: 9808.328046564588, Epsilon: 0.822\n",
      "Episode 910 finished after 2206 timesteps\n",
      "Total reward: 12415.711215952582, Epsilon: 0.822\n",
      "Episode 911 finished after 433 timesteps\n",
      "Total reward: 3992.0719195964475, Epsilon: 0.822\n",
      "Episode 912 finished after 2226 timesteps\n",
      "Total reward: 13123.680552663134, Epsilon: 0.821\n",
      "Episode 913 finished after 1299 timesteps\n",
      "Total reward: 7915.767776088232, Epsilon: 0.821\n",
      "Episode 914 finished after 986 timesteps\n",
      "Total reward: 5182.116030518342, Epsilon: 0.821\n",
      "Episode 915 finished after 1199 timesteps\n",
      "Total reward: 7763.078930284306, Epsilon: 0.821\n",
      "Episode 916 finished after 1558 timesteps\n",
      "Total reward: 10710.296620873596, Epsilon: 0.821\n",
      "Episode 917 finished after 3001 timesteps\n",
      "Total reward: 14571.368975484287, Epsilon: 0.821\n",
      "Episode 918 finished after 1550 timesteps\n",
      "Total reward: 8854.993486785726, Epsilon: 0.821\n",
      "Episode 919 finished after 243 timesteps\n",
      "Total reward: 2297.750185820242, Epsilon: 0.821\n",
      "Episode 920 finished after 2592 timesteps\n",
      "Total reward: 13521.10339760837, Epsilon: 0.821\n",
      "Episode 921 finished after 1169 timesteps\n",
      "Total reward: 6797.521771907883, Epsilon: 0.821\n",
      "Episode 922 finished after 1471 timesteps\n",
      "Total reward: 7432.24047912446, Epsilon: 0.821\n",
      "Episode 923 finished after 3001 timesteps\n",
      "Total reward: 13970.676820229717, Epsilon: 0.821\n",
      "Episode 924 finished after 696 timesteps\n",
      "Total reward: 5469.933840466262, Epsilon: 0.820\n",
      "Episode 925 finished after 1045 timesteps\n",
      "Total reward: 5899.599099152868, Epsilon: 0.820\n",
      "Episode 926 finished after 3001 timesteps\n",
      "Total reward: 14819.21280504888, Epsilon: 0.820\n",
      "Episode 927 finished after 565 timesteps\n",
      "Total reward: 3770.946567165608, Epsilon: 0.820\n",
      "Episode 928 finished after 3001 timesteps\n",
      "Total reward: 13942.791493988476, Epsilon: 0.820\n",
      "Episode 929 finished after 565 timesteps\n",
      "Total reward: 4269.212254408594, Epsilon: 0.820\n",
      "Episode 930 finished after 2219 timesteps\n",
      "Total reward: 14226.533269293228, Epsilon: 0.820\n",
      "Episode 931 finished after 2047 timesteps\n",
      "Total reward: 11557.663339498726, Epsilon: 0.820\n",
      "Episode 932 finished after 3001 timesteps\n",
      "Total reward: 15267.876591015573, Epsilon: 0.820\n",
      "Episode 933 finished after 2401 timesteps\n",
      "Total reward: 15576.147282026204, Epsilon: 0.820\n",
      "Episode 934 finished after 2175 timesteps\n",
      "Total reward: 13599.919571141067, Epsilon: 0.820\n",
      "Episode 935 finished after 2453 timesteps\n",
      "Total reward: 14007.944392420477, Epsilon: 0.820\n",
      "Episode 936 finished after 559 timesteps\n",
      "Total reward: 4948.913650025232, Epsilon: 0.819\n",
      "Episode 937 finished after 3001 timesteps\n",
      "Total reward: 15018.13341207492, Epsilon: 0.819\n",
      "Episode 938 finished after 2923 timesteps\n",
      "Total reward: 15440.23345928064, Epsilon: 0.819\n",
      "Episode 939 finished after 2128 timesteps\n",
      "Total reward: 13866.041652183852, Epsilon: 0.819\n",
      "Episode 940 finished after 492 timesteps\n",
      "Total reward: 3185.84827376648, Epsilon: 0.819\n",
      "Episode 941 finished after 642 timesteps\n",
      "Total reward: 4088.6093170676236, Epsilon: 0.819\n",
      "Episode 942 finished after 1641 timesteps\n",
      "Total reward: 9234.797037667273, Epsilon: 0.819\n",
      "Episode 943 finished after 1225 timesteps\n",
      "Total reward: 6223.701411911763, Epsilon: 0.819\n",
      "Episode 944 finished after 976 timesteps\n",
      "Total reward: 5663.878647212139, Epsilon: 0.819\n",
      "Episode 945 finished after 1257 timesteps\n",
      "Total reward: 6251.581189926681, Epsilon: 0.819\n",
      "Episode 946 finished after 660 timesteps\n",
      "Total reward: 5048.943855220631, Epsilon: 0.819\n",
      "Episode 947 finished after 1010 timesteps\n",
      "Total reward: 5118.525974245266, Epsilon: 0.819\n",
      "Episode 948 finished after 453 timesteps\n",
      "Total reward: 3400.5640291370673, Epsilon: 0.819\n",
      "Episode 949 finished after 301 timesteps\n",
      "Total reward: 2697.3923538524577, Epsilon: 0.818\n",
      "Episode 950 finished after 1083 timesteps\n",
      "Total reward: 7696.5532361818205, Epsilon: 0.818\n",
      "Episode 951 finished after 3001 timesteps\n",
      "Total reward: 14476.742755045916, Epsilon: 0.818\n",
      "Episode 952 finished after 3001 timesteps\n",
      "Total reward: 14158.638218897511, Epsilon: 0.818\n",
      "Episode 953 finished after 476 timesteps\n",
      "Total reward: 3693.0862858717746, Epsilon: 0.818\n",
      "Episode 954 finished after 499 timesteps\n",
      "Total reward: 3461.03015901166, Epsilon: 0.818\n",
      "Episode 955 finished after 743 timesteps\n",
      "Total reward: 5857.98644770364, Epsilon: 0.818\n",
      "Episode 956 finished after 3001 timesteps\n",
      "Total reward: 14477.52207594435, Epsilon: 0.818\n",
      "Episode 957 finished after 272 timesteps\n",
      "Total reward: 2485.2578457562754, Epsilon: 0.818\n",
      "Episode 958 finished after 418 timesteps\n",
      "Total reward: 3509.5154417458975, Epsilon: 0.818\n",
      "Episode 959 finished after 3001 timesteps\n",
      "Total reward: 14703.160832809117, Epsilon: 0.818\n",
      "Episode 960 finished after 1109 timesteps\n",
      "Total reward: 6167.156658198051, Epsilon: 0.818\n",
      "Episode 961 finished after 3001 timesteps\n",
      "Total reward: 13965.143894571804, Epsilon: 0.817\n",
      "Episode 962 finished after 3001 timesteps\n",
      "Total reward: 14191.85336119768, Epsilon: 0.817\n",
      "Episode 963 finished after 2215 timesteps\n",
      "Total reward: 11438.896301900324, Epsilon: 0.817\n",
      "Episode 964 finished after 688 timesteps\n",
      "Total reward: 5793.751034443894, Epsilon: 0.817\n",
      "Episode 965 finished after 1911 timesteps\n",
      "Total reward: 9564.646747589251, Epsilon: 0.817\n",
      "Episode 966 finished after 911 timesteps\n",
      "Total reward: 4821.103275414919, Epsilon: 0.817\n",
      "Episode 967 finished after 3001 timesteps\n",
      "Total reward: 15464.209381254139, Epsilon: 0.817\n",
      "Episode 968 finished after 1532 timesteps\n",
      "Total reward: 8339.09464671039, Epsilon: 0.817\n",
      "Episode 969 finished after 3001 timesteps\n",
      "Total reward: 13668.520101401871, Epsilon: 0.817\n",
      "Episode 970 finished after 3001 timesteps\n",
      "Total reward: 17313.84828072389, Epsilon: 0.817\n",
      "Episode 971 finished after 1078 timesteps\n",
      "Total reward: 5844.912721906323, Epsilon: 0.817\n",
      "Episode 972 finished after 472 timesteps\n",
      "Total reward: 3420.51431985353, Epsilon: 0.817\n",
      "Episode 973 finished after 2288 timesteps\n",
      "Total reward: 14771.046027681232, Epsilon: 0.816\n",
      "Episode 974 finished after 775 timesteps\n",
      "Total reward: 4399.803942145532, Epsilon: 0.816\n",
      "Episode 975 finished after 3001 timesteps\n",
      "Total reward: 14888.866887704664, Epsilon: 0.816\n",
      "Episode 976 finished after 2755 timesteps\n",
      "Total reward: 13916.903207332662, Epsilon: 0.816\n",
      "Episode 977 finished after 231 timesteps\n",
      "Total reward: 2849.538154549926, Epsilon: 0.816\n",
      "Episode 978 finished after 3001 timesteps\n",
      "Total reward: 16643.963172289863, Epsilon: 0.816\n",
      "Episode 979 finished after 3001 timesteps\n",
      "Total reward: 16932.098972151583, Epsilon: 0.816\n",
      "Episode 980 finished after 635 timesteps\n",
      "Total reward: 5058.772341567658, Epsilon: 0.816\n",
      "Episode 981 finished after 3001 timesteps\n",
      "Total reward: 13676.213603222383, Epsilon: 0.816\n",
      "Episode 982 finished after 792 timesteps\n",
      "Total reward: 4208.134355194041, Epsilon: 0.816\n",
      "Episode 983 finished after 2346 timesteps\n",
      "Total reward: 13885.276292750552, Epsilon: 0.816\n",
      "Episode 984 finished after 1971 timesteps\n",
      "Total reward: 12656.742798298243, Epsilon: 0.816\n",
      "Episode 985 finished after 1465 timesteps\n",
      "Total reward: 10741.720735347015, Epsilon: 0.815\n",
      "Episode 986 finished after 457 timesteps\n",
      "Total reward: 3603.2962584786146, Epsilon: 0.815\n",
      "Episode 987 finished after 2504 timesteps\n",
      "Total reward: 11757.065655531675, Epsilon: 0.815\n",
      "Episode 988 finished after 3001 timesteps\n",
      "Total reward: 16151.34998751879, Epsilon: 0.815\n",
      "Episode 989 finished after 2853 timesteps\n",
      "Total reward: 19006.849649023643, Epsilon: 0.815\n",
      "Episode 990 finished after 850 timesteps\n",
      "Total reward: 5629.38583129758, Epsilon: 0.815\n",
      "Episode 991 finished after 2886 timesteps\n",
      "Total reward: 14659.099538529317, Epsilon: 0.815\n",
      "Episode 992 finished after 1669 timesteps\n",
      "Total reward: 8892.911729701349, Epsilon: 0.815\n",
      "Episode 993 finished after 2344 timesteps\n",
      "Total reward: 14337.580775506442, Epsilon: 0.815\n",
      "Episode 994 finished after 2137 timesteps\n",
      "Total reward: 12215.841073371483, Epsilon: 0.815\n",
      "Episode 995 finished after 3001 timesteps\n",
      "Total reward: 14003.653891512005, Epsilon: 0.815\n",
      "Episode 996 finished after 953 timesteps\n",
      "Total reward: 7376.611616343032, Epsilon: 0.815\n",
      "Episode 997 finished after 3001 timesteps\n",
      "Total reward: 17920.723322227837, Epsilon: 0.815\n",
      "Episode 998 finished after 1061 timesteps\n",
      "Total reward: 8139.221268714162, Epsilon: 0.814\n",
      "Episode 999 finished after 1991 timesteps\n",
      "Total reward: 14707.066950445336, Epsilon: 0.814\n",
      "Episode 1000 finished after 1505 timesteps\n",
      "Total reward: 7614.85801304548, Epsilon: 0.814\n",
      "Episode 1001 finished after 728 timesteps\n",
      "Total reward: 5928.155094669653, Epsilon: 0.814\n",
      "Episode 1002 finished after 1579 timesteps\n",
      "Total reward: 11447.497986796923, Epsilon: 0.814\n",
      "Episode 1003 finished after 158 timesteps\n",
      "Total reward: 1635.4449230329124, Epsilon: 0.814\n",
      "Episode 1004 finished after 678 timesteps\n",
      "Total reward: 4539.438365417807, Epsilon: 0.814\n",
      "Episode 1005 finished after 1446 timesteps\n",
      "Total reward: 7513.581083072476, Epsilon: 0.814\n",
      "Episode 1006 finished after 656 timesteps\n",
      "Total reward: 3694.281809163147, Epsilon: 0.814\n",
      "Episode 1007 finished after 707 timesteps\n",
      "Total reward: 4395.981068439056, Epsilon: 0.814\n",
      "Episode 1008 finished after 1784 timesteps\n",
      "Total reward: 11055.177659228768, Epsilon: 0.814\n",
      "Episode 1009 finished after 822 timesteps\n",
      "Total reward: 5640.345721314396, Epsilon: 0.814\n",
      "Episode 1010 finished after 881 timesteps\n",
      "Total reward: 7051.345980278419, Epsilon: 0.813\n",
      "Episode 1011 finished after 3001 timesteps\n",
      "Total reward: 15043.70974440005, Epsilon: 0.813\n",
      "Episode 1012 finished after 1175 timesteps\n",
      "Total reward: 7108.925282412108, Epsilon: 0.813\n",
      "Episode 1013 finished after 2865 timesteps\n",
      "Total reward: 19237.07895379881, Epsilon: 0.813\n",
      "Episode 1014 finished after 626 timesteps\n",
      "Total reward: 4456.562763990257, Epsilon: 0.813\n",
      "Episode 1015 finished after 253 timesteps\n",
      "Total reward: 2447.9362413355716, Epsilon: 0.813\n",
      "Episode 1016 finished after 3001 timesteps\n",
      "Total reward: 17093.98305965221, Epsilon: 0.813\n",
      "Episode 1017 finished after 554 timesteps\n",
      "Total reward: 3932.9720117189445, Epsilon: 0.813\n",
      "Episode 1018 finished after 1575 timesteps\n",
      "Total reward: 8575.02847374468, Epsilon: 0.813\n",
      "Episode 1019 finished after 877 timesteps\n",
      "Total reward: 5210.6629681885925, Epsilon: 0.813\n",
      "Episode 1020 finished after 504 timesteps\n",
      "Total reward: 3464.9957804838778, Epsilon: 0.813\n",
      "Episode 1021 finished after 1723 timesteps\n",
      "Total reward: 8984.733007683555, Epsilon: 0.813\n",
      "Episode 1022 finished after 859 timesteps\n",
      "Total reward: 5293.219388410629, Epsilon: 0.812\n",
      "Episode 1023 finished after 2529 timesteps\n",
      "Total reward: 17145.60113155777, Epsilon: 0.812\n",
      "Episode 1024 finished after 1472 timesteps\n",
      "Total reward: 9298.130751782172, Epsilon: 0.812\n",
      "Episode 1025 finished after 115 timesteps\n",
      "Total reward: 1496.9499456684382, Epsilon: 0.812\n",
      "Episode 1026 finished after 2533 timesteps\n",
      "Total reward: 15776.027059554142, Epsilon: 0.812\n",
      "Episode 1027 finished after 1677 timesteps\n",
      "Total reward: 10660.42279447737, Epsilon: 0.812\n",
      "Episode 1028 finished after 1192 timesteps\n",
      "Total reward: 6775.975525389191, Epsilon: 0.812\n",
      "Episode 1029 finished after 1274 timesteps\n",
      "Total reward: 8240.481323454746, Epsilon: 0.812\n",
      "Episode 1030 finished after 746 timesteps\n",
      "Total reward: 7819.6270659232805, Epsilon: 0.812\n",
      "Episode 1031 finished after 1166 timesteps\n",
      "Total reward: 7374.028850709391, Epsilon: 0.812\n",
      "Episode 1032 finished after 1736 timesteps\n",
      "Total reward: 8342.999166120404, Epsilon: 0.812\n",
      "Episode 1033 finished after 1948 timesteps\n",
      "Total reward: 10444.30823849261, Epsilon: 0.812\n",
      "Episode 1034 finished after 2603 timesteps\n",
      "Total reward: 15658.976960941534, Epsilon: 0.812\n",
      "Episode 1035 finished after 968 timesteps\n",
      "Total reward: 5592.618616077776, Epsilon: 0.811\n",
      "Episode 1036 finished after 3001 timesteps\n",
      "Total reward: 17535.002912606367, Epsilon: 0.811\n",
      "Episode 1037 finished after 2711 timesteps\n",
      "Total reward: 15827.10871295296, Epsilon: 0.811\n",
      "Episode 1038 finished after 2879 timesteps\n",
      "Total reward: 15223.390193016576, Epsilon: 0.811\n",
      "Episode 1039 finished after 3001 timesteps\n",
      "Total reward: 15228.946031015823, Epsilon: 0.811\n",
      "Episode 1040 finished after 314 timesteps\n",
      "Total reward: 2409.0822893921118, Epsilon: 0.811\n",
      "Episode 1041 finished after 3001 timesteps\n",
      "Total reward: 17126.400491032677, Epsilon: 0.811\n",
      "Episode 1042 finished after 1921 timesteps\n",
      "Total reward: 11391.022144512777, Epsilon: 0.811\n",
      "Episode 1043 finished after 950 timesteps\n",
      "Total reward: 7248.214273536678, Epsilon: 0.811\n",
      "Episode 1044 finished after 2427 timesteps\n",
      "Total reward: 12626.84511820365, Epsilon: 0.811\n",
      "Episode 1045 finished after 3001 timesteps\n",
      "Total reward: 14198.820330255887, Epsilon: 0.811\n",
      "Episode 1046 finished after 2956 timesteps\n",
      "Total reward: 15288.461300221185, Epsilon: 0.811\n",
      "Episode 1047 finished after 215 timesteps\n",
      "Total reward: 2004.518536254109, Epsilon: 0.810\n",
      "Episode 1048 finished after 2359 timesteps\n",
      "Total reward: 12930.992661623437, Epsilon: 0.810\n",
      "Episode 1049 finished after 746 timesteps\n",
      "Total reward: 7742.581439012265, Epsilon: 0.810\n",
      "Episode 1050 finished after 1105 timesteps\n",
      "Total reward: 6810.8857246095495, Epsilon: 0.810\n",
      "Episode 1051 finished after 768 timesteps\n",
      "Total reward: 5432.242249844183, Epsilon: 0.810\n",
      "Episode 1052 finished after 667 timesteps\n",
      "Total reward: 5074.565161558332, Epsilon: 0.810\n",
      "Episode 1053 finished after 3001 timesteps\n",
      "Total reward: 14316.240362558734, Epsilon: 0.810\n",
      "Episode 1054 finished after 3001 timesteps\n",
      "Total reward: 15238.624928184181, Epsilon: 0.810\n",
      "Episode 1055 finished after 445 timesteps\n",
      "Total reward: 3810.9355951570965, Epsilon: 0.810\n",
      "Episode 1056 finished after 1572 timesteps\n",
      "Total reward: 8337.535927170798, Epsilon: 0.810\n",
      "Episode 1057 finished after 1341 timesteps\n",
      "Total reward: 6654.248389802237, Epsilon: 0.810\n",
      "Episode 1058 finished after 2319 timesteps\n",
      "Total reward: 12887.431928018232, Epsilon: 0.810\n",
      "Episode 1059 finished after 1250 timesteps\n",
      "Total reward: 6697.984055567273, Epsilon: 0.809\n",
      "Episode 1060 finished after 962 timesteps\n",
      "Total reward: 6628.774971403279, Epsilon: 0.809\n",
      "Episode 1061 finished after 734 timesteps\n",
      "Total reward: 5077.461571763663, Epsilon: 0.809\n",
      "Episode 1062 finished after 431 timesteps\n",
      "Total reward: 3937.4979299095544, Epsilon: 0.809\n",
      "Episode 1063 finished after 1734 timesteps\n",
      "Total reward: 13000.455272247757, Epsilon: 0.809\n",
      "Episode 1064 finished after 3001 timesteps\n",
      "Total reward: 14688.860355616971, Epsilon: 0.809\n",
      "Episode 1065 finished after 874 timesteps\n",
      "Total reward: 6354.050079725658, Epsilon: 0.809\n",
      "Episode 1066 finished after 2802 timesteps\n",
      "Total reward: 16338.984154951162, Epsilon: 0.809\n",
      "Episode 1067 finished after 875 timesteps\n",
      "Total reward: 6695.882643091045, Epsilon: 0.809\n",
      "Episode 1068 finished after 693 timesteps\n",
      "Total reward: 4586.174431027241, Epsilon: 0.809\n",
      "Episode 1069 finished after 3001 timesteps\n",
      "Total reward: 14548.990548937734, Epsilon: 0.809\n",
      "Episode 1070 finished after 2648 timesteps\n",
      "Total reward: 14201.001872281182, Epsilon: 0.809\n",
      "Episode 1071 finished after 1221 timesteps\n",
      "Total reward: 9334.303238062703, Epsilon: 0.809\n",
      "Episode 1072 finished after 3001 timesteps\n",
      "Total reward: 15636.282097296616, Epsilon: 0.808\n",
      "Episode 1073 finished after 1924 timesteps\n",
      "Total reward: 13065.346299581339, Epsilon: 0.808\n",
      "Episode 1074 finished after 2656 timesteps\n",
      "Total reward: 14056.601231924824, Epsilon: 0.808\n",
      "Episode 1075 finished after 3001 timesteps\n",
      "Total reward: 13320.615636886127, Epsilon: 0.808\n",
      "Episode 1076 finished after 3001 timesteps\n",
      "Total reward: 13360.059298027294, Epsilon: 0.808\n",
      "Episode 1077 finished after 3001 timesteps\n",
      "Total reward: 15732.632536182493, Epsilon: 0.808\n",
      "Episode 1078 finished after 1022 timesteps\n",
      "Total reward: 8677.566596657185, Epsilon: 0.808\n",
      "Episode 1079 finished after 1082 timesteps\n",
      "Total reward: 8294.007645921358, Epsilon: 0.808\n",
      "Episode 1080 finished after 1281 timesteps\n",
      "Total reward: 9498.076516689001, Epsilon: 0.808\n",
      "Episode 1081 finished after 3001 timesteps\n",
      "Total reward: 16628.474356961466, Epsilon: 0.808\n",
      "Episode 1082 finished after 907 timesteps\n",
      "Total reward: 6634.59469598372, Epsilon: 0.808\n",
      "Episode 1083 finished after 1435 timesteps\n",
      "Total reward: 8692.692071952295, Epsilon: 0.808\n",
      "Episode 1084 finished after 3001 timesteps\n",
      "Total reward: 13807.21980494569, Epsilon: 0.807\n",
      "Episode 1085 finished after 1568 timesteps\n",
      "Total reward: 10871.769132722302, Epsilon: 0.807\n",
      "Episode 1086 finished after 1202 timesteps\n",
      "Total reward: 5711.932113212584, Epsilon: 0.807\n",
      "Episode 1087 finished after 3001 timesteps\n",
      "Total reward: 16354.119969430458, Epsilon: 0.807\n",
      "Episode 1088 finished after 2599 timesteps\n",
      "Total reward: 17418.639625784668, Epsilon: 0.807\n",
      "Episode 1089 finished after 851 timesteps\n",
      "Total reward: 6154.183335699626, Epsilon: 0.807\n",
      "Episode 1090 finished after 2030 timesteps\n",
      "Total reward: 13324.813105567253, Epsilon: 0.807\n",
      "Episode 1091 finished after 2241 timesteps\n",
      "Total reward: 11704.018650006943, Epsilon: 0.807\n",
      "Episode 1092 finished after 824 timesteps\n",
      "Total reward: 4516.79901401607, Epsilon: 0.807\n",
      "Episode 1093 finished after 594 timesteps\n",
      "Total reward: 4282.890478456138, Epsilon: 0.807\n",
      "Episode 1094 finished after 2964 timesteps\n",
      "Total reward: 14765.019793611396, Epsilon: 0.807\n",
      "Episode 1095 finished after 1118 timesteps\n",
      "Total reward: 6534.863528471135, Epsilon: 0.807\n",
      "Episode 1096 finished after 2989 timesteps\n",
      "Total reward: 15455.703919213993, Epsilon: 0.806\n",
      "Episode 1097 finished after 2639 timesteps\n",
      "Total reward: 13320.293283172025, Epsilon: 0.806\n",
      "Episode 1098 finished after 1249 timesteps\n",
      "Total reward: 9337.780166367862, Epsilon: 0.806\n",
      "Episode 1099 finished after 567 timesteps\n",
      "Total reward: 4944.258483350299, Epsilon: 0.806\n",
      "Episode 1100 finished after 1426 timesteps\n",
      "Total reward: 9258.605888092841, Epsilon: 0.806\n",
      "Episode 1101 finished after 511 timesteps\n",
      "Total reward: 3432.939239778297, Epsilon: 0.806\n",
      "Episode 1102 finished after 3001 timesteps\n",
      "Total reward: 15634.270489611046, Epsilon: 0.806\n",
      "Episode 1103 finished after 778 timesteps\n",
      "Total reward: 6361.653587163327, Epsilon: 0.806\n",
      "Episode 1104 finished after 1509 timesteps\n",
      "Total reward: 8408.896736595183, Epsilon: 0.806\n",
      "Episode 1105 finished after 1141 timesteps\n",
      "Total reward: 6420.599245316799, Epsilon: 0.806\n",
      "Episode 1106 finished after 2405 timesteps\n",
      "Total reward: 13593.435135927066, Epsilon: 0.806\n",
      "Episode 1107 finished after 1596 timesteps\n",
      "Total reward: 9427.38925174705, Epsilon: 0.806\n",
      "Episode 1108 finished after 608 timesteps\n",
      "Total reward: 4177.2452012470385, Epsilon: 0.806\n",
      "Episode 1109 finished after 2429 timesteps\n",
      "Total reward: 12476.188991753372, Epsilon: 0.805\n",
      "Episode 1110 finished after 664 timesteps\n",
      "Total reward: 4514.4745712140675, Epsilon: 0.805\n",
      "Episode 1111 finished after 1366 timesteps\n",
      "Total reward: 11113.704697375859, Epsilon: 0.805\n",
      "Episode 1112 finished after 1569 timesteps\n",
      "Total reward: 10310.83462573414, Epsilon: 0.805\n",
      "Episode 1113 finished after 1766 timesteps\n",
      "Total reward: 9272.294775706716, Epsilon: 0.805\n",
      "Episode 1114 finished after 3001 timesteps\n",
      "Total reward: 14819.793560998845, Epsilon: 0.805\n",
      "Episode 1115 finished after 1173 timesteps\n",
      "Total reward: 7910.978114127574, Epsilon: 0.805\n",
      "Episode 1116 finished after 2146 timesteps\n",
      "Total reward: 13673.640003924927, Epsilon: 0.805\n",
      "Episode 1117 finished after 3001 timesteps\n",
      "Total reward: 15581.620597645728, Epsilon: 0.805\n",
      "Episode 1118 finished after 996 timesteps\n",
      "Total reward: 7434.547239910596, Epsilon: 0.805\n",
      "Episode 1119 finished after 509 timesteps\n",
      "Total reward: 3996.736355139154, Epsilon: 0.805\n",
      "Episode 1120 finished after 703 timesteps\n",
      "Total reward: 4753.86404614218, Epsilon: 0.805\n",
      "Episode 1121 finished after 735 timesteps\n",
      "Total reward: 5610.01372310177, Epsilon: 0.804\n",
      "Episode 1122 finished after 3001 timesteps\n",
      "Total reward: 17096.609292856807, Epsilon: 0.804\n",
      "Episode 1123 finished after 774 timesteps\n",
      "Total reward: 4364.023803804229, Epsilon: 0.804\n",
      "Episode 1124 finished after 3001 timesteps\n",
      "Total reward: 14576.557734609172, Epsilon: 0.804\n",
      "Episode 1125 finished after 292 timesteps\n",
      "Total reward: 2485.596108078913, Epsilon: 0.804\n",
      "Episode 1126 finished after 2840 timesteps\n",
      "Total reward: 15014.085827609077, Epsilon: 0.804\n",
      "Episode 1127 finished after 1804 timesteps\n",
      "Total reward: 12148.900165729969, Epsilon: 0.804\n",
      "Episode 1128 finished after 1882 timesteps\n",
      "Total reward: 11990.012499492123, Epsilon: 0.804\n",
      "Episode 1129 finished after 2342 timesteps\n",
      "Total reward: 12127.624123423491, Epsilon: 0.804\n",
      "Episode 1130 finished after 1159 timesteps\n",
      "Total reward: 5952.860831497434, Epsilon: 0.804\n",
      "Episode 1131 finished after 3001 timesteps\n",
      "Total reward: 16548.641493335475, Epsilon: 0.804\n",
      "Episode 1132 finished after 2419 timesteps\n",
      "Total reward: 12266.25062869003, Epsilon: 0.804\n",
      "Episode 1133 finished after 844 timesteps\n",
      "Total reward: 4998.729320587677, Epsilon: 0.804\n",
      "Episode 1134 finished after 2470 timesteps\n",
      "Total reward: 13920.120621718832, Epsilon: 0.803\n",
      "Episode 1135 finished after 1655 timesteps\n",
      "Total reward: 10140.23303981211, Epsilon: 0.803\n",
      "Episode 1136 finished after 3001 timesteps\n",
      "Total reward: 19015.22584267226, Epsilon: 0.803\n",
      "Episode 1137 finished after 511 timesteps\n",
      "Total reward: 4629.241853394022, Epsilon: 0.803\n",
      "Episode 1138 finished after 958 timesteps\n",
      "Total reward: 6421.141142679475, Epsilon: 0.803\n",
      "Episode 1139 finished after 3001 timesteps\n",
      "Total reward: 12729.702736200677, Epsilon: 0.803\n",
      "Episode 1140 finished after 2045 timesteps\n",
      "Total reward: 10711.165800385405, Epsilon: 0.803\n",
      "Episode 1141 finished after 743 timesteps\n",
      "Total reward: 4559.47525422574, Epsilon: 0.803\n",
      "Episode 1142 finished after 948 timesteps\n",
      "Total reward: 5956.534563344556, Epsilon: 0.803\n",
      "Episode 1143 finished after 615 timesteps\n",
      "Total reward: 4207.952724355886, Epsilon: 0.803\n",
      "Episode 1144 finished after 449 timesteps\n",
      "Total reward: 4177.849896598555, Epsilon: 0.803\n",
      "Episode 1145 finished after 2969 timesteps\n",
      "Total reward: 14696.49614876455, Epsilon: 0.803\n",
      "Episode 1146 finished after 2482 timesteps\n",
      "Total reward: 17390.9719964977, Epsilon: 0.802\n",
      "Episode 1147 finished after 3001 timesteps\n",
      "Total reward: 15244.70087716188, Epsilon: 0.802\n",
      "Episode 1148 finished after 1245 timesteps\n",
      "Total reward: 6813.843483662851, Epsilon: 0.802\n",
      "Episode 1149 finished after 1648 timesteps\n",
      "Total reward: 10653.525694989588, Epsilon: 0.802\n",
      "Episode 1150 finished after 2110 timesteps\n",
      "Total reward: 11313.160167087713, Epsilon: 0.802\n",
      "Episode 1151 finished after 1170 timesteps\n",
      "Total reward: 7424.750860018559, Epsilon: 0.802\n",
      "Episode 1152 finished after 1645 timesteps\n",
      "Total reward: 11950.628722603997, Epsilon: 0.802\n",
      "Episode 1153 finished after 1441 timesteps\n",
      "Total reward: 7807.476218838, Epsilon: 0.802\n",
      "Episode 1154 finished after 3001 timesteps\n",
      "Total reward: 13928.422325419277, Epsilon: 0.802\n",
      "Episode 1155 finished after 3001 timesteps\n",
      "Total reward: 14916.200557773729, Epsilon: 0.802\n",
      "Episode 1156 finished after 267 timesteps\n",
      "Total reward: 2648.677980548202, Epsilon: 0.802\n",
      "Episode 1157 finished after 533 timesteps\n",
      "Total reward: 3930.3143498953996, Epsilon: 0.802\n",
      "Episode 1158 finished after 2054 timesteps\n",
      "Total reward: 16253.004983525976, Epsilon: 0.802\n",
      "Episode 1159 finished after 650 timesteps\n",
      "Total reward: 4689.39903946767, Epsilon: 0.801\n",
      "Episode 1160 finished after 2276 timesteps\n",
      "Total reward: 12564.054812049239, Epsilon: 0.801\n",
      "Episode 1161 finished after 2138 timesteps\n",
      "Total reward: 14020.207943211124, Epsilon: 0.801\n",
      "Episode 1162 finished after 2530 timesteps\n",
      "Total reward: 12439.923883188703, Epsilon: 0.801\n",
      "Episode 1163 finished after 3001 timesteps\n",
      "Total reward: 17556.902832601347, Epsilon: 0.801\n",
      "Episode 1164 finished after 331 timesteps\n",
      "Total reward: 2549.487463927025, Epsilon: 0.801\n",
      "Episode 1165 finished after 956 timesteps\n",
      "Total reward: 5591.343801573825, Epsilon: 0.801\n",
      "Episode 1166 finished after 2627 timesteps\n",
      "Total reward: 16875.829718923986, Epsilon: 0.801\n",
      "Episode 1167 finished after 1159 timesteps\n",
      "Total reward: 7113.969133643193, Epsilon: 0.801\n",
      "Episode 1168 finished after 478 timesteps\n",
      "Total reward: 3682.831059623588, Epsilon: 0.801\n",
      "Episode 1169 finished after 1205 timesteps\n",
      "Total reward: 9751.208050117999, Epsilon: 0.801\n",
      "Episode 1170 finished after 1023 timesteps\n",
      "Total reward: 5685.498516161978, Epsilon: 0.801\n",
      "Episode 1171 finished after 477 timesteps\n",
      "Total reward: 3302.0577222044117, Epsilon: 0.800\n",
      "Episode 1172 finished after 3001 timesteps\n",
      "Total reward: 14681.291762459918, Epsilon: 0.800\n",
      "Episode 1173 finished after 1528 timesteps\n",
      "Total reward: 8489.2256790147, Epsilon: 0.800\n",
      "Episode 1174 finished after 504 timesteps\n",
      "Total reward: 3791.2516302140293, Epsilon: 0.800\n",
      "Episode 1175 finished after 858 timesteps\n",
      "Total reward: 7200.5456061363275, Epsilon: 0.800\n",
      "Episode 1176 finished after 2582 timesteps\n",
      "Total reward: 16757.48422142081, Epsilon: 0.800\n",
      "Episode 1177 finished after 2453 timesteps\n",
      "Total reward: 13543.373202437348, Epsilon: 0.800\n",
      "Episode 1178 finished after 1324 timesteps\n",
      "Total reward: 7160.585643194382, Epsilon: 0.800\n",
      "Episode 1179 finished after 1534 timesteps\n",
      "Total reward: 11029.246554398922, Epsilon: 0.800\n",
      "Episode 1180 finished after 499 timesteps\n",
      "Total reward: 3796.6889378830733, Epsilon: 0.800\n",
      "Episode 1181 finished after 730 timesteps\n",
      "Total reward: 5241.635778821697, Epsilon: 0.800\n",
      "Episode 1182 finished after 1153 timesteps\n",
      "Total reward: 6407.6884602127875, Epsilon: 0.800\n",
      "Episode 1183 finished after 914 timesteps\n",
      "Total reward: 5493.03720873158, Epsilon: 0.800\n",
      "Episode 1184 finished after 981 timesteps\n",
      "Total reward: 6796.734489860609, Epsilon: 0.799\n",
      "Episode 1185 finished after 440 timesteps\n",
      "Total reward: 3600.1677393462087, Epsilon: 0.799\n",
      "Episode 1186 finished after 690 timesteps\n",
      "Total reward: 4679.740590677089, Epsilon: 0.799\n",
      "Episode 1187 finished after 271 timesteps\n",
      "Total reward: 2382.7968486674254, Epsilon: 0.799\n",
      "Episode 1188 finished after 2483 timesteps\n",
      "Total reward: 13114.509638871044, Epsilon: 0.799\n",
      "Episode 1189 finished after 1907 timesteps\n",
      "Total reward: 10767.63008134839, Epsilon: 0.799\n",
      "Episode 1190 finished after 294 timesteps\n",
      "Total reward: 2605.3120803629545, Epsilon: 0.799\n",
      "Episode 1191 finished after 3001 timesteps\n",
      "Total reward: 13517.457514959066, Epsilon: 0.799\n",
      "Episode 1192 finished after 496 timesteps\n",
      "Total reward: 3552.169014653837, Epsilon: 0.799\n",
      "Episode 1193 finished after 3001 timesteps\n",
      "Total reward: 13334.830005695196, Epsilon: 0.799\n",
      "Episode 1194 finished after 1429 timesteps\n",
      "Total reward: 8662.227372464706, Epsilon: 0.799\n",
      "Episode 1195 finished after 2739 timesteps\n",
      "Total reward: 14870.263704187802, Epsilon: 0.799\n",
      "Episode 1196 finished after 964 timesteps\n",
      "Total reward: 5308.782115043712, Epsilon: 0.798\n",
      "Episode 1197 finished after 634 timesteps\n",
      "Total reward: 6023.413679750176, Epsilon: 0.798\n",
      "Episode 1198 finished after 3001 timesteps\n",
      "Total reward: 13880.079599772967, Epsilon: 0.798\n",
      "Episode 1199 finished after 413 timesteps\n",
      "Total reward: 3527.600786216847, Epsilon: 0.798\n",
      "Episode 1200 finished after 2454 timesteps\n",
      "Total reward: 13476.270616727883, Epsilon: 0.798\n",
      "Episode 1201 finished after 1008 timesteps\n",
      "Total reward: 5905.68342769988, Epsilon: 0.798\n",
      "Episode 1202 finished after 1510 timesteps\n",
      "Total reward: 11585.343839826655, Epsilon: 0.798\n",
      "Episode 1203 finished after 1639 timesteps\n",
      "Total reward: 10316.203026991285, Epsilon: 0.798\n",
      "Episode 1204 finished after 442 timesteps\n",
      "Total reward: 5435.761648803848, Epsilon: 0.798\n",
      "Episode 1205 finished after 3001 timesteps\n",
      "Total reward: 18540.783516360225, Epsilon: 0.798\n",
      "Episode 1206 finished after 1788 timesteps\n",
      "Total reward: 11428.467122646876, Epsilon: 0.798\n",
      "Episode 1207 finished after 2540 timesteps\n",
      "Total reward: 16047.621328921921, Epsilon: 0.798\n",
      "Episode 1208 finished after 1734 timesteps\n",
      "Total reward: 9475.52910155589, Epsilon: 0.798\n",
      "Episode 1209 finished after 2913 timesteps\n",
      "Total reward: 15415.045807565266, Epsilon: 0.797\n",
      "Episode 1210 finished after 2523 timesteps\n",
      "Total reward: 14162.510560177636, Epsilon: 0.797\n",
      "Episode 1211 finished after 1010 timesteps\n",
      "Total reward: 5325.762927768076, Epsilon: 0.797\n",
      "Episode 1212 finished after 1074 timesteps\n",
      "Total reward: 7888.153137064266, Epsilon: 0.797\n",
      "Episode 1213 finished after 665 timesteps\n",
      "Total reward: 5431.188915074681, Epsilon: 0.797\n",
      "Episode 1214 finished after 1992 timesteps\n",
      "Total reward: 10228.63748329927, Epsilon: 0.797\n",
      "Episode 1215 finished after 658 timesteps\n",
      "Total reward: 5145.23161626304, Epsilon: 0.797\n",
      "Episode 1216 finished after 3001 timesteps\n",
      "Total reward: 15827.500793544175, Epsilon: 0.797\n",
      "Episode 1217 finished after 1273 timesteps\n",
      "Total reward: 6690.294472641007, Epsilon: 0.797\n",
      "Episode 1218 finished after 912 timesteps\n",
      "Total reward: 4984.122326177067, Epsilon: 0.797\n",
      "Episode 1219 finished after 3001 timesteps\n",
      "Total reward: 18252.105187167614, Epsilon: 0.797\n",
      "Episode 1220 finished after 3001 timesteps\n",
      "Total reward: 16265.402715836179, Epsilon: 0.797\n",
      "Episode 1221 finished after 592 timesteps\n",
      "Total reward: 5469.10373484878, Epsilon: 0.796\n",
      "Episode 1222 finished after 1323 timesteps\n",
      "Total reward: 8276.782771300004, Epsilon: 0.796\n",
      "Episode 1223 finished after 888 timesteps\n",
      "Total reward: 7232.160212124376, Epsilon: 0.796\n",
      "Episode 1224 finished after 905 timesteps\n",
      "Total reward: 5812.158695962805, Epsilon: 0.796\n",
      "Episode 1225 finished after 440 timesteps\n",
      "Total reward: 3538.206864136939, Epsilon: 0.796\n",
      "Episode 1226 finished after 490 timesteps\n",
      "Total reward: 3844.360558429466, Epsilon: 0.796\n",
      "Episode 1227 finished after 733 timesteps\n",
      "Total reward: 4249.817916942785, Epsilon: 0.796\n",
      "Episode 1228 finished after 1469 timesteps\n",
      "Total reward: 8639.688636174065, Epsilon: 0.796\n",
      "Episode 1229 finished after 1234 timesteps\n",
      "Total reward: 8502.33171474411, Epsilon: 0.796\n",
      "Episode 1230 finished after 3001 timesteps\n",
      "Total reward: 13018.798641359093, Epsilon: 0.796\n",
      "Episode 1231 finished after 946 timesteps\n",
      "Total reward: 6619.396578612665, Epsilon: 0.796\n",
      "Episode 1232 finished after 633 timesteps\n",
      "Total reward: 5236.7024878618495, Epsilon: 0.796\n",
      "Episode 1233 finished after 1314 timesteps\n",
      "Total reward: 8943.636973019919, Epsilon: 0.796\n",
      "Episode 1234 finished after 1137 timesteps\n",
      "Total reward: 5742.450438771971, Epsilon: 0.795\n",
      "Episode 1235 finished after 3001 timesteps\n",
      "Total reward: 17302.601745194577, Epsilon: 0.795\n",
      "Episode 1236 finished after 1215 timesteps\n",
      "Total reward: 8808.89136608223, Epsilon: 0.795\n",
      "Episode 1237 finished after 1492 timesteps\n",
      "Total reward: 8973.666973980457, Epsilon: 0.795\n",
      "Episode 1238 finished after 1844 timesteps\n",
      "Total reward: 10506.53934751216, Epsilon: 0.795\n",
      "Episode 1239 finished after 2766 timesteps\n",
      "Total reward: 15130.862889491253, Epsilon: 0.795\n",
      "Episode 1240 finished after 1462 timesteps\n",
      "Total reward: 9876.626870625283, Epsilon: 0.795\n",
      "Episode 1241 finished after 2187 timesteps\n",
      "Total reward: 17908.396976073098, Epsilon: 0.795\n",
      "Episode 1242 finished after 1634 timesteps\n",
      "Total reward: 9132.483647538147, Epsilon: 0.795\n",
      "Episode 1243 finished after 976 timesteps\n",
      "Total reward: 5649.464305385984, Epsilon: 0.795\n",
      "Episode 1244 finished after 120 timesteps\n",
      "Total reward: 1838.2257387638672, Epsilon: 0.795\n",
      "Episode 1245 finished after 3001 timesteps\n",
      "Total reward: 13223.676759378335, Epsilon: 0.795\n",
      "Episode 1246 finished after 3001 timesteps\n",
      "Total reward: 15315.942730129118, Epsilon: 0.794\n",
      "Episode 1247 finished after 852 timesteps\n",
      "Total reward: 4977.045625024403, Epsilon: 0.794\n",
      "Episode 1248 finished after 1032 timesteps\n",
      "Total reward: 7284.708440052188, Epsilon: 0.794\n",
      "Episode 1249 finished after 1611 timesteps\n",
      "Total reward: 8845.199921908801, Epsilon: 0.794\n",
      "Episode 1250 finished after 956 timesteps\n",
      "Total reward: 5460.558786012403, Epsilon: 0.794\n",
      "Episode 1251 finished after 555 timesteps\n",
      "Total reward: 4316.187085559995, Epsilon: 0.794\n",
      "Episode 1252 finished after 526 timesteps\n",
      "Total reward: 3443.3451077689115, Epsilon: 0.794\n",
      "Episode 1253 finished after 3001 timesteps\n",
      "Total reward: 15034.51749803888, Epsilon: 0.794\n",
      "Episode 1254 finished after 713 timesteps\n",
      "Total reward: 5935.047968878948, Epsilon: 0.794\n",
      "Episode 1255 finished after 2327 timesteps\n",
      "Total reward: 14974.424197007827, Epsilon: 0.794\n",
      "Episode 1256 finished after 1187 timesteps\n",
      "Total reward: 7803.137933740425, Epsilon: 0.794\n",
      "Episode 1257 finished after 1366 timesteps\n",
      "Total reward: 9461.70071734454, Epsilon: 0.794\n",
      "Episode 1258 finished after 3001 timesteps\n",
      "Total reward: 13574.214687136622, Epsilon: 0.794\n",
      "Episode 1259 finished after 642 timesteps\n",
      "Total reward: 5396.2778464983485, Epsilon: 0.793\n",
      "Episode 1260 finished after 3001 timesteps\n",
      "Total reward: 14848.853387812615, Epsilon: 0.793\n",
      "Episode 1261 finished after 2530 timesteps\n",
      "Total reward: 12575.878530412423, Epsilon: 0.793\n",
      "Episode 1262 finished after 1264 timesteps\n",
      "Total reward: 9123.516206416249, Epsilon: 0.793\n",
      "Episode 1263 finished after 503 timesteps\n",
      "Total reward: 3793.1137805882245, Epsilon: 0.793\n",
      "Episode 1264 finished after 3001 timesteps\n",
      "Total reward: 14070.481502106208, Epsilon: 0.793\n",
      "Episode 1265 finished after 1922 timesteps\n",
      "Total reward: 12394.320118505348, Epsilon: 0.793\n",
      "Episode 1266 finished after 3001 timesteps\n",
      "Total reward: 13905.412310247066, Epsilon: 0.793\n",
      "Episode 1267 finished after 2444 timesteps\n",
      "Total reward: 11951.289213184957, Epsilon: 0.793\n",
      "Episode 1268 finished after 109 timesteps\n",
      "Total reward: 1619.049258004485, Epsilon: 0.793\n",
      "Episode 1269 finished after 1280 timesteps\n",
      "Total reward: 8053.6741118761865, Epsilon: 0.793\n",
      "Episode 1270 finished after 2189 timesteps\n",
      "Total reward: 13731.032076160049, Epsilon: 0.793\n",
      "Episode 1271 finished after 425 timesteps\n",
      "Total reward: 2866.8706253250243, Epsilon: 0.792\n",
      "Episode 1272 finished after 1009 timesteps\n",
      "Total reward: 6420.594089343849, Epsilon: 0.792\n",
      "Episode 1273 finished after 2185 timesteps\n",
      "Total reward: 14352.205961962696, Epsilon: 0.792\n",
      "Episode 1274 finished after 994 timesteps\n",
      "Total reward: 8266.052068774388, Epsilon: 0.792\n",
      "Episode 1275 finished after 2075 timesteps\n",
      "Total reward: 12369.21529486018, Epsilon: 0.792\n",
      "Episode 1276 finished after 1553 timesteps\n",
      "Total reward: 8491.548809650996, Epsilon: 0.792\n",
      "Episode 1277 finished after 3001 timesteps\n",
      "Total reward: 13889.663842086524, Epsilon: 0.792\n",
      "Episode 1278 finished after 3001 timesteps\n",
      "Total reward: 14676.058256859797, Epsilon: 0.792\n",
      "Episode 1279 finished after 706 timesteps\n",
      "Total reward: 4858.0245734137725, Epsilon: 0.792\n",
      "Episode 1280 finished after 3001 timesteps\n",
      "Total reward: 17049.358618818507, Epsilon: 0.792\n",
      "Episode 1281 finished after 2473 timesteps\n",
      "Total reward: 12872.521924623255, Epsilon: 0.792\n",
      "Episode 1282 finished after 733 timesteps\n",
      "Total reward: 5898.823991231216, Epsilon: 0.792\n",
      "Episode 1283 finished after 2402 timesteps\n",
      "Total reward: 13803.435922796982, Epsilon: 0.792\n",
      "Episode 1284 finished after 2723 timesteps\n",
      "Total reward: 13566.296988842541, Epsilon: 0.791\n",
      "Episode 1285 finished after 960 timesteps\n",
      "Total reward: 6094.632107115821, Epsilon: 0.791\n",
      "Episode 1286 finished after 585 timesteps\n",
      "Total reward: 4225.527408746487, Epsilon: 0.791\n",
      "Episode 1287 finished after 521 timesteps\n",
      "Total reward: 3427.9776720756145, Epsilon: 0.791\n",
      "Episode 1288 finished after 1615 timesteps\n",
      "Total reward: 8998.264113249152, Epsilon: 0.791\n",
      "Episode 1289 finished after 2756 timesteps\n",
      "Total reward: 14451.3902978407, Epsilon: 0.791\n",
      "Episode 1290 finished after 1202 timesteps\n",
      "Total reward: 7202.917604048497, Epsilon: 0.791\n",
      "Episode 1291 finished after 901 timesteps\n",
      "Total reward: 5951.37156027134, Epsilon: 0.791\n",
      "Episode 1292 finished after 1732 timesteps\n",
      "Total reward: 12406.754069723815, Epsilon: 0.791\n",
      "Episode 1293 finished after 2403 timesteps\n",
      "Total reward: 16285.100445586366, Epsilon: 0.791\n",
      "Episode 1294 finished after 238 timesteps\n",
      "Total reward: 2624.877836222432, Epsilon: 0.791\n",
      "Episode 1295 finished after 2613 timesteps\n",
      "Total reward: 15618.375583358742, Epsilon: 0.791\n",
      "Episode 1296 finished after 1339 timesteps\n",
      "Total reward: 7440.047373178056, Epsilon: 0.791\n",
      "Episode 1297 finished after 1571 timesteps\n",
      "Total reward: 10776.185424777717, Epsilon: 0.790\n",
      "Episode 1298 finished after 2114 timesteps\n",
      "Total reward: 11751.359332455802, Epsilon: 0.790\n",
      "Episode 1299 finished after 2166 timesteps\n",
      "Total reward: 11618.53468286719, Epsilon: 0.790\n",
      "Episode 1300 finished after 2500 timesteps\n",
      "Total reward: 12974.103186772858, Epsilon: 0.790\n",
      "Episode 1301 finished after 756 timesteps\n",
      "Total reward: 4492.415806162218, Epsilon: 0.790\n",
      "Episode 1302 finished after 926 timesteps\n",
      "Total reward: 6120.471196609259, Epsilon: 0.790\n",
      "Episode 1303 finished after 2150 timesteps\n",
      "Total reward: 11951.301208509098, Epsilon: 0.790\n",
      "Episode 1304 finished after 1649 timesteps\n",
      "Total reward: 11285.51228385207, Epsilon: 0.790\n",
      "Episode 1305 finished after 3001 timesteps\n",
      "Total reward: 21343.02789085208, Epsilon: 0.790\n",
      "Episode 1306 finished after 634 timesteps\n",
      "Total reward: 7135.362660266149, Epsilon: 0.790\n",
      "Episode 1307 finished after 3001 timesteps\n",
      "Total reward: 16213.845117302133, Epsilon: 0.790\n",
      "Episode 1308 finished after 688 timesteps\n",
      "Total reward: 4501.751730179297, Epsilon: 0.790\n",
      "Episode 1309 finished after 3001 timesteps\n",
      "Total reward: 13625.084291308298, Epsilon: 0.789\n",
      "Episode 1310 finished after 518 timesteps\n",
      "Total reward: 4120.852656050007, Epsilon: 0.789\n",
      "Episode 1311 finished after 1974 timesteps\n",
      "Total reward: 10186.310649666651, Epsilon: 0.789\n",
      "Episode 1312 finished after 1639 timesteps\n",
      "Total reward: 8855.41585806032, Epsilon: 0.789\n",
      "Episode 1313 finished after 3001 timesteps\n",
      "Total reward: 15778.093916583537, Epsilon: 0.789\n",
      "Episode 1314 finished after 1429 timesteps\n",
      "Total reward: 9241.651101136018, Epsilon: 0.789\n",
      "Episode 1315 finished after 3001 timesteps\n",
      "Total reward: 14759.712326174764, Epsilon: 0.789\n",
      "Episode 1316 finished after 1400 timesteps\n",
      "Total reward: 8903.221499454225, Epsilon: 0.789\n",
      "Episode 1317 finished after 595 timesteps\n",
      "Total reward: 6623.443974698221, Epsilon: 0.789\n",
      "Episode 1318 finished after 3001 timesteps\n",
      "Total reward: 16983.716613088316, Epsilon: 0.789\n",
      "Episode 1319 finished after 1214 timesteps\n",
      "Total reward: 7543.473719910681, Epsilon: 0.789\n",
      "Episode 1320 finished after 2655 timesteps\n",
      "Total reward: 12662.960049550466, Epsilon: 0.789\n",
      "Episode 1321 finished after 3001 timesteps\n",
      "Total reward: 14248.499026225534, Epsilon: 0.789\n",
      "Episode 1322 finished after 706 timesteps\n",
      "Total reward: 5807.768280812864, Epsilon: 0.788\n",
      "Episode 1323 finished after 2814 timesteps\n",
      "Total reward: 15055.286997118194, Epsilon: 0.788\n",
      "Episode 1324 finished after 3001 timesteps\n",
      "Total reward: 13221.186561513221, Epsilon: 0.788\n",
      "Episode 1325 finished after 2305 timesteps\n",
      "Total reward: 13962.803056884944, Epsilon: 0.788\n",
      "Episode 1326 finished after 1153 timesteps\n",
      "Total reward: 5763.295772924158, Epsilon: 0.788\n",
      "Episode 1327 finished after 2725 timesteps\n",
      "Total reward: 14841.938480866118, Epsilon: 0.788\n",
      "Episode 1328 finished after 2288 timesteps\n",
      "Total reward: 12213.716730235845, Epsilon: 0.788\n",
      "Episode 1329 finished after 3001 timesteps\n",
      "Total reward: 15902.948342978727, Epsilon: 0.788\n",
      "Episode 1330 finished after 2132 timesteps\n",
      "Total reward: 13501.677255196615, Epsilon: 0.788\n",
      "Episode 1331 finished after 874 timesteps\n",
      "Total reward: 6235.219874814409, Epsilon: 0.788\n",
      "Episode 1332 finished after 608 timesteps\n",
      "Total reward: 3999.4426348289735, Epsilon: 0.788\n",
      "Episode 1333 finished after 1831 timesteps\n",
      "Total reward: 12547.537448484407, Epsilon: 0.788\n",
      "Episode 1334 finished after 1529 timesteps\n",
      "Total reward: 8031.949874857486, Epsilon: 0.788\n",
      "Episode 1335 finished after 1764 timesteps\n",
      "Total reward: 10777.542797623855, Epsilon: 0.787\n",
      "Episode 1336 finished after 3001 timesteps\n",
      "Total reward: 14692.516764380489, Epsilon: 0.787\n",
      "Episode 1337 finished after 1273 timesteps\n",
      "Total reward: 7928.5670138997075, Epsilon: 0.787\n",
      "Episode 1338 finished after 2427 timesteps\n",
      "Total reward: 12956.409150144746, Epsilon: 0.787\n",
      "Episode 1339 finished after 1778 timesteps\n",
      "Total reward: 9125.226590356122, Epsilon: 0.787\n",
      "Episode 1340 finished after 2990 timesteps\n",
      "Total reward: 17819.710908546385, Epsilon: 0.787\n",
      "Episode 1341 finished after 940 timesteps\n",
      "Total reward: 5477.088241954425, Epsilon: 0.787\n",
      "Episode 1342 finished after 3001 timesteps\n",
      "Total reward: 16748.083441140127, Epsilon: 0.787\n",
      "Episode 1343 finished after 1595 timesteps\n",
      "Total reward: 10231.751714372256, Epsilon: 0.787\n",
      "Episode 1344 finished after 1088 timesteps\n",
      "Total reward: 5206.868663435296, Epsilon: 0.787\n",
      "Episode 1345 finished after 3001 timesteps\n",
      "Total reward: 13839.426936803004, Epsilon: 0.787\n",
      "Episode 1346 finished after 1092 timesteps\n",
      "Total reward: 8296.593545128282, Epsilon: 0.787\n",
      "Episode 1347 finished after 553 timesteps\n",
      "Total reward: 5183.705864561269, Epsilon: 0.786\n",
      "Episode 1348 finished after 3001 timesteps\n",
      "Total reward: 16847.323772185144, Epsilon: 0.786\n",
      "Episode 1349 finished after 517 timesteps\n",
      "Total reward: 4659.447961723382, Epsilon: 0.786\n",
      "Episode 1350 finished after 3001 timesteps\n",
      "Total reward: 13474.782730726143, Epsilon: 0.786\n",
      "Episode 1351 finished after 3001 timesteps\n",
      "Total reward: 13931.442959327342, Epsilon: 0.786\n",
      "Episode 1352 finished after 1201 timesteps\n",
      "Total reward: 6375.630141126286, Epsilon: 0.786\n",
      "Episode 1353 finished after 679 timesteps\n",
      "Total reward: 5337.827705547659, Epsilon: 0.786\n",
      "Episode 1354 finished after 1665 timesteps\n",
      "Total reward: 9709.504619124804, Epsilon: 0.786\n",
      "Episode 1355 finished after 876 timesteps\n",
      "Total reward: 6161.07462752866, Epsilon: 0.786\n",
      "Episode 1356 finished after 2570 timesteps\n",
      "Total reward: 14696.951703654058, Epsilon: 0.786\n",
      "Episode 1357 finished after 1575 timesteps\n",
      "Total reward: 8736.797931642988, Epsilon: 0.786\n",
      "Episode 1358 finished after 3001 timesteps\n",
      "Total reward: 13448.498502056895, Epsilon: 0.786\n",
      "Episode 1359 finished after 1997 timesteps\n",
      "Total reward: 9966.422867797308, Epsilon: 0.786\n",
      "Episode 1360 finished after 3001 timesteps\n",
      "Total reward: 14901.357880469322, Epsilon: 0.785\n",
      "Episode 1361 finished after 1527 timesteps\n",
      "Total reward: 9802.8970905749, Epsilon: 0.785\n",
      "Episode 1362 finished after 2263 timesteps\n",
      "Total reward: 15043.541942537746, Epsilon: 0.785\n",
      "Episode 1363 finished after 3001 timesteps\n",
      "Total reward: 12936.457405985719, Epsilon: 0.785\n",
      "Episode 1364 finished after 1808 timesteps\n",
      "Total reward: 12703.408882124782, Epsilon: 0.785\n",
      "Episode 1365 finished after 1520 timesteps\n",
      "Total reward: 8362.735669208438, Epsilon: 0.785\n",
      "Episode 1366 finished after 537 timesteps\n",
      "Total reward: 3782.1034030764117, Epsilon: 0.785\n",
      "Episode 1367 finished after 2935 timesteps\n",
      "Total reward: 15646.468655214321, Epsilon: 0.785\n",
      "Episode 1368 finished after 3001 timesteps\n",
      "Total reward: 15065.186287132936, Epsilon: 0.785\n",
      "Episode 1369 finished after 393 timesteps\n",
      "Total reward: 2813.756639589103, Epsilon: 0.785\n",
      "Episode 1370 finished after 919 timesteps\n",
      "Total reward: 5594.939423371627, Epsilon: 0.785\n",
      "Episode 1371 finished after 852 timesteps\n",
      "Total reward: 4606.998146532832, Epsilon: 0.785\n",
      "Episode 1372 finished after 900 timesteps\n",
      "Total reward: 4983.168484224223, Epsilon: 0.785\n",
      "Episode 1373 finished after 1401 timesteps\n",
      "Total reward: 11646.049710057629, Epsilon: 0.784\n",
      "Episode 1374 finished after 1718 timesteps\n",
      "Total reward: 11705.05894045672, Epsilon: 0.784\n",
      "Episode 1375 finished after 252 timesteps\n",
      "Total reward: 2200.748314462343, Epsilon: 0.784\n",
      "Episode 1376 finished after 1171 timesteps\n",
      "Total reward: 10605.857154733047, Epsilon: 0.784\n",
      "Episode 1377 finished after 678 timesteps\n",
      "Total reward: 4749.81772533087, Epsilon: 0.784\n",
      "Episode 1378 finished after 1644 timesteps\n",
      "Total reward: 9749.255459870663, Epsilon: 0.784\n",
      "Episode 1379 finished after 522 timesteps\n",
      "Total reward: 2904.4897693650196, Epsilon: 0.784\n",
      "Episode 1380 finished after 2104 timesteps\n",
      "Total reward: 12288.037042414557, Epsilon: 0.784\n",
      "Episode 1381 finished after 1529 timesteps\n",
      "Total reward: 10823.969948842732, Epsilon: 0.784\n",
      "Episode 1382 finished after 905 timesteps\n",
      "Total reward: 5346.875200021019, Epsilon: 0.784\n",
      "Episode 1383 finished after 2255 timesteps\n",
      "Total reward: 14348.39186958234, Epsilon: 0.784\n",
      "Episode 1384 finished after 1288 timesteps\n",
      "Total reward: 7835.111840556119, Epsilon: 0.784\n",
      "Episode 1385 finished after 229 timesteps\n",
      "Total reward: 2225.2142908118626, Epsilon: 0.784\n",
      "Episode 1386 finished after 3001 timesteps\n",
      "Total reward: 15686.223791311244, Epsilon: 0.783\n",
      "Episode 1387 finished after 1221 timesteps\n",
      "Total reward: 6343.3466442121335, Epsilon: 0.783\n",
      "Episode 1388 finished after 481 timesteps\n",
      "Total reward: 3101.5466512874455, Epsilon: 0.783\n",
      "Episode 1389 finished after 210 timesteps\n",
      "Total reward: 2160.9959677859492, Epsilon: 0.783\n",
      "Episode 1390 finished after 324 timesteps\n",
      "Total reward: 3632.6063402655263, Epsilon: 0.783\n",
      "Episode 1391 finished after 377 timesteps\n",
      "Total reward: 3198.9988168788113, Epsilon: 0.783\n",
      "Episode 1392 finished after 1065 timesteps\n",
      "Total reward: 8418.459381354234, Epsilon: 0.783\n",
      "Episode 1393 finished after 1840 timesteps\n",
      "Total reward: 9544.313373937877, Epsilon: 0.783\n",
      "Episode 1394 finished after 3001 timesteps\n",
      "Total reward: 14534.82817243272, Epsilon: 0.783\n",
      "Episode 1395 finished after 1049 timesteps\n",
      "Total reward: 6372.730981160013, Epsilon: 0.783\n",
      "Episode 1396 finished after 423 timesteps\n",
      "Total reward: 3318.690334007524, Epsilon: 0.783\n",
      "Episode 1397 finished after 1245 timesteps\n",
      "Total reward: 7801.980045856837, Epsilon: 0.783\n",
      "Episode 1398 finished after 3001 timesteps\n",
      "Total reward: 16758.054741235956, Epsilon: 0.782\n",
      "Episode 1399 finished after 1969 timesteps\n",
      "Total reward: 12159.395553592498, Epsilon: 0.782\n",
      "Episode 1400 finished after 3001 timesteps\n",
      "Total reward: 18687.85684163597, Epsilon: 0.782\n",
      "Episode 1401 finished after 374 timesteps\n",
      "Total reward: 3175.7877973179952, Epsilon: 0.782\n",
      "Episode 1402 finished after 570 timesteps\n",
      "Total reward: 4906.333289717912, Epsilon: 0.782\n",
      "Episode 1403 finished after 519 timesteps\n",
      "Total reward: 4217.0402651780805, Epsilon: 0.782\n",
      "Episode 1404 finished after 1644 timesteps\n",
      "Total reward: 8531.432641744354, Epsilon: 0.782\n",
      "Episode 1405 finished after 1081 timesteps\n",
      "Total reward: 8783.567013899774, Epsilon: 0.782\n",
      "Episode 1406 finished after 3001 timesteps\n",
      "Total reward: 13446.427180197867, Epsilon: 0.782\n",
      "Episode 1407 finished after 792 timesteps\n",
      "Total reward: 5658.054656391481, Epsilon: 0.782\n",
      "Episode 1408 finished after 631 timesteps\n",
      "Total reward: 4467.604194379699, Epsilon: 0.782\n",
      "Episode 1409 finished after 2027 timesteps\n",
      "Total reward: 11132.379719446553, Epsilon: 0.782\n",
      "Episode 1410 finished after 433 timesteps\n",
      "Total reward: 3101.959825425576, Epsilon: 0.782\n",
      "Episode 1411 finished after 533 timesteps\n",
      "Total reward: 3785.115156452901, Epsilon: 0.781\n",
      "Episode 1412 finished after 2677 timesteps\n",
      "Total reward: 16076.449225235769, Epsilon: 0.781\n",
      "Episode 1413 finished after 1577 timesteps\n",
      "Total reward: 13302.521064699951, Epsilon: 0.781\n",
      "Episode 1414 finished after 922 timesteps\n",
      "Total reward: 6931.856178076586, Epsilon: 0.781\n",
      "Episode 1415 finished after 1011 timesteps\n",
      "Total reward: 6103.878028176832, Epsilon: 0.781\n",
      "Episode 1416 finished after 3001 timesteps\n",
      "Total reward: 16371.620400822554, Epsilon: 0.781\n",
      "Episode 1417 finished after 3001 timesteps\n",
      "Total reward: 15088.671841479518, Epsilon: 0.781\n",
      "Episode 1418 finished after 631 timesteps\n",
      "Total reward: 6082.713885229338, Epsilon: 0.781\n",
      "Episode 1419 finished after 464 timesteps\n",
      "Total reward: 4031.7500179469894, Epsilon: 0.781\n",
      "Episode 1420 finished after 1342 timesteps\n",
      "Total reward: 6345.662204648793, Epsilon: 0.781\n",
      "Episode 1421 finished after 2012 timesteps\n",
      "Total reward: 11409.468137756543, Epsilon: 0.781\n",
      "Episode 1422 finished after 3001 timesteps\n",
      "Total reward: 14788.638151728279, Epsilon: 0.781\n",
      "Episode 1423 finished after 2411 timesteps\n",
      "Total reward: 16982.726729824033, Epsilon: 0.781\n",
      "Episode 1424 finished after 2133 timesteps\n",
      "Total reward: 12052.952636353664, Epsilon: 0.780\n",
      "Episode 1425 finished after 3001 timesteps\n",
      "Total reward: 15807.075951446423, Epsilon: 0.780\n",
      "Episode 1426 finished after 2316 timesteps\n",
      "Total reward: 13438.677149678842, Epsilon: 0.780\n",
      "Episode 1427 finished after 1200 timesteps\n",
      "Total reward: 7282.5655021362, Epsilon: 0.780\n",
      "Episode 1428 finished after 3001 timesteps\n",
      "Total reward: 20601.36538822915, Epsilon: 0.780\n",
      "Episode 1429 finished after 1820 timesteps\n",
      "Total reward: 9300.321513869152, Epsilon: 0.780\n",
      "Episode 1430 finished after 3001 timesteps\n",
      "Total reward: 15594.852273579805, Epsilon: 0.780\n",
      "Episode 1431 finished after 3001 timesteps\n",
      "Total reward: 15300.354559185462, Epsilon: 0.780\n",
      "Episode 1432 finished after 2119 timesteps\n",
      "Total reward: 11390.042193755045, Epsilon: 0.780\n",
      "Episode 1433 finished after 3001 timesteps\n",
      "Total reward: 14850.348004565365, Epsilon: 0.780\n",
      "Episode 1434 finished after 3001 timesteps\n",
      "Total reward: 14718.611721363815, Epsilon: 0.780\n",
      "Episode 1435 finished after 1879 timesteps\n",
      "Total reward: 11684.459046247364, Epsilon: 0.780\n",
      "Episode 1436 finished after 3001 timesteps\n",
      "Total reward: 17405.035043292435, Epsilon: 0.780\n",
      "Episode 1437 finished after 1775 timesteps\n",
      "Total reward: 8854.217966525104, Epsilon: 0.779\n",
      "Episode 1438 finished after 2451 timesteps\n",
      "Total reward: 12165.841243503522, Epsilon: 0.779\n",
      "Episode 1439 finished after 2051 timesteps\n",
      "Total reward: 13110.587973219046, Epsilon: 0.779\n",
      "Episode 1440 finished after 215 timesteps\n",
      "Total reward: 2950.5876870111106, Epsilon: 0.779\n",
      "Episode 1441 finished after 1958 timesteps\n",
      "Total reward: 11395.6472361158, Epsilon: 0.779\n",
      "Episode 1442 finished after 3001 timesteps\n",
      "Total reward: 15362.662469240764, Epsilon: 0.779\n",
      "Episode 1443 finished after 3001 timesteps\n",
      "Total reward: 15841.595758808027, Epsilon: 0.779\n",
      "Episode 1444 finished after 1488 timesteps\n",
      "Total reward: 8515.086802641597, Epsilon: 0.779\n",
      "Episode 1445 finished after 3001 timesteps\n",
      "Total reward: 14453.652441831155, Epsilon: 0.779\n",
      "Episode 1446 finished after 538 timesteps\n",
      "Total reward: 3818.6214891882387, Epsilon: 0.779\n",
      "Episode 1447 finished after 1795 timesteps\n",
      "Total reward: 11032.284756519324, Epsilon: 0.779\n",
      "Episode 1448 finished after 2767 timesteps\n",
      "Total reward: 15358.50250082364, Epsilon: 0.779\n",
      "Episode 1449 finished after 1912 timesteps\n",
      "Total reward: 10460.884852511017, Epsilon: 0.779\n",
      "Episode 1450 finished after 879 timesteps\n",
      "Total reward: 5167.431323605594, Epsilon: 0.778\n",
      "Episode 1451 finished after 895 timesteps\n",
      "Total reward: 5527.614139389662, Epsilon: 0.778\n",
      "Episode 1452 finished after 3001 timesteps\n",
      "Total reward: 15011.10610891662, Epsilon: 0.778\n",
      "Episode 1453 finished after 1151 timesteps\n",
      "Total reward: 6327.604017058484, Epsilon: 0.778\n",
      "Episode 1454 finished after 1545 timesteps\n",
      "Total reward: 9804.170632813994, Epsilon: 0.778\n",
      "Episode 1455 finished after 3001 timesteps\n",
      "Total reward: 16453.968782410197, Epsilon: 0.778\n",
      "Episode 1456 finished after 357 timesteps\n",
      "Total reward: 2903.9311461858274, Epsilon: 0.778\n",
      "Episode 1457 finished after 2320 timesteps\n",
      "Total reward: 13699.872785779704, Epsilon: 0.778\n",
      "Episode 1458 finished after 1292 timesteps\n",
      "Total reward: 10672.113591692541, Epsilon: 0.778\n",
      "Episode 1459 finished after 1868 timesteps\n",
      "Total reward: 10305.235168318439, Epsilon: 0.778\n",
      "Episode 1460 finished after 1247 timesteps\n",
      "Total reward: 8269.883960792882, Epsilon: 0.778\n",
      "Episode 1461 finished after 1117 timesteps\n",
      "Total reward: 6787.711626162275, Epsilon: 0.778\n",
      "Episode 1462 finished after 973 timesteps\n",
      "Total reward: 5494.675226638872, Epsilon: 0.778\n",
      "Episode 1463 finished after 3001 timesteps\n",
      "Total reward: 18077.823998608492, Epsilon: 0.777\n",
      "Episode 1464 finished after 2267 timesteps\n",
      "Total reward: 13943.833855862842, Epsilon: 0.777\n",
      "Episode 1465 finished after 700 timesteps\n",
      "Total reward: 4769.9790639137245, Epsilon: 0.777\n",
      "Episode 1466 finished after 167 timesteps\n",
      "Total reward: 2172.016413365677, Epsilon: 0.777\n",
      "Episode 1467 finished after 1593 timesteps\n",
      "Total reward: 9685.275325065786, Epsilon: 0.777\n",
      "Episode 1468 finished after 3001 timesteps\n",
      "Total reward: 16929.87956043334, Epsilon: 0.777\n",
      "Episode 1469 finished after 1863 timesteps\n",
      "Total reward: 11243.234188318265, Epsilon: 0.777\n",
      "Episode 1470 finished after 578 timesteps\n",
      "Total reward: 5137.1085554066385, Epsilon: 0.777\n",
      "Episode 1471 finished after 982 timesteps\n",
      "Total reward: 5994.214808361642, Epsilon: 0.777\n",
      "Episode 1472 finished after 2350 timesteps\n",
      "Total reward: 13672.705450327961, Epsilon: 0.777\n",
      "Episode 1473 finished after 3001 timesteps\n",
      "Total reward: 20723.80797506165, Epsilon: 0.777\n",
      "Episode 1474 finished after 344 timesteps\n",
      "Total reward: 2742.305500496701, Epsilon: 0.777\n",
      "Episode 1475 finished after 1116 timesteps\n",
      "Total reward: 7490.371559753303, Epsilon: 0.776\n",
      "Episode 1476 finished after 2490 timesteps\n",
      "Total reward: 14554.285629735215, Epsilon: 0.776\n",
      "Episode 1477 finished after 529 timesteps\n",
      "Total reward: 3539.4259750126785, Epsilon: 0.776\n",
      "Episode 1478 finished after 3001 timesteps\n",
      "Total reward: 15222.307524825497, Epsilon: 0.776\n",
      "Episode 1479 finished after 1038 timesteps\n",
      "Total reward: 5866.601717516176, Epsilon: 0.776\n",
      "Episode 1480 finished after 859 timesteps\n",
      "Total reward: 5783.06090462309, Epsilon: 0.776\n",
      "Episode 1481 finished after 899 timesteps\n",
      "Total reward: 5071.774786806302, Epsilon: 0.776\n",
      "Episode 1482 finished after 2385 timesteps\n",
      "Total reward: 13969.506832379271, Epsilon: 0.776\n",
      "Episode 1483 finished after 483 timesteps\n",
      "Total reward: 3822.608244617954, Epsilon: 0.776\n",
      "Episode 1484 finished after 445 timesteps\n",
      "Total reward: 3723.9118106789037, Epsilon: 0.776\n",
      "Episode 1485 finished after 2122 timesteps\n",
      "Total reward: 13678.440099659434, Epsilon: 0.776\n",
      "Episode 1486 finished after 3001 timesteps\n",
      "Total reward: 14641.642041351759, Epsilon: 0.776\n",
      "Episode 1487 finished after 1255 timesteps\n",
      "Total reward: 7835.147539758705, Epsilon: 0.776\n",
      "Episode 1488 finished after 861 timesteps\n",
      "Total reward: 4782.190991357161, Epsilon: 0.775\n",
      "Episode 1489 finished after 2001 timesteps\n",
      "Total reward: 11194.393893417622, Epsilon: 0.775\n",
      "Episode 1490 finished after 2019 timesteps\n",
      "Total reward: 11424.666470550299, Epsilon: 0.775\n",
      "Episode 1491 finished after 3001 timesteps\n",
      "Total reward: 13492.987390503757, Epsilon: 0.775\n",
      "Episode 1492 finished after 1680 timesteps\n",
      "Total reward: 10175.842622722, Epsilon: 0.775\n",
      "Episode 1493 finished after 857 timesteps\n",
      "Total reward: 4456.187674695374, Epsilon: 0.775\n",
      "Episode 1494 finished after 3001 timesteps\n",
      "Total reward: 16335.452794903473, Epsilon: 0.775\n",
      "Episode 1495 finished after 368 timesteps\n",
      "Total reward: 3486.45292873356, Epsilon: 0.775\n",
      "Episode 1496 finished after 1312 timesteps\n",
      "Total reward: 7976.492696293382, Epsilon: 0.775\n",
      "Episode 1497 finished after 3001 timesteps\n",
      "Total reward: 17172.671931146542, Epsilon: 0.775\n",
      "Episode 1498 finished after 1075 timesteps\n",
      "Total reward: 6762.5672966868915, Epsilon: 0.775\n",
      "Episode 1499 finished after 1794 timesteps\n",
      "Total reward: 10615.143589722784, Epsilon: 0.775\n",
      "Episode 1500 finished after 3001 timesteps\n",
      "Total reward: 14028.661704324972, Epsilon: 0.775\n",
      "Episode 1501 finished after 567 timesteps\n",
      "Total reward: 4697.701960557324, Epsilon: 0.774\n",
      "Episode 1502 finished after 1361 timesteps\n",
      "Total reward: 8325.282779692327, Epsilon: 0.774\n",
      "Episode 1503 finished after 432 timesteps\n",
      "Total reward: 3397.8956448043446, Epsilon: 0.774\n",
      "Episode 1504 finished after 2336 timesteps\n",
      "Total reward: 17863.445512632283, Epsilon: 0.774\n",
      "Episode 1505 finished after 3001 timesteps\n",
      "Total reward: 15300.167422986904, Epsilon: 0.774\n",
      "Episode 1506 finished after 373 timesteps\n",
      "Total reward: 3289.9764968413647, Epsilon: 0.774\n",
      "Episode 1507 finished after 476 timesteps\n",
      "Total reward: 3586.3447052361958, Epsilon: 0.774\n",
      "Episode 1508 finished after 3001 timesteps\n",
      "Total reward: 13691.532576509419, Epsilon: 0.774\n",
      "Episode 1509 finished after 551 timesteps\n",
      "Total reward: 4750.869009417294, Epsilon: 0.774\n",
      "Episode 1510 finished after 3001 timesteps\n",
      "Total reward: 16762.97390112547, Epsilon: 0.774\n",
      "Episode 1511 finished after 1965 timesteps\n",
      "Total reward: 10877.68144209524, Epsilon: 0.774\n",
      "Episode 1512 finished after 2208 timesteps\n",
      "Total reward: 13777.183196357177, Epsilon: 0.774\n",
      "Episode 1513 finished after 569 timesteps\n",
      "Total reward: 5236.149603885661, Epsilon: 0.774\n",
      "Episode 1514 finished after 1379 timesteps\n",
      "Total reward: 8346.093245450078, Epsilon: 0.773\n",
      "Episode 1515 finished after 2572 timesteps\n",
      "Total reward: 14136.376105219335, Epsilon: 0.773\n",
      "Episode 1516 finished after 1860 timesteps\n",
      "Total reward: 11206.060736240284, Epsilon: 0.773\n",
      "Episode 1517 finished after 2496 timesteps\n",
      "Total reward: 11775.375447543816, Epsilon: 0.773\n",
      "Episode 1518 finished after 2582 timesteps\n",
      "Total reward: 13907.771469327876, Epsilon: 0.773\n",
      "Episode 1519 finished after 2647 timesteps\n",
      "Total reward: 17632.710879810424, Epsilon: 0.773\n",
      "Episode 1520 finished after 791 timesteps\n",
      "Total reward: 4586.88699512266, Epsilon: 0.773\n",
      "Episode 1521 finished after 184 timesteps\n",
      "Total reward: 1947.8558565723763, Epsilon: 0.773\n",
      "Episode 1522 finished after 2849 timesteps\n",
      "Total reward: 18450.712670600496, Epsilon: 0.773\n",
      "Episode 1523 finished after 2777 timesteps\n",
      "Total reward: 16074.617865397651, Epsilon: 0.773\n",
      "Episode 1524 finished after 3001 timesteps\n",
      "Total reward: 15313.624853048605, Epsilon: 0.773\n",
      "Episode 1525 finished after 1328 timesteps\n",
      "Total reward: 6638.044613841378, Epsilon: 0.773\n",
      "Episode 1526 finished after 339 timesteps\n",
      "Total reward: 2321.413197938506, Epsilon: 0.773\n",
      "Episode 1527 finished after 1329 timesteps\n",
      "Total reward: 7782.031755887935, Epsilon: 0.772\n",
      "Episode 1528 finished after 154 timesteps\n",
      "Total reward: 2025.8799744885832, Epsilon: 0.772\n",
      "Episode 1529 finished after 3001 timesteps\n",
      "Total reward: 14077.92296655497, Epsilon: 0.772\n",
      "Episode 1530 finished after 387 timesteps\n",
      "Total reward: 3287.2971978722126, Epsilon: 0.772\n",
      "Episode 1531 finished after 3001 timesteps\n",
      "Total reward: 15803.035565510861, Epsilon: 0.772\n",
      "Episode 1532 finished after 1465 timesteps\n",
      "Total reward: 8500.980638987332, Epsilon: 0.772\n",
      "Episode 1533 finished after 3001 timesteps\n",
      "Total reward: 13042.02655799739, Epsilon: 0.772\n",
      "Episode 1534 finished after 2569 timesteps\n",
      "Total reward: 13788.816403060257, Epsilon: 0.772\n",
      "Episode 1535 finished after 3001 timesteps\n",
      "Total reward: 16755.035320321545, Epsilon: 0.772\n",
      "Episode 1536 finished after 1777 timesteps\n",
      "Total reward: 11597.230199704827, Epsilon: 0.772\n",
      "Episode 1537 finished after 1484 timesteps\n",
      "Total reward: 9047.350232838076, Epsilon: 0.772\n",
      "Episode 1538 finished after 1424 timesteps\n",
      "Total reward: 9915.69382851165, Epsilon: 0.772\n",
      "Episode 1539 finished after 3001 timesteps\n",
      "Total reward: 16865.762252483873, Epsilon: 0.772\n",
      "Episode 1540 finished after 795 timesteps\n",
      "Total reward: 5672.397610839625, Epsilon: 0.771\n",
      "Episode 1541 finished after 3001 timesteps\n",
      "Total reward: 13482.099469918428, Epsilon: 0.771\n",
      "Episode 1542 finished after 559 timesteps\n",
      "Total reward: 3492.726163384876, Epsilon: 0.771\n",
      "Episode 1543 finished after 972 timesteps\n",
      "Total reward: 6829.130530357216, Epsilon: 0.771\n",
      "Episode 1544 finished after 2887 timesteps\n",
      "Total reward: 15473.002015569265, Epsilon: 0.771\n",
      "Episode 1545 finished after 3001 timesteps\n",
      "Total reward: 17315.39947643477, Epsilon: 0.771\n",
      "Episode 1546 finished after 1107 timesteps\n",
      "Total reward: 10064.296579185127, Epsilon: 0.771\n",
      "Episode 1547 finished after 121 timesteps\n",
      "Total reward: 1858.853462116209, Epsilon: 0.771\n",
      "Episode 1548 finished after 1390 timesteps\n",
      "Total reward: 9466.604027026216, Epsilon: 0.771\n",
      "Episode 1549 finished after 3001 timesteps\n",
      "Total reward: 17272.119758475394, Epsilon: 0.771\n",
      "Episode 1550 finished after 484 timesteps\n",
      "Total reward: 3262.892037628551, Epsilon: 0.771\n",
      "Episode 1551 finished after 3001 timesteps\n",
      "Total reward: 15157.482391214018, Epsilon: 0.771\n",
      "Episode 1552 finished after 3001 timesteps\n",
      "Total reward: 15399.994079848611, Epsilon: 0.771\n",
      "Episode 1553 finished after 2298 timesteps\n",
      "Total reward: 13324.86034435795, Epsilon: 0.770\n",
      "Episode 1554 finished after 792 timesteps\n",
      "Total reward: 4923.837739142737, Epsilon: 0.770\n",
      "Episode 1555 finished after 3001 timesteps\n",
      "Total reward: 13595.60073592137, Epsilon: 0.770\n",
      "Episode 1556 finished after 1486 timesteps\n",
      "Total reward: 7965.231053020579, Epsilon: 0.770\n",
      "Episode 1557 finished after 1150 timesteps\n",
      "Total reward: 6303.589661854035, Epsilon: 0.770\n",
      "Episode 1558 finished after 458 timesteps\n",
      "Total reward: 2836.4790685906883, Epsilon: 0.770\n",
      "Episode 1559 finished after 1231 timesteps\n",
      "Total reward: 10591.290350706286, Epsilon: 0.770\n",
      "Episode 1560 finished after 1557 timesteps\n",
      "Total reward: 11493.388908704193, Epsilon: 0.770\n",
      "Episode 1561 finished after 549 timesteps\n",
      "Total reward: 4026.422494633526, Epsilon: 0.770\n",
      "Episode 1562 finished after 2744 timesteps\n",
      "Total reward: 16258.686037771644, Epsilon: 0.770\n",
      "Episode 1563 finished after 2429 timesteps\n",
      "Total reward: 13849.81555164177, Epsilon: 0.770\n",
      "Episode 1564 finished after 1044 timesteps\n",
      "Total reward: 8203.289080556664, Epsilon: 0.770\n",
      "Episode 1565 finished after 1693 timesteps\n",
      "Total reward: 10083.923647723019, Epsilon: 0.770\n",
      "Episode 1566 finished after 2265 timesteps\n",
      "Total reward: 13602.905619374656, Epsilon: 0.769\n",
      "Episode 1567 finished after 3001 timesteps\n",
      "Total reward: 17775.111882983212, Epsilon: 0.769\n",
      "Episode 1568 finished after 3001 timesteps\n",
      "Total reward: 13587.527640546026, Epsilon: 0.769\n",
      "Episode 1569 finished after 3001 timesteps\n",
      "Total reward: 17117.179449421925, Epsilon: 0.769\n",
      "Episode 1570 finished after 1326 timesteps\n",
      "Total reward: 7829.626144570836, Epsilon: 0.769\n",
      "Episode 1571 finished after 3001 timesteps\n",
      "Total reward: 15852.818366383564, Epsilon: 0.769\n",
      "Episode 1572 finished after 1869 timesteps\n",
      "Total reward: 11447.856156530957, Epsilon: 0.769\n",
      "Episode 1573 finished after 1398 timesteps\n",
      "Total reward: 9222.732663698656, Epsilon: 0.769\n",
      "Episode 1574 finished after 2792 timesteps\n",
      "Total reward: 14109.200559133507, Epsilon: 0.769\n",
      "Episode 1575 finished after 1271 timesteps\n",
      "Total reward: 8765.565336387772, Epsilon: 0.769\n",
      "Episode 1576 finished after 714 timesteps\n",
      "Total reward: 5844.472518643178, Epsilon: 0.769\n",
      "Episode 1577 finished after 1790 timesteps\n",
      "Total reward: 9768.417033237247, Epsilon: 0.769\n",
      "Episode 1578 finished after 3001 timesteps\n",
      "Total reward: 18638.084020505623, Epsilon: 0.769\n",
      "Episode 1579 finished after 2855 timesteps\n",
      "Total reward: 15836.767363342267, Epsilon: 0.768\n",
      "Episode 1580 finished after 1683 timesteps\n",
      "Total reward: 8631.724632405896, Epsilon: 0.768\n",
      "Episode 1581 finished after 1077 timesteps\n",
      "Total reward: 5901.592826216052, Epsilon: 0.768\n",
      "Episode 1582 finished after 3001 timesteps\n",
      "Total reward: 16229.465527610542, Epsilon: 0.768\n",
      "Episode 1583 finished after 3001 timesteps\n",
      "Total reward: 13849.391243087115, Epsilon: 0.768\n",
      "Episode 1584 finished after 518 timesteps\n",
      "Total reward: 4085.5475362407333, Epsilon: 0.768\n",
      "Episode 1585 finished after 1350 timesteps\n",
      "Total reward: 10397.38364188255, Epsilon: 0.768\n",
      "Episode 1586 finished after 1223 timesteps\n",
      "Total reward: 7964.249189625673, Epsilon: 0.768\n",
      "Episode 1587 finished after 1065 timesteps\n",
      "Total reward: 7013.856137464032, Epsilon: 0.768\n",
      "Episode 1588 finished after 956 timesteps\n",
      "Total reward: 7055.74484785356, Epsilon: 0.768\n",
      "Episode 1589 finished after 825 timesteps\n",
      "Total reward: 5314.78262219621, Epsilon: 0.768\n",
      "Episode 1590 finished after 1338 timesteps\n",
      "Total reward: 7200.301504685406, Epsilon: 0.768\n",
      "Episode 1591 finished after 1211 timesteps\n",
      "Total reward: 6738.284748835184, Epsilon: 0.768\n",
      "Episode 1592 finished after 796 timesteps\n",
      "Total reward: 4737.227694112811, Epsilon: 0.767\n",
      "Episode 1593 finished after 3001 timesteps\n",
      "Total reward: 16139.001234446772, Epsilon: 0.767\n",
      "Episode 1594 finished after 3001 timesteps\n",
      "Total reward: 15498.929324150156, Epsilon: 0.767\n",
      "Episode 1595 finished after 3001 timesteps\n",
      "Total reward: 16356.510632956333, Epsilon: 0.767\n",
      "Episode 1596 finished after 3001 timesteps\n",
      "Total reward: 15229.713027578595, Epsilon: 0.767\n",
      "Episode 1597 finished after 2584 timesteps\n",
      "Total reward: 20289.552373003105, Epsilon: 0.767\n",
      "Episode 1598 finished after 613 timesteps\n",
      "Total reward: 4402.590989036152, Epsilon: 0.767\n",
      "Episode 1599 finished after 452 timesteps\n",
      "Total reward: 3415.1601236404294, Epsilon: 0.767\n",
      "Episode 1600 finished after 1033 timesteps\n",
      "Total reward: 6313.759094821664, Epsilon: 0.767\n",
      "Episode 1601 finished after 2189 timesteps\n",
      "Total reward: 15291.588269276044, Epsilon: 0.767\n",
      "Episode 1602 finished after 3001 timesteps\n",
      "Total reward: 14349.845137150955, Epsilon: 0.767\n",
      "Episode 1603 finished after 2723 timesteps\n",
      "Total reward: 16749.064704642067, Epsilon: 0.767\n",
      "Episode 1604 finished after 1943 timesteps\n",
      "Total reward: 11686.680805831405, Epsilon: 0.767\n",
      "Episode 1605 finished after 1602 timesteps\n",
      "Total reward: 8171.687485025097, Epsilon: 0.766\n",
      "Episode 1606 finished after 756 timesteps\n",
      "Total reward: 4936.699048658283, Epsilon: 0.766\n",
      "Episode 1607 finished after 935 timesteps\n",
      "Total reward: 5370.007045580806, Epsilon: 0.766\n",
      "Episode 1608 finished after 634 timesteps\n",
      "Total reward: 5149.827650604029, Epsilon: 0.766\n",
      "Episode 1609 finished after 649 timesteps\n",
      "Total reward: 4544.331450584219, Epsilon: 0.766\n",
      "Episode 1610 finished after 940 timesteps\n",
      "Total reward: 5825.852986022196, Epsilon: 0.766\n",
      "Episode 1611 finished after 504 timesteps\n",
      "Total reward: 3875.0252965643244, Epsilon: 0.766\n",
      "Episode 1612 finished after 1322 timesteps\n",
      "Total reward: 8634.865314559851, Epsilon: 0.766\n",
      "Episode 1613 finished after 3001 timesteps\n",
      "Total reward: 13837.347768012347, Epsilon: 0.766\n",
      "Episode 1614 finished after 750 timesteps\n",
      "Total reward: 4821.994544246446, Epsilon: 0.766\n",
      "Episode 1615 finished after 1393 timesteps\n",
      "Total reward: 7103.257072848759, Epsilon: 0.766\n",
      "Episode 1616 finished after 2040 timesteps\n",
      "Total reward: 9906.968831134005, Epsilon: 0.766\n",
      "Episode 1617 finished after 833 timesteps\n",
      "Total reward: 5420.657762485986, Epsilon: 0.766\n",
      "Episode 1618 finished after 843 timesteps\n",
      "Total reward: 6757.075880026362, Epsilon: 0.765\n",
      "Episode 1619 finished after 1082 timesteps\n",
      "Total reward: 7539.416311052892, Epsilon: 0.765\n",
      "Episode 1620 finished after 2568 timesteps\n",
      "Total reward: 15424.969431066533, Epsilon: 0.765\n",
      "Episode 1621 finished after 440 timesteps\n",
      "Total reward: 3919.9624619577075, Epsilon: 0.765\n",
      "Episode 1622 finished after 3001 timesteps\n",
      "Total reward: 13436.267471080015, Epsilon: 0.765\n",
      "Episode 1623 finished after 1004 timesteps\n",
      "Total reward: 6085.147777229239, Epsilon: 0.765\n",
      "Episode 1624 finished after 1495 timesteps\n",
      "Total reward: 8973.845921854081, Epsilon: 0.765\n",
      "Episode 1625 finished after 732 timesteps\n",
      "Total reward: 3954.163118701932, Epsilon: 0.765\n",
      "Episode 1626 finished after 932 timesteps\n",
      "Total reward: 5061.096032099809, Epsilon: 0.765\n",
      "Episode 1627 finished after 3001 timesteps\n",
      "Total reward: 14832.58315979166, Epsilon: 0.765\n",
      "Episode 1628 finished after 1475 timesteps\n",
      "Total reward: 9031.663805456514, Epsilon: 0.765\n",
      "Episode 1629 finished after 1256 timesteps\n",
      "Total reward: 9916.253475081963, Epsilon: 0.765\n",
      "Episode 1630 finished after 3001 timesteps\n",
      "Total reward: 16784.653641657787, Epsilon: 0.765\n",
      "Episode 1631 finished after 1137 timesteps\n",
      "Total reward: 6874.515409816207, Epsilon: 0.764\n",
      "Episode 1632 finished after 3001 timesteps\n",
      "Total reward: 18893.454100733397, Epsilon: 0.764\n",
      "Episode 1633 finished after 612 timesteps\n",
      "Total reward: 4180.053787762685, Epsilon: 0.764\n",
      "Episode 1634 finished after 775 timesteps\n",
      "Total reward: 4827.990986732077, Epsilon: 0.764\n",
      "Episode 1635 finished after 3001 timesteps\n",
      "Total reward: 14309.828936866303, Epsilon: 0.764\n",
      "Episode 1636 finished after 3001 timesteps\n",
      "Total reward: 13917.024488228697, Epsilon: 0.764\n",
      "Episode 1637 finished after 1342 timesteps\n",
      "Total reward: 7273.578297216315, Epsilon: 0.764\n",
      "Episode 1638 finished after 916 timesteps\n",
      "Total reward: 6075.832114195947, Epsilon: 0.764\n",
      "Episode 1639 finished after 1435 timesteps\n",
      "Total reward: 10297.891561998988, Epsilon: 0.764\n",
      "Episode 1640 finished after 459 timesteps\n",
      "Total reward: 3153.647578004193, Epsilon: 0.764\n",
      "Episode 1641 finished after 3001 timesteps\n",
      "Total reward: 14511.500647770832, Epsilon: 0.764\n",
      "Episode 1642 finished after 1841 timesteps\n",
      "Total reward: 11742.835220435705, Epsilon: 0.764\n",
      "Episode 1643 finished after 1561 timesteps\n",
      "Total reward: 9049.625736838067, Epsilon: 0.764\n",
      "Episode 1644 finished after 1223 timesteps\n",
      "Total reward: 8682.3425932893, Epsilon: 0.763\n",
      "Episode 1645 finished after 2073 timesteps\n",
      "Total reward: 14293.958599870755, Epsilon: 0.763\n",
      "Episode 1646 finished after 3001 timesteps\n",
      "Total reward: 14882.053302232023, Epsilon: 0.763\n",
      "Episode 1647 finished after 2817 timesteps\n",
      "Total reward: 19594.167329382875, Epsilon: 0.763\n",
      "Episode 1648 finished after 3001 timesteps\n",
      "Total reward: 18120.12017726753, Epsilon: 0.763\n",
      "Episode 1649 finished after 572 timesteps\n",
      "Total reward: 4688.343081183698, Epsilon: 0.763\n",
      "Episode 1650 finished after 3001 timesteps\n",
      "Total reward: 13627.12223914847, Epsilon: 0.763\n",
      "Episode 1651 finished after 2419 timesteps\n",
      "Total reward: 14073.933798089072, Epsilon: 0.763\n",
      "Episode 1652 finished after 3001 timesteps\n",
      "Total reward: 22351.77699282512, Epsilon: 0.763\n",
      "Episode 1653 finished after 619 timesteps\n",
      "Total reward: 4924.725332838387, Epsilon: 0.763\n",
      "Episode 1654 finished after 301 timesteps\n",
      "Total reward: 3342.5999529543815, Epsilon: 0.763\n",
      "Episode 1655 finished after 3001 timesteps\n",
      "Total reward: 15410.885777603386, Epsilon: 0.763\n",
      "Episode 1656 finished after 339 timesteps\n",
      "Total reward: 2729.3150079257703, Epsilon: 0.763\n",
      "Episode 1657 finished after 1967 timesteps\n",
      "Total reward: 10999.50527684562, Epsilon: 0.762\n",
      "Episode 1658 finished after 478 timesteps\n",
      "Total reward: 3355.1272383387995, Epsilon: 0.762\n",
      "Episode 1659 finished after 1138 timesteps\n",
      "Total reward: 6668.564017314672, Epsilon: 0.762\n",
      "Episode 1660 finished after 1190 timesteps\n",
      "Total reward: 7156.27967001584, Epsilon: 0.762\n",
      "Episode 1661 finished after 3001 timesteps\n",
      "Total reward: 14289.52736091615, Epsilon: 0.762\n",
      "Episode 1662 finished after 3001 timesteps\n",
      "Total reward: 14834.939839906492, Epsilon: 0.762\n",
      "Episode 1663 finished after 1753 timesteps\n",
      "Total reward: 9574.83188796013, Epsilon: 0.762\n",
      "Episode 1664 finished after 1359 timesteps\n",
      "Total reward: 7485.894711104918, Epsilon: 0.762\n",
      "Episode 1665 finished after 2080 timesteps\n",
      "Total reward: 11494.02616125557, Epsilon: 0.762\n",
      "Episode 1666 finished after 2608 timesteps\n",
      "Total reward: 14189.007577809176, Epsilon: 0.762\n",
      "Episode 1667 finished after 2073 timesteps\n",
      "Total reward: 10958.55113316419, Epsilon: 0.762\n",
      "Episode 1668 finished after 3001 timesteps\n",
      "Total reward: 14794.316326344328, Epsilon: 0.762\n",
      "Episode 1669 finished after 650 timesteps\n",
      "Total reward: 4337.127483858678, Epsilon: 0.762\n",
      "Episode 1670 finished after 1200 timesteps\n",
      "Total reward: 8611.88510965682, Epsilon: 0.761\n",
      "Episode 1671 finished after 1434 timesteps\n",
      "Total reward: 7821.865958409784, Epsilon: 0.761\n",
      "Episode 1672 finished after 1102 timesteps\n",
      "Total reward: 7867.236187008689, Epsilon: 0.761\n",
      "Episode 1673 finished after 1123 timesteps\n",
      "Total reward: 7225.607646697387, Epsilon: 0.761\n",
      "Episode 1674 finished after 2109 timesteps\n",
      "Total reward: 13894.877109858964, Epsilon: 0.761\n",
      "Episode 1675 finished after 740 timesteps\n",
      "Total reward: 4880.935684206716, Epsilon: 0.761\n",
      "Episode 1676 finished after 1526 timesteps\n",
      "Total reward: 8997.056347791218, Epsilon: 0.761\n",
      "Episode 1677 finished after 1336 timesteps\n",
      "Total reward: 8514.631173779431, Epsilon: 0.761\n",
      "Episode 1678 finished after 3001 timesteps\n",
      "Total reward: 13096.261717723255, Epsilon: 0.761\n",
      "Episode 1679 finished after 2591 timesteps\n",
      "Total reward: 14856.140382001264, Epsilon: 0.761\n",
      "Episode 1680 finished after 639 timesteps\n",
      "Total reward: 4340.445860513803, Epsilon: 0.761\n",
      "Episode 1681 finished after 3001 timesteps\n",
      "Total reward: 16438.1526775503, Epsilon: 0.761\n",
      "Episode 1682 finished after 2571 timesteps\n",
      "Total reward: 17307.17336664889, Epsilon: 0.761\n",
      "Episode 1683 finished after 3001 timesteps\n",
      "Total reward: 16140.471576357822, Epsilon: 0.761\n",
      "Episode 1684 finished after 3001 timesteps\n",
      "Total reward: 15079.741188593847, Epsilon: 0.760\n",
      "Episode 1685 finished after 574 timesteps\n",
      "Total reward: 4095.4138009197704, Epsilon: 0.760\n",
      "Episode 1686 finished after 749 timesteps\n",
      "Total reward: 5313.712583615668, Epsilon: 0.760\n",
      "Episode 1687 finished after 3001 timesteps\n",
      "Total reward: 15591.992908294647, Epsilon: 0.760\n",
      "Episode 1688 finished after 777 timesteps\n",
      "Total reward: 5551.2068487390225, Epsilon: 0.760\n",
      "Episode 1689 finished after 526 timesteps\n",
      "Total reward: 3435.530685713213, Epsilon: 0.760\n",
      "Episode 1690 finished after 635 timesteps\n",
      "Total reward: 4451.011112368753, Epsilon: 0.760\n",
      "Episode 1691 finished after 1268 timesteps\n",
      "Total reward: 8968.956525544942, Epsilon: 0.760\n",
      "Episode 1692 finished after 2975 timesteps\n",
      "Total reward: 14735.867325096106, Epsilon: 0.760\n",
      "Episode 1693 finished after 1033 timesteps\n",
      "Total reward: 5325.526275502313, Epsilon: 0.760\n",
      "Episode 1694 finished after 2123 timesteps\n",
      "Total reward: 12252.329499723664, Epsilon: 0.760\n",
      "Episode 1695 finished after 249 timesteps\n",
      "Total reward: 3350.281678803485, Epsilon: 0.760\n",
      "Episode 1696 finished after 3001 timesteps\n",
      "Total reward: 13770.966085185797, Epsilon: 0.760\n",
      "Episode 1697 finished after 303 timesteps\n",
      "Total reward: 2787.7230254950623, Epsilon: 0.759\n",
      "Episode 1698 finished after 3001 timesteps\n",
      "Total reward: 13912.11983216241, Epsilon: 0.759\n",
      "Episode 1699 finished after 2595 timesteps\n",
      "Total reward: 16561.50645209752, Epsilon: 0.759\n",
      "Episode 1700 finished after 2683 timesteps\n",
      "Total reward: 13960.131159546614, Epsilon: 0.759\n",
      "Episode 1701 finished after 955 timesteps\n",
      "Total reward: 5131.484059370318, Epsilon: 0.759\n",
      "Episode 1702 finished after 1527 timesteps\n",
      "Total reward: 11880.226397785034, Epsilon: 0.759\n",
      "Episode 1703 finished after 3001 timesteps\n",
      "Total reward: 12553.343255340795, Epsilon: 0.759\n",
      "Episode 1704 finished after 1274 timesteps\n",
      "Total reward: 7429.137996280149, Epsilon: 0.759\n",
      "Episode 1705 finished after 684 timesteps\n",
      "Total reward: 3990.526757398468, Epsilon: 0.759\n",
      "Episode 1706 finished after 492 timesteps\n",
      "Total reward: 3928.1590799564865, Epsilon: 0.759\n",
      "Episode 1707 finished after 675 timesteps\n",
      "Total reward: 4206.343419738696, Epsilon: 0.759\n",
      "Episode 1708 finished after 2733 timesteps\n",
      "Total reward: 15503.769635711504, Epsilon: 0.759\n",
      "Episode 1709 finished after 1370 timesteps\n",
      "Total reward: 8305.17968711138, Epsilon: 0.759\n",
      "Episode 1710 finished after 2145 timesteps\n",
      "Total reward: 11838.666176100613, Epsilon: 0.758\n",
      "Episode 1711 finished after 1876 timesteps\n",
      "Total reward: 10265.504559698393, Epsilon: 0.758\n",
      "Episode 1712 finished after 444 timesteps\n",
      "Total reward: 4616.794676089703, Epsilon: 0.758\n",
      "Episode 1713 finished after 3001 timesteps\n",
      "Total reward: 16034.23460486156, Epsilon: 0.758\n",
      "Episode 1714 finished after 3001 timesteps\n",
      "Total reward: 16148.066915128156, Epsilon: 0.758\n",
      "Episode 1715 finished after 537 timesteps\n",
      "Total reward: 4473.94581818883, Epsilon: 0.758\n",
      "Episode 1716 finished after 1491 timesteps\n",
      "Total reward: 7848.725957710145, Epsilon: 0.758\n",
      "Episode 1717 finished after 2562 timesteps\n",
      "Total reward: 14915.605720513875, Epsilon: 0.758\n",
      "Episode 1718 finished after 1975 timesteps\n",
      "Total reward: 10371.682220985005, Epsilon: 0.758\n",
      "Episode 1719 finished after 1370 timesteps\n",
      "Total reward: 8190.10683600441, Epsilon: 0.758\n",
      "Episode 1720 finished after 3001 timesteps\n",
      "Total reward: 15811.82965294233, Epsilon: 0.758\n",
      "Episode 1721 finished after 2619 timesteps\n",
      "Total reward: 18188.673267266786, Epsilon: 0.758\n",
      "Episode 1722 finished after 3001 timesteps\n",
      "Total reward: 14274.55388709357, Epsilon: 0.758\n",
      "Episode 1723 finished after 1418 timesteps\n",
      "Total reward: 9640.577602027084, Epsilon: 0.757\n",
      "Episode 1724 finished after 937 timesteps\n",
      "Total reward: 5018.608086271552, Epsilon: 0.757\n",
      "Episode 1725 finished after 1256 timesteps\n",
      "Total reward: 7249.991724201843, Epsilon: 0.757\n",
      "Episode 1726 finished after 723 timesteps\n",
      "Total reward: 5714.72518454186, Epsilon: 0.757\n",
      "Episode 1727 finished after 3001 timesteps\n",
      "Total reward: 13560.190034571187, Epsilon: 0.757\n",
      "Episode 1728 finished after 808 timesteps\n",
      "Total reward: 5692.78075970028, Epsilon: 0.757\n",
      "Episode 1729 finished after 317 timesteps\n",
      "Total reward: 2879.03888373808, Epsilon: 0.757\n",
      "Episode 1730 finished after 3001 timesteps\n",
      "Total reward: 14905.283797021999, Epsilon: 0.757\n",
      "Episode 1731 finished after 2236 timesteps\n",
      "Total reward: 13101.604154481653, Epsilon: 0.757\n",
      "Episode 1732 finished after 3001 timesteps\n",
      "Total reward: 14852.694291532927, Epsilon: 0.757\n",
      "Episode 1733 finished after 1023 timesteps\n",
      "Total reward: 5640.008381496376, Epsilon: 0.757\n",
      "Episode 1734 finished after 1600 timesteps\n",
      "Total reward: 8111.839346171646, Epsilon: 0.757\n",
      "Episode 1735 finished after 3001 timesteps\n",
      "Total reward: 14810.188772935331, Epsilon: 0.757\n",
      "Episode 1736 finished after 3001 timesteps\n",
      "Total reward: 16097.71378892853, Epsilon: 0.756\n",
      "Episode 1737 finished after 1297 timesteps\n",
      "Total reward: 8516.217471675303, Epsilon: 0.756\n",
      "Episode 1738 finished after 379 timesteps\n",
      "Total reward: 3138.2344974666216, Epsilon: 0.756\n",
      "Episode 1739 finished after 643 timesteps\n",
      "Total reward: 4967.923029186221, Epsilon: 0.756\n",
      "Episode 1740 finished after 3001 timesteps\n",
      "Total reward: 15365.667147163918, Epsilon: 0.756\n",
      "Episode 1741 finished after 2406 timesteps\n",
      "Total reward: 17113.421848679594, Epsilon: 0.756\n",
      "Episode 1742 finished after 1047 timesteps\n",
      "Total reward: 6533.253993212441, Epsilon: 0.756\n",
      "Episode 1743 finished after 3001 timesteps\n",
      "Total reward: 17123.269495159948, Epsilon: 0.756\n",
      "Episode 1744 finished after 3001 timesteps\n",
      "Total reward: 14141.450991250644, Epsilon: 0.756\n",
      "Episode 1745 finished after 1368 timesteps\n",
      "Total reward: 7236.253145597848, Epsilon: 0.756\n",
      "Episode 1746 finished after 3001 timesteps\n",
      "Total reward: 16097.325285078377, Epsilon: 0.756\n",
      "Episode 1747 finished after 2393 timesteps\n",
      "Total reward: 12396.06641381299, Epsilon: 0.756\n",
      "Episode 1748 finished after 2521 timesteps\n",
      "Total reward: 12301.750515486177, Epsilon: 0.756\n",
      "Episode 1749 finished after 651 timesteps\n",
      "Total reward: 5543.198548889357, Epsilon: 0.756\n",
      "Episode 1750 finished after 1086 timesteps\n",
      "Total reward: 6452.533715270823, Epsilon: 0.755\n",
      "Episode 1751 finished after 739 timesteps\n",
      "Total reward: 6549.125465704884, Epsilon: 0.755\n",
      "Episode 1752 finished after 3001 timesteps\n",
      "Total reward: 12841.292767210512, Epsilon: 0.755\n",
      "Episode 1753 finished after 684 timesteps\n",
      "Total reward: 5480.654999496621, Epsilon: 0.755\n",
      "Episode 1754 finished after 2390 timesteps\n",
      "Total reward: 11390.196566486944, Epsilon: 0.755\n",
      "Episode 1755 finished after 3001 timesteps\n",
      "Total reward: 14774.412676282453, Epsilon: 0.755\n",
      "Episode 1756 finished after 826 timesteps\n",
      "Total reward: 5698.083480734943, Epsilon: 0.755\n",
      "Episode 1757 finished after 1336 timesteps\n",
      "Total reward: 7686.612353460269, Epsilon: 0.755\n",
      "Episode 1758 finished after 310 timesteps\n",
      "Total reward: 2498.076729900614, Epsilon: 0.755\n",
      "Episode 1759 finished after 3001 timesteps\n",
      "Total reward: 14594.314107024935, Epsilon: 0.755\n",
      "Episode 1760 finished after 3001 timesteps\n",
      "Total reward: 20470.561445588937, Epsilon: 0.755\n",
      "Episode 1761 finished after 985 timesteps\n",
      "Total reward: 9208.89357316749, Epsilon: 0.755\n",
      "Episode 1762 finished after 1108 timesteps\n",
      "Total reward: 7950.16494152369, Epsilon: 0.755\n",
      "Episode 1763 finished after 3001 timesteps\n",
      "Total reward: 17198.43250641468, Epsilon: 0.754\n",
      "Episode 1764 finished after 1755 timesteps\n",
      "Total reward: 10841.4854692335, Epsilon: 0.754\n",
      "Episode 1765 finished after 922 timesteps\n",
      "Total reward: 5491.439229752671, Epsilon: 0.754\n",
      "Episode 1766 finished after 321 timesteps\n",
      "Total reward: 2686.9666060178697, Epsilon: 0.754\n",
      "Episode 1767 finished after 952 timesteps\n",
      "Total reward: 6579.458045820963, Epsilon: 0.754\n",
      "Episode 1768 finished after 1316 timesteps\n",
      "Total reward: 7720.563863004522, Epsilon: 0.754\n",
      "Episode 1769 finished after 1281 timesteps\n",
      "Total reward: 8626.745866433546, Epsilon: 0.754\n",
      "Episode 1770 finished after 811 timesteps\n",
      "Total reward: 5409.01483555369, Epsilon: 0.754\n",
      "Episode 1771 finished after 1434 timesteps\n",
      "Total reward: 6520.7991337048925, Epsilon: 0.754\n",
      "Episode 1772 finished after 1502 timesteps\n",
      "Total reward: 11118.744668753154, Epsilon: 0.754\n",
      "Episode 1773 finished after 527 timesteps\n",
      "Total reward: 3149.1191084306265, Epsilon: 0.754\n",
      "Episode 1774 finished after 1478 timesteps\n",
      "Total reward: 7620.901917263295, Epsilon: 0.754\n",
      "Episode 1775 finished after 1614 timesteps\n",
      "Total reward: 9630.517905822864, Epsilon: 0.754\n",
      "Episode 1776 finished after 1679 timesteps\n",
      "Total reward: 8472.968625663734, Epsilon: 0.753\n",
      "Episode 1777 finished after 949 timesteps\n",
      "Total reward: 5878.239999592264, Epsilon: 0.753\n",
      "Episode 1778 finished after 2539 timesteps\n",
      "Total reward: 15556.659515377833, Epsilon: 0.753\n",
      "Episode 1779 finished after 1205 timesteps\n",
      "Total reward: 6800.309491943101, Epsilon: 0.753\n",
      "Episode 1780 finished after 1154 timesteps\n",
      "Total reward: 6803.308326905253, Epsilon: 0.753\n",
      "Episode 1781 finished after 1540 timesteps\n",
      "Total reward: 8893.36697417126, Epsilon: 0.753\n",
      "Episode 1782 finished after 1799 timesteps\n",
      "Total reward: 8154.582195936153, Epsilon: 0.753\n",
      "Episode 1783 finished after 3001 timesteps\n",
      "Total reward: 14901.965353257585, Epsilon: 0.753\n",
      "Episode 1784 finished after 1000 timesteps\n",
      "Total reward: 7009.59827294984, Epsilon: 0.753\n",
      "Episode 1785 finished after 900 timesteps\n",
      "Total reward: 5438.4644783909, Epsilon: 0.753\n",
      "Episode 1786 finished after 2973 timesteps\n",
      "Total reward: 15421.757974784772, Epsilon: 0.753\n",
      "Episode 1787 finished after 2261 timesteps\n",
      "Total reward: 11673.484255357453, Epsilon: 0.753\n",
      "Episode 1788 finished after 746 timesteps\n",
      "Total reward: 5052.761669089954, Epsilon: 0.753\n",
      "Episode 1789 finished after 399 timesteps\n",
      "Total reward: 3025.7176277740064, Epsilon: 0.752\n",
      "Episode 1790 finished after 2791 timesteps\n",
      "Total reward: 14783.893772365433, Epsilon: 0.752\n",
      "Episode 1791 finished after 1230 timesteps\n",
      "Total reward: 7194.3721754626395, Epsilon: 0.752\n",
      "Episode 1792 finished after 2021 timesteps\n",
      "Total reward: 10821.454437015138, Epsilon: 0.752\n",
      "Episode 1793 finished after 1165 timesteps\n",
      "Total reward: 6181.25587859178, Epsilon: 0.752\n",
      "Episode 1794 finished after 1006 timesteps\n",
      "Total reward: 6510.427067428328, Epsilon: 0.752\n",
      "Episode 1795 finished after 928 timesteps\n",
      "Total reward: 5631.991185203951, Epsilon: 0.752\n",
      "Episode 1796 finished after 1407 timesteps\n",
      "Total reward: 7121.824140445268, Epsilon: 0.752\n",
      "Episode 1797 finished after 1164 timesteps\n",
      "Total reward: 10127.129867121168, Epsilon: 0.752\n",
      "Episode 1798 finished after 1851 timesteps\n",
      "Total reward: 11284.862117106419, Epsilon: 0.752\n",
      "Episode 1799 finished after 1840 timesteps\n",
      "Total reward: 11920.55039026461, Epsilon: 0.752\n",
      "Episode 1800 finished after 2314 timesteps\n",
      "Total reward: 11249.653744108924, Epsilon: 0.752\n",
      "Episode 1801 finished after 2220 timesteps\n",
      "Total reward: 11355.929827951115, Epsilon: 0.752\n",
      "Episode 1802 finished after 1336 timesteps\n",
      "Total reward: 8096.41751927501, Epsilon: 0.752\n",
      "Episode 1803 finished after 825 timesteps\n",
      "Total reward: 6551.013846446093, Epsilon: 0.751\n",
      "Episode 1804 finished after 549 timesteps\n",
      "Total reward: 3829.119214312666, Epsilon: 0.751\n",
      "Episode 1805 finished after 357 timesteps\n",
      "Total reward: 3292.169099135228, Epsilon: 0.751\n",
      "Episode 1806 finished after 709 timesteps\n",
      "Total reward: 4431.255578561895, Epsilon: 0.751\n",
      "Episode 1807 finished after 850 timesteps\n",
      "Total reward: 5123.341257574953, Epsilon: 0.751\n",
      "Episode 1808 finished after 1262 timesteps\n",
      "Total reward: 6233.406268083091, Epsilon: 0.751\n",
      "Episode 1809 finished after 2976 timesteps\n",
      "Total reward: 16698.6629390409, Epsilon: 0.751\n",
      "Episode 1810 finished after 712 timesteps\n",
      "Total reward: 5240.182200241939, Epsilon: 0.751\n",
      "Episode 1811 finished after 3001 timesteps\n",
      "Total reward: 14093.058299786702, Epsilon: 0.751\n",
      "Episode 1812 finished after 3001 timesteps\n",
      "Total reward: 16026.652610708925, Epsilon: 0.751\n",
      "Episode 1813 finished after 410 timesteps\n",
      "Total reward: 3906.3066289981634, Epsilon: 0.751\n",
      "Episode 1814 finished after 506 timesteps\n",
      "Total reward: 3316.3830615290603, Epsilon: 0.751\n",
      "Episode 1815 finished after 3001 timesteps\n",
      "Total reward: 15110.399764411846, Epsilon: 0.751\n",
      "Episode 1816 finished after 2998 timesteps\n",
      "Total reward: 19106.140196362274, Epsilon: 0.750\n",
      "Episode 1817 finished after 1668 timesteps\n",
      "Total reward: 7829.55608861109, Epsilon: 0.750\n",
      "Episode 1818 finished after 345 timesteps\n",
      "Total reward: 2640.939364613278, Epsilon: 0.750\n",
      "Episode 1819 finished after 1271 timesteps\n",
      "Total reward: 8359.519141452296, Epsilon: 0.750\n",
      "Episode 1820 finished after 2008 timesteps\n",
      "Total reward: 12829.829529499551, Epsilon: 0.750\n",
      "Episode 1821 finished after 1126 timesteps\n",
      "Total reward: 7852.599815684226, Epsilon: 0.750\n",
      "Episode 1822 finished after 3001 timesteps\n",
      "Total reward: 16452.554143221507, Epsilon: 0.750\n",
      "Episode 1823 finished after 861 timesteps\n",
      "Total reward: 4877.375803179038, Epsilon: 0.750\n",
      "Episode 1824 finished after 2780 timesteps\n",
      "Total reward: 14087.573684700876, Epsilon: 0.750\n",
      "Episode 1825 finished after 1264 timesteps\n",
      "Total reward: 8168.990945806134, Epsilon: 0.750\n",
      "Episode 1826 finished after 3001 timesteps\n",
      "Total reward: 14994.182173605237, Epsilon: 0.750\n",
      "Episode 1827 finished after 2801 timesteps\n",
      "Total reward: 15951.962773781803, Epsilon: 0.750\n",
      "Episode 1828 finished after 3001 timesteps\n",
      "Total reward: 13442.891901106748, Epsilon: 0.750\n",
      "Episode 1829 finished after 539 timesteps\n",
      "Total reward: 4657.96101433169, Epsilon: 0.749\n",
      "Episode 1830 finished after 673 timesteps\n",
      "Total reward: 4342.545064712167, Epsilon: 0.749\n",
      "Episode 1831 finished after 777 timesteps\n",
      "Total reward: 5485.188107508819, Epsilon: 0.749\n",
      "Episode 1832 finished after 1154 timesteps\n",
      "Total reward: 6443.02330621165, Epsilon: 0.749\n",
      "Episode 1833 finished after 2324 timesteps\n",
      "Total reward: 13017.46431098216, Epsilon: 0.749\n",
      "Episode 1834 finished after 3001 timesteps\n",
      "Total reward: 14015.75919676487, Epsilon: 0.749\n",
      "Episode 1835 finished after 586 timesteps\n",
      "Total reward: 4350.592732150865, Epsilon: 0.749\n",
      "Episode 1836 finished after 2128 timesteps\n",
      "Total reward: 13583.899471235503, Epsilon: 0.749\n",
      "Episode 1837 finished after 440 timesteps\n",
      "Total reward: 3285.811162775334, Epsilon: 0.749\n",
      "Episode 1838 finished after 748 timesteps\n",
      "Total reward: 4611.7440528268025, Epsilon: 0.749\n",
      "Episode 1839 finished after 3001 timesteps\n",
      "Total reward: 14976.905094098205, Epsilon: 0.749\n",
      "Episode 1840 finished after 3001 timesteps\n",
      "Total reward: 13366.943554861306, Epsilon: 0.749\n",
      "Episode 1841 finished after 3001 timesteps\n",
      "Total reward: 22421.478334096653, Epsilon: 0.749\n",
      "Episode 1842 finished after 268 timesteps\n",
      "Total reward: 2521.762638927708, Epsilon: 0.749\n",
      "Episode 1843 finished after 3001 timesteps\n",
      "Total reward: 14741.422230813845, Epsilon: 0.748\n",
      "Episode 1844 finished after 194 timesteps\n",
      "Total reward: 1918.672969843254, Epsilon: 0.748\n",
      "Episode 1845 finished after 228 timesteps\n",
      "Total reward: 2110.0699229982997, Epsilon: 0.748\n",
      "Episode 1846 finished after 2128 timesteps\n",
      "Total reward: 11279.056494037455, Epsilon: 0.748\n",
      "Episode 1847 finished after 785 timesteps\n",
      "Total reward: 4783.378244748567, Epsilon: 0.748\n",
      "Episode 1848 finished after 682 timesteps\n",
      "Total reward: 4523.126987576681, Epsilon: 0.748\n",
      "Episode 1849 finished after 3001 timesteps\n",
      "Total reward: 13719.418577617158, Epsilon: 0.748\n",
      "Episode 1850 finished after 3001 timesteps\n",
      "Total reward: 13578.606607497553, Epsilon: 0.748\n",
      "Episode 1851 finished after 1096 timesteps\n",
      "Total reward: 7434.305161033956, Epsilon: 0.748\n",
      "Episode 1852 finished after 3001 timesteps\n",
      "Total reward: 17803.669146490407, Epsilon: 0.748\n",
      "Episode 1853 finished after 3001 timesteps\n",
      "Total reward: 17183.831853046737, Epsilon: 0.748\n",
      "Episode 1854 finished after 1657 timesteps\n",
      "Total reward: 9678.196473915452, Epsilon: 0.748\n",
      "Episode 1855 finished after 939 timesteps\n",
      "Total reward: 6087.023270192938, Epsilon: 0.748\n",
      "Episode 1856 finished after 720 timesteps\n",
      "Total reward: 7272.489213392914, Epsilon: 0.747\n",
      "Episode 1857 finished after 1302 timesteps\n",
      "Total reward: 7143.865502379679, Epsilon: 0.747\n",
      "Episode 1858 finished after 1201 timesteps\n",
      "Total reward: 8607.668506124817, Epsilon: 0.747\n",
      "Episode 1859 finished after 3001 timesteps\n",
      "Total reward: 14450.534747099915, Epsilon: 0.747\n",
      "Episode 1860 finished after 1995 timesteps\n",
      "Total reward: 13845.945308086199, Epsilon: 0.747\n",
      "Episode 1861 finished after 885 timesteps\n",
      "Total reward: 5795.0812108567425, Epsilon: 0.747\n",
      "Episode 1862 finished after 2361 timesteps\n",
      "Total reward: 17107.810821268296, Epsilon: 0.747\n",
      "Episode 1863 finished after 175 timesteps\n",
      "Total reward: 1928.226516368754, Epsilon: 0.747\n",
      "Episode 1864 finished after 885 timesteps\n",
      "Total reward: 7620.173297049334, Epsilon: 0.747\n",
      "Episode 1865 finished after 917 timesteps\n",
      "Total reward: 6337.100553188375, Epsilon: 0.747\n",
      "Episode 1866 finished after 1569 timesteps\n",
      "Total reward: 8777.569480828253, Epsilon: 0.747\n",
      "Episode 1867 finished after 925 timesteps\n",
      "Total reward: 6965.510042874723, Epsilon: 0.747\n",
      "Episode 1868 finished after 590 timesteps\n",
      "Total reward: 5282.092638956023, Epsilon: 0.747\n",
      "Episode 1869 finished after 2944 timesteps\n",
      "Total reward: 15279.612545931472, Epsilon: 0.746\n",
      "Episode 1870 finished after 233 timesteps\n",
      "Total reward: 1985.2333903955218, Epsilon: 0.746\n",
      "Episode 1871 finished after 1299 timesteps\n",
      "Total reward: 8561.759613545775, Epsilon: 0.746\n",
      "Episode 1872 finished after 382 timesteps\n",
      "Total reward: 2912.7041811936724, Epsilon: 0.746\n",
      "Episode 1873 finished after 963 timesteps\n",
      "Total reward: 6534.990442621552, Epsilon: 0.746\n",
      "Episode 1874 finished after 1483 timesteps\n",
      "Total reward: 8329.710493786673, Epsilon: 0.746\n",
      "Episode 1875 finished after 2905 timesteps\n",
      "Total reward: 16299.727726818244, Epsilon: 0.746\n",
      "Episode 1876 finished after 561 timesteps\n",
      "Total reward: 3071.715556122698, Epsilon: 0.746\n",
      "Episode 1877 finished after 3001 timesteps\n",
      "Total reward: 16172.559654200555, Epsilon: 0.746\n",
      "Episode 1878 finished after 1687 timesteps\n",
      "Total reward: 9787.66149801633, Epsilon: 0.746\n",
      "Episode 1879 finished after 2665 timesteps\n",
      "Total reward: 13031.54870750113, Epsilon: 0.746\n",
      "Episode 1880 finished after 642 timesteps\n",
      "Total reward: 4445.155432551783, Epsilon: 0.746\n",
      "Episode 1881 finished after 492 timesteps\n",
      "Total reward: 5497.697655368285, Epsilon: 0.746\n",
      "Episode 1882 finished after 2294 timesteps\n",
      "Total reward: 13796.172907978696, Epsilon: 0.746\n",
      "Episode 1883 finished after 1191 timesteps\n",
      "Total reward: 6982.245824629499, Epsilon: 0.745\n",
      "Episode 1884 finished after 1279 timesteps\n",
      "Total reward: 9317.719656192829, Epsilon: 0.745\n",
      "Episode 1885 finished after 1706 timesteps\n",
      "Total reward: 10115.7906165709, Epsilon: 0.745\n",
      "Episode 1886 finished after 1370 timesteps\n",
      "Total reward: 7688.220109470865, Epsilon: 0.745\n",
      "Episode 1887 finished after 838 timesteps\n",
      "Total reward: 5481.089498149358, Epsilon: 0.745\n",
      "Episode 1888 finished after 1798 timesteps\n",
      "Total reward: 9733.89806848869, Epsilon: 0.745\n",
      "Episode 1889 finished after 613 timesteps\n",
      "Total reward: 3794.871392257142, Epsilon: 0.745\n",
      "Episode 1890 finished after 1613 timesteps\n",
      "Total reward: 9967.023251082843, Epsilon: 0.745\n",
      "Episode 1891 finished after 1355 timesteps\n",
      "Total reward: 8066.632013015303, Epsilon: 0.745\n",
      "Episode 1892 finished after 2556 timesteps\n",
      "Total reward: 12324.628508745376, Epsilon: 0.745\n",
      "Episode 1893 finished after 1069 timesteps\n",
      "Total reward: 5308.5977277887405, Epsilon: 0.745\n",
      "Episode 1894 finished after 3001 timesteps\n",
      "Total reward: 15753.71196801364, Epsilon: 0.745\n",
      "Episode 1895 finished after 594 timesteps\n",
      "Total reward: 5031.65124081885, Epsilon: 0.745\n",
      "Episode 1896 finished after 1979 timesteps\n",
      "Total reward: 9933.682683204277, Epsilon: 0.744\n",
      "Episode 1897 finished after 2043 timesteps\n",
      "Total reward: 9883.708829449693, Epsilon: 0.744\n",
      "Episode 1898 finished after 1153 timesteps\n",
      "Total reward: 6944.679288685649, Epsilon: 0.744\n",
      "Episode 1899 finished after 3001 timesteps\n",
      "Total reward: 14163.663527682258, Epsilon: 0.744\n",
      "Episode 1900 finished after 1959 timesteps\n",
      "Total reward: 14139.64805491284, Epsilon: 0.744\n",
      "Episode 1901 finished after 1283 timesteps\n",
      "Total reward: 6671.074556881386, Epsilon: 0.744\n",
      "Episode 1902 finished after 1178 timesteps\n",
      "Total reward: 6945.395112071172, Epsilon: 0.744\n",
      "Episode 1903 finished after 1110 timesteps\n",
      "Total reward: 6596.071930439287, Epsilon: 0.744\n",
      "Episode 1904 finished after 1579 timesteps\n",
      "Total reward: 9069.568383423917, Epsilon: 0.744\n",
      "Episode 1905 finished after 1025 timesteps\n",
      "Total reward: 5012.6956701309055, Epsilon: 0.744\n",
      "Episode 1906 finished after 242 timesteps\n",
      "Total reward: 2671.9253196725044, Epsilon: 0.744\n",
      "Episode 1907 finished after 936 timesteps\n",
      "Total reward: 6357.322018134092, Epsilon: 0.744\n",
      "Episode 1908 finished after 1071 timesteps\n",
      "Total reward: 5915.603255406512, Epsilon: 0.744\n",
      "Episode 1909 finished after 227 timesteps\n",
      "Total reward: 2108.7298908306384, Epsilon: 0.744\n",
      "Episode 1910 finished after 574 timesteps\n",
      "Total reward: 3624.027312694607, Epsilon: 0.743\n",
      "Episode 1911 finished after 1138 timesteps\n",
      "Total reward: 5703.007886794863, Epsilon: 0.743\n",
      "Episode 1912 finished after 1176 timesteps\n",
      "Total reward: 7799.626517851891, Epsilon: 0.743\n",
      "Episode 1913 finished after 2169 timesteps\n",
      "Total reward: 15057.187113923335, Epsilon: 0.743\n",
      "Episode 1914 finished after 1584 timesteps\n",
      "Total reward: 10136.918632631932, Epsilon: 0.743\n",
      "Episode 1915 finished after 3001 timesteps\n",
      "Total reward: 13766.53806192105, Epsilon: 0.743\n",
      "Episode 1916 finished after 2359 timesteps\n",
      "Total reward: 14556.454987686031, Epsilon: 0.743\n",
      "Episode 1917 finished after 3001 timesteps\n",
      "Total reward: 13838.135594015097, Epsilon: 0.743\n",
      "Episode 1918 finished after 1286 timesteps\n",
      "Total reward: 6645.898818115349, Epsilon: 0.743\n",
      "Episode 1919 finished after 751 timesteps\n",
      "Total reward: 4090.8309989218933, Epsilon: 0.743\n",
      "Episode 1920 finished after 2375 timesteps\n",
      "Total reward: 12182.899409303847, Epsilon: 0.743\n",
      "Episode 1921 finished after 2616 timesteps\n",
      "Total reward: 18263.32348020861, Epsilon: 0.743\n",
      "Episode 1922 finished after 1311 timesteps\n",
      "Total reward: 10144.363227396014, Epsilon: 0.743\n",
      "Episode 1923 finished after 2379 timesteps\n",
      "Total reward: 14832.41203263939, Epsilon: 0.742\n",
      "Episode 1924 finished after 3001 timesteps\n",
      "Total reward: 15074.60883778683, Epsilon: 0.742\n",
      "Episode 1925 finished after 664 timesteps\n",
      "Total reward: 5146.525892557098, Epsilon: 0.742\n",
      "Episode 1926 finished after 2166 timesteps\n",
      "Total reward: 13015.175828457044, Epsilon: 0.742\n",
      "Episode 1927 finished after 3001 timesteps\n",
      "Total reward: 15901.040930562547, Epsilon: 0.742\n",
      "Episode 1928 finished after 1012 timesteps\n",
      "Total reward: 5383.539321840228, Epsilon: 0.742\n",
      "Episode 1929 finished after 1801 timesteps\n",
      "Total reward: 9979.586049301119, Epsilon: 0.742\n",
      "Episode 1930 finished after 1405 timesteps\n",
      "Total reward: 9282.322188687429, Epsilon: 0.742\n",
      "Episode 1931 finished after 994 timesteps\n",
      "Total reward: 5561.969744403879, Epsilon: 0.742\n",
      "Episode 1932 finished after 3001 timesteps\n",
      "Total reward: 15353.21768634465, Epsilon: 0.742\n",
      "Episode 1933 finished after 3001 timesteps\n",
      "Total reward: 16315.139730448627, Epsilon: 0.742\n",
      "Episode 1934 finished after 905 timesteps\n",
      "Total reward: 6345.3891671065985, Epsilon: 0.742\n",
      "Episode 1935 finished after 3001 timesteps\n",
      "Total reward: 17091.19308303012, Epsilon: 0.742\n",
      "Episode 1936 finished after 3001 timesteps\n",
      "Total reward: 12962.923782173626, Epsilon: 0.742\n",
      "Episode 1937 finished after 1466 timesteps\n",
      "Total reward: 8425.716047114784, Epsilon: 0.741\n",
      "Episode 1938 finished after 877 timesteps\n",
      "Total reward: 5441.050691133891, Epsilon: 0.741\n",
      "Episode 1939 finished after 2956 timesteps\n",
      "Total reward: 14001.056045228886, Epsilon: 0.741\n",
      "Episode 1940 finished after 1643 timesteps\n",
      "Total reward: 8413.28783907243, Epsilon: 0.741\n",
      "Episode 1941 finished after 687 timesteps\n",
      "Total reward: 4437.86889311281, Epsilon: 0.741\n",
      "Episode 1942 finished after 2205 timesteps\n",
      "Total reward: 11603.910133291092, Epsilon: 0.741\n",
      "Episode 1943 finished after 3001 timesteps\n",
      "Total reward: 18924.28699503781, Epsilon: 0.741\n",
      "Episode 1944 finished after 1463 timesteps\n",
      "Total reward: 7249.510108524697, Epsilon: 0.741\n",
      "Episode 1945 finished after 390 timesteps\n",
      "Total reward: 3385.4172256224892, Epsilon: 0.741\n",
      "Episode 1946 finished after 479 timesteps\n",
      "Total reward: 4980.9082178377785, Epsilon: 0.741\n",
      "Episode 1947 finished after 3001 timesteps\n",
      "Total reward: 15161.941383907084, Epsilon: 0.741\n",
      "Episode 1948 finished after 260 timesteps\n",
      "Total reward: 2703.5674813508235, Epsilon: 0.741\n",
      "Episode 1949 finished after 2855 timesteps\n",
      "Total reward: 16590.867939084404, Epsilon: 0.741\n",
      "Episode 1950 finished after 3001 timesteps\n",
      "Total reward: 14300.718595528377, Epsilon: 0.740\n",
      "Episode 1951 finished after 3001 timesteps\n",
      "Total reward: 15372.010758032753, Epsilon: 0.740\n",
      "Episode 1952 finished after 1600 timesteps\n",
      "Total reward: 10441.607000672588, Epsilon: 0.740\n",
      "Episode 1953 finished after 1041 timesteps\n",
      "Total reward: 8970.408766875897, Epsilon: 0.740\n",
      "Episode 1954 finished after 1946 timesteps\n",
      "Total reward: 10799.43975510626, Epsilon: 0.740\n",
      "Episode 1955 finished after 2771 timesteps\n",
      "Total reward: 13636.477758699059, Epsilon: 0.740\n",
      "Episode 1956 finished after 488 timesteps\n",
      "Total reward: 3387.7800001599708, Epsilon: 0.740\n",
      "Episode 1957 finished after 1458 timesteps\n",
      "Total reward: 10295.242525941458, Epsilon: 0.740\n",
      "Episode 1958 finished after 3001 timesteps\n",
      "Total reward: 14444.141441960908, Epsilon: 0.740\n",
      "Episode 1959 finished after 3001 timesteps\n",
      "Total reward: 15338.738744061457, Epsilon: 0.740\n",
      "Episode 1960 finished after 3001 timesteps\n",
      "Total reward: 13568.82141125138, Epsilon: 0.740\n",
      "Episode 1961 finished after 494 timesteps\n",
      "Total reward: 3039.9910235585867, Epsilon: 0.740\n",
      "Episode 1962 finished after 1393 timesteps\n",
      "Total reward: 7082.5350401102805, Epsilon: 0.740\n",
      "Episode 1963 finished after 689 timesteps\n",
      "Total reward: 3976.0618549726773, Epsilon: 0.740\n",
      "Episode 1964 finished after 1434 timesteps\n",
      "Total reward: 10326.593854632234, Epsilon: 0.739\n",
      "Episode 1965 finished after 1017 timesteps\n",
      "Total reward: 6427.248573727986, Epsilon: 0.739\n",
      "Episode 1966 finished after 510 timesteps\n",
      "Total reward: 3600.829366444449, Epsilon: 0.739\n",
      "Episode 1967 finished after 3001 timesteps\n",
      "Total reward: 13588.382963358254, Epsilon: 0.739\n",
      "Episode 1968 finished after 2432 timesteps\n",
      "Total reward: 12951.573186960855, Epsilon: 0.739\n",
      "Episode 1969 finished after 1084 timesteps\n",
      "Total reward: 6877.775014112303, Epsilon: 0.739\n",
      "Episode 1970 finished after 1102 timesteps\n",
      "Total reward: 6279.093462362463, Epsilon: 0.739\n",
      "Episode 1971 finished after 2189 timesteps\n",
      "Total reward: 15137.815899254736, Epsilon: 0.739\n",
      "Episode 1972 finished after 429 timesteps\n",
      "Total reward: 4277.423240970844, Epsilon: 0.739\n",
      "Episode 1973 finished after 868 timesteps\n",
      "Total reward: 5247.5783040380475, Epsilon: 0.739\n",
      "Episode 1974 finished after 1880 timesteps\n",
      "Total reward: 9457.234772461283, Epsilon: 0.739\n",
      "Episode 1975 finished after 3001 timesteps\n",
      "Total reward: 15836.773414546513, Epsilon: 0.739\n",
      "Episode 1976 finished after 1384 timesteps\n",
      "Total reward: 8604.669952829316, Epsilon: 0.739\n",
      "Episode 1977 finished after 3001 timesteps\n",
      "Total reward: 13137.883707154871, Epsilon: 0.738\n",
      "Episode 1978 finished after 1201 timesteps\n",
      "Total reward: 8287.805948762934, Epsilon: 0.738\n",
      "Episode 1979 finished after 3001 timesteps\n",
      "Total reward: 15280.144426931896, Epsilon: 0.738\n",
      "Episode 1980 finished after 997 timesteps\n",
      "Total reward: 6169.810655302669, Epsilon: 0.738\n",
      "Episode 1981 finished after 2562 timesteps\n",
      "Total reward: 14134.984113191638, Epsilon: 0.738\n",
      "Episode 1982 finished after 2493 timesteps\n",
      "Total reward: 11967.97778769968, Epsilon: 0.738\n",
      "Episode 1983 finished after 1109 timesteps\n",
      "Total reward: 7464.988278513505, Epsilon: 0.738\n",
      "Episode 1984 finished after 945 timesteps\n",
      "Total reward: 6283.941716078395, Epsilon: 0.738\n",
      "Episode 1985 finished after 1496 timesteps\n",
      "Total reward: 8113.201031109198, Epsilon: 0.738\n",
      "Episode 1986 finished after 140 timesteps\n",
      "Total reward: 1572.479027299834, Epsilon: 0.738\n",
      "Episode 1987 finished after 925 timesteps\n",
      "Total reward: 5594.040690230829, Epsilon: 0.738\n",
      "Episode 1988 finished after 3001 timesteps\n",
      "Total reward: 19738.241339365126, Epsilon: 0.738\n",
      "Episode 1989 finished after 2062 timesteps\n",
      "Total reward: 14041.105940764648, Epsilon: 0.738\n",
      "Episode 1990 finished after 962 timesteps\n",
      "Total reward: 5860.378470158889, Epsilon: 0.738\n",
      "Episode 1991 finished after 1427 timesteps\n",
      "Total reward: 7554.614191388343, Epsilon: 0.737\n",
      "Episode 1992 finished after 3001 timesteps\n",
      "Total reward: 12732.816199069926, Epsilon: 0.737\n",
      "Episode 1993 finished after 3001 timesteps\n",
      "Total reward: 12956.848848750613, Epsilon: 0.737\n",
      "Episode 1994 finished after 2889 timesteps\n",
      "Total reward: 16345.507152633065, Epsilon: 0.737\n",
      "Episode 1995 finished after 2139 timesteps\n",
      "Total reward: 11366.871746202582, Epsilon: 0.737\n",
      "Episode 1996 finished after 1972 timesteps\n",
      "Total reward: 10669.514082730411, Epsilon: 0.737\n",
      "Episode 1997 finished after 1536 timesteps\n",
      "Total reward: 8171.004737887441, Epsilon: 0.737\n",
      "Episode 1998 finished after 474 timesteps\n",
      "Total reward: 3655.8549913681354, Epsilon: 0.737\n",
      "Episode 1999 finished after 3001 timesteps\n",
      "Total reward: 14406.21823494478, Epsilon: 0.737\n",
      "Episode 2000 finished after 478 timesteps\n",
      "Total reward: 4598.4742402974125, Epsilon: 0.737\n",
      "Episode 2001 finished after 2732 timesteps\n",
      "Total reward: 15627.73027110521, Epsilon: 0.737\n",
      "Episode 2002 finished after 2027 timesteps\n",
      "Total reward: 11767.40558868381, Epsilon: 0.737\n",
      "Episode 2003 finished after 960 timesteps\n",
      "Total reward: 5411.523473812269, Epsilon: 0.737\n",
      "Episode 2004 finished after 267 timesteps\n",
      "Total reward: 2526.300036016736, Epsilon: 0.736\n",
      "Episode 2005 finished after 1632 timesteps\n",
      "Total reward: 9425.912339974595, Epsilon: 0.736\n",
      "Episode 2006 finished after 1378 timesteps\n",
      "Total reward: 7401.506063274197, Epsilon: 0.736\n",
      "Episode 2007 finished after 2387 timesteps\n",
      "Total reward: 17815.59245032062, Epsilon: 0.736\n",
      "Episode 2008 finished after 3001 timesteps\n",
      "Total reward: 13475.951404670132, Epsilon: 0.736\n",
      "Episode 2009 finished after 404 timesteps\n",
      "Total reward: 3494.0845624430463, Epsilon: 0.736\n",
      "Episode 2010 finished after 2775 timesteps\n",
      "Total reward: 19447.591646838657, Epsilon: 0.736\n",
      "Episode 2011 finished after 640 timesteps\n",
      "Total reward: 4169.909266770568, Epsilon: 0.736\n",
      "Episode 2012 finished after 893 timesteps\n",
      "Total reward: 5444.8474612029595, Epsilon: 0.736\n",
      "Episode 2013 finished after 3001 timesteps\n",
      "Total reward: 12781.721358103568, Epsilon: 0.736\n",
      "Episode 2014 finished after 2612 timesteps\n",
      "Total reward: 12710.540808896616, Epsilon: 0.736\n",
      "Episode 2015 finished after 3001 timesteps\n",
      "Total reward: 14979.014190806207, Epsilon: 0.736\n",
      "Episode 2016 finished after 994 timesteps\n",
      "Total reward: 6483.056041865469, Epsilon: 0.736\n",
      "Episode 2017 finished after 2049 timesteps\n",
      "Total reward: 11231.02216312961, Epsilon: 0.736\n",
      "Episode 2018 finished after 1658 timesteps\n",
      "Total reward: 8485.877530865331, Epsilon: 0.735\n",
      "Episode 2019 finished after 1127 timesteps\n",
      "Total reward: 6790.274515318873, Epsilon: 0.735\n",
      "Episode 2020 finished after 1008 timesteps\n",
      "Total reward: 7361.126221405443, Epsilon: 0.735\n",
      "Episode 2021 finished after 1489 timesteps\n",
      "Total reward: 9073.466577559882, Epsilon: 0.735\n",
      "Episode 2022 finished after 1996 timesteps\n",
      "Total reward: 9561.007401466291, Epsilon: 0.735\n",
      "Episode 2023 finished after 3001 timesteps\n",
      "Total reward: 14497.652858757261, Epsilon: 0.735\n",
      "Episode 2024 finished after 2007 timesteps\n",
      "Total reward: 10046.234285197641, Epsilon: 0.735\n",
      "Episode 2025 finished after 1884 timesteps\n",
      "Total reward: 12473.593618392411, Epsilon: 0.735\n",
      "Episode 2026 finished after 1726 timesteps\n",
      "Total reward: 8921.505030252185, Epsilon: 0.735\n",
      "Episode 2027 finished after 3001 timesteps\n",
      "Total reward: 12917.16586783737, Epsilon: 0.735\n",
      "Episode 2028 finished after 230 timesteps\n",
      "Total reward: 2346.1378148986278, Epsilon: 0.735\n",
      "Episode 2029 finished after 3001 timesteps\n",
      "Total reward: 14612.211534936008, Epsilon: 0.735\n",
      "Episode 2030 finished after 506 timesteps\n",
      "Total reward: 3436.613763184399, Epsilon: 0.735\n",
      "Episode 2031 finished after 2785 timesteps\n",
      "Total reward: 17375.356468483624, Epsilon: 0.734\n",
      "Episode 2032 finished after 1002 timesteps\n",
      "Total reward: 5511.164546911602, Epsilon: 0.734\n",
      "Episode 2033 finished after 3001 timesteps\n",
      "Total reward: 14588.051956753476, Epsilon: 0.734\n",
      "Episode 2034 finished after 410 timesteps\n",
      "Total reward: 3933.3531994400573, Epsilon: 0.734\n",
      "Episode 2035 finished after 2473 timesteps\n",
      "Total reward: 12014.512609537007, Epsilon: 0.734\n",
      "Episode 2036 finished after 150 timesteps\n",
      "Total reward: 1695.7628669886958, Epsilon: 0.734\n",
      "Episode 2037 finished after 670 timesteps\n",
      "Total reward: 4930.851822458056, Epsilon: 0.734\n",
      "Episode 2038 finished after 1588 timesteps\n",
      "Total reward: 8751.562652353632, Epsilon: 0.734\n",
      "Episode 2039 finished after 1294 timesteps\n",
      "Total reward: 7617.255606484607, Epsilon: 0.734\n",
      "Episode 2040 finished after 1781 timesteps\n",
      "Total reward: 10190.711506523836, Epsilon: 0.734\n",
      "Episode 2041 finished after 3001 timesteps\n",
      "Total reward: 15173.867386236172, Epsilon: 0.734\n",
      "Episode 2042 finished after 1188 timesteps\n",
      "Total reward: 6409.721307831646, Epsilon: 0.734\n",
      "Episode 2043 finished after 1179 timesteps\n",
      "Total reward: 6242.728652027878, Epsilon: 0.734\n",
      "Episode 2044 finished after 1107 timesteps\n",
      "Total reward: 8593.135770094437, Epsilon: 0.734\n",
      "Episode 2045 finished after 1521 timesteps\n",
      "Total reward: 9064.354832741994, Epsilon: 0.733\n",
      "Episode 2046 finished after 1963 timesteps\n",
      "Total reward: 12208.88009358905, Epsilon: 0.733\n",
      "Episode 2047 finished after 2523 timesteps\n",
      "Total reward: 15859.692435377192, Epsilon: 0.733\n",
      "Episode 2048 finished after 580 timesteps\n",
      "Total reward: 3397.653303468454, Epsilon: 0.733\n",
      "Episode 2049 finished after 2013 timesteps\n",
      "Total reward: 10914.73509551812, Epsilon: 0.733\n",
      "Episode 2050 finished after 377 timesteps\n",
      "Total reward: 2484.187490678917, Epsilon: 0.733\n",
      "Episode 2051 finished after 3001 timesteps\n",
      "Total reward: 13778.529556892274, Epsilon: 0.733\n",
      "Episode 2052 finished after 1682 timesteps\n",
      "Total reward: 9881.918322905016, Epsilon: 0.733\n",
      "Episode 2053 finished after 3001 timesteps\n",
      "Total reward: 12666.989658246313, Epsilon: 0.733\n",
      "Episode 2054 finished after 3001 timesteps\n",
      "Total reward: 14642.892773026839, Epsilon: 0.733\n",
      "Episode 2055 finished after 1028 timesteps\n",
      "Total reward: 6202.68176955257, Epsilon: 0.733\n",
      "Episode 2056 finished after 2612 timesteps\n",
      "Total reward: 14532.134622457834, Epsilon: 0.733\n",
      "Episode 2057 finished after 513 timesteps\n",
      "Total reward: 4261.63516758942, Epsilon: 0.733\n",
      "Episode 2058 finished after 783 timesteps\n",
      "Total reward: 6517.147905510235, Epsilon: 0.733\n",
      "Episode 2059 finished after 391 timesteps\n",
      "Total reward: 2480.603696391409, Epsilon: 0.732\n",
      "Episode 2060 finished after 2079 timesteps\n",
      "Total reward: 15399.26791250151, Epsilon: 0.732\n",
      "Episode 2061 finished after 507 timesteps\n",
      "Total reward: 3075.0441907862073, Epsilon: 0.732\n",
      "Episode 2062 finished after 3001 timesteps\n",
      "Total reward: 16829.25443557033, Epsilon: 0.732\n",
      "Episode 2063 finished after 848 timesteps\n",
      "Total reward: 5649.982587336078, Epsilon: 0.732\n",
      "Episode 2064 finished after 2515 timesteps\n",
      "Total reward: 12543.777360033255, Epsilon: 0.732\n",
      "Episode 2065 finished after 224 timesteps\n",
      "Total reward: 1976.235929317794, Epsilon: 0.732\n",
      "Episode 2066 finished after 3001 timesteps\n",
      "Total reward: 14561.41018285912, Epsilon: 0.732\n",
      "Episode 2067 finished after 232 timesteps\n",
      "Total reward: 2061.378005948935, Epsilon: 0.732\n",
      "Episode 2068 finished after 2328 timesteps\n",
      "Total reward: 12718.245602216832, Epsilon: 0.732\n",
      "Episode 2069 finished after 1771 timesteps\n",
      "Total reward: 11015.563924779772, Epsilon: 0.732\n",
      "Episode 2070 finished after 2609 timesteps\n",
      "Total reward: 15288.408969594531, Epsilon: 0.732\n",
      "Episode 2071 finished after 333 timesteps\n",
      "Total reward: 2618.6518855086756, Epsilon: 0.732\n",
      "Episode 2072 finished after 3001 timesteps\n",
      "Total reward: 13777.124093181812, Epsilon: 0.731\n",
      "Episode 2073 finished after 3001 timesteps\n",
      "Total reward: 13671.488733745651, Epsilon: 0.731\n",
      "Episode 2074 finished after 195 timesteps\n",
      "Total reward: 1779.7171898134372, Epsilon: 0.731\n",
      "Episode 2075 finished after 2509 timesteps\n",
      "Total reward: 13123.61617075358, Epsilon: 0.731\n",
      "Episode 2076 finished after 3001 timesteps\n",
      "Total reward: 13439.05041379364, Epsilon: 0.731\n",
      "Episode 2077 finished after 2808 timesteps\n",
      "Total reward: 13501.55178486724, Epsilon: 0.731\n",
      "Episode 2078 finished after 1386 timesteps\n",
      "Total reward: 8722.156362814756, Epsilon: 0.731\n",
      "Episode 2079 finished after 1626 timesteps\n",
      "Total reward: 8357.576441850335, Epsilon: 0.731\n",
      "Episode 2080 finished after 283 timesteps\n",
      "Total reward: 2379.1915752104705, Epsilon: 0.731\n",
      "Episode 2081 finished after 3001 timesteps\n",
      "Total reward: 14230.11533688912, Epsilon: 0.731\n",
      "Episode 2082 finished after 763 timesteps\n",
      "Total reward: 4820.426849548796, Epsilon: 0.731\n",
      "Episode 2083 finished after 515 timesteps\n",
      "Total reward: 4617.175612927258, Epsilon: 0.731\n",
      "Episode 2084 finished after 3001 timesteps\n",
      "Total reward: 13728.698679690991, Epsilon: 0.731\n",
      "Episode 2085 finished after 2759 timesteps\n",
      "Total reward: 17830.30025308152, Epsilon: 0.731\n",
      "Episode 2086 finished after 744 timesteps\n",
      "Total reward: 4777.467251733224, Epsilon: 0.730\n",
      "Episode 2087 finished after 855 timesteps\n",
      "Total reward: 6458.817546281831, Epsilon: 0.730\n",
      "Episode 2088 finished after 773 timesteps\n",
      "Total reward: 5846.0618041050175, Epsilon: 0.730\n",
      "Episode 2089 finished after 3001 timesteps\n",
      "Total reward: 15623.33602715312, Epsilon: 0.730\n",
      "Episode 2090 finished after 627 timesteps\n",
      "Total reward: 3920.9983552148738, Epsilon: 0.730\n",
      "Episode 2091 finished after 609 timesteps\n",
      "Total reward: 4922.839048395802, Epsilon: 0.730\n",
      "Episode 2092 finished after 853 timesteps\n",
      "Total reward: 4554.922226436656, Epsilon: 0.730\n",
      "Episode 2093 finished after 1144 timesteps\n",
      "Total reward: 7138.347380535269, Epsilon: 0.730\n",
      "Episode 2094 finished after 3001 timesteps\n",
      "Total reward: 18153.838170287498, Epsilon: 0.730\n",
      "Episode 2095 finished after 3001 timesteps\n",
      "Total reward: 16395.942999907882, Epsilon: 0.730\n",
      "Episode 2096 finished after 1390 timesteps\n",
      "Total reward: 8492.146334721338, Epsilon: 0.730\n",
      "Episode 2097 finished after 2318 timesteps\n",
      "Total reward: 11132.767612361227, Epsilon: 0.730\n",
      "Episode 2098 finished after 524 timesteps\n",
      "Total reward: 3703.4787377138155, Epsilon: 0.730\n",
      "Episode 2099 finished after 3001 timesteps\n",
      "Total reward: 13796.262873995205, Epsilon: 0.730\n",
      "Episode 2100 finished after 2139 timesteps\n",
      "Total reward: 11995.365873474253, Epsilon: 0.729\n",
      "Episode 2101 finished after 3001 timesteps\n",
      "Total reward: 15035.14327954918, Epsilon: 0.729\n",
      "Episode 2102 finished after 3001 timesteps\n",
      "Total reward: 15447.162932454903, Epsilon: 0.729\n",
      "Episode 2103 finished after 510 timesteps\n",
      "Total reward: 3840.1378451559463, Epsilon: 0.729\n",
      "Episode 2104 finished after 3001 timesteps\n",
      "Total reward: 17113.778269012233, Epsilon: 0.729\n",
      "Episode 2105 finished after 3001 timesteps\n",
      "Total reward: 14104.493734010204, Epsilon: 0.729\n",
      "Episode 2106 finished after 3001 timesteps\n",
      "Total reward: 13234.076090059061, Epsilon: 0.729\n",
      "Episode 2107 finished after 3001 timesteps\n",
      "Total reward: 17474.009614572104, Epsilon: 0.729\n",
      "Episode 2108 finished after 1229 timesteps\n",
      "Total reward: 10747.719061198755, Epsilon: 0.729\n",
      "Episode 2109 finished after 237 timesteps\n",
      "Total reward: 2526.574236441938, Epsilon: 0.729\n",
      "Episode 2110 finished after 561 timesteps\n",
      "Total reward: 3941.0818695942644, Epsilon: 0.729\n",
      "Episode 2111 finished after 3001 timesteps\n",
      "Total reward: 13319.461538597396, Epsilon: 0.729\n",
      "Episode 2112 finished after 1619 timesteps\n",
      "Total reward: 11351.035267848276, Epsilon: 0.729\n",
      "Episode 2113 finished after 2053 timesteps\n",
      "Total reward: 9832.567854822155, Epsilon: 0.728\n",
      "Episode 2114 finished after 3001 timesteps\n",
      "Total reward: 13749.77188593875, Epsilon: 0.728\n",
      "Episode 2115 finished after 3001 timesteps\n",
      "Total reward: 16161.47891821698, Epsilon: 0.728\n",
      "Episode 2116 finished after 2252 timesteps\n",
      "Total reward: 10973.431418367198, Epsilon: 0.728\n",
      "Episode 2117 finished after 3001 timesteps\n",
      "Total reward: 13475.569606757372, Epsilon: 0.728\n",
      "Episode 2118 finished after 1065 timesteps\n",
      "Total reward: 6723.83790773934, Epsilon: 0.728\n",
      "Episode 2119 finished after 463 timesteps\n",
      "Total reward: 4941.974519436932, Epsilon: 0.728\n",
      "Episode 2120 finished after 3001 timesteps\n",
      "Total reward: 13002.009005568309, Epsilon: 0.728\n",
      "Episode 2121 finished after 909 timesteps\n",
      "Total reward: 6257.709435716273, Epsilon: 0.728\n",
      "Episode 2122 finished after 512 timesteps\n",
      "Total reward: 3330.2809423894205, Epsilon: 0.728\n",
      "Episode 2123 finished after 3001 timesteps\n",
      "Total reward: 15423.717872305993, Epsilon: 0.728\n",
      "Episode 2124 finished after 1198 timesteps\n",
      "Total reward: 6900.045701746937, Epsilon: 0.728\n",
      "Episode 2125 finished after 2618 timesteps\n",
      "Total reward: 14210.688457268148, Epsilon: 0.728\n",
      "Episode 2126 finished after 1279 timesteps\n",
      "Total reward: 8661.2042716568, Epsilon: 0.728\n",
      "Episode 2127 finished after 3001 timesteps\n",
      "Total reward: 16626.475857845347, Epsilon: 0.727\n",
      "Episode 2128 finished after 3001 timesteps\n",
      "Total reward: 15801.356307254555, Epsilon: 0.727\n",
      "Episode 2129 finished after 432 timesteps\n",
      "Total reward: 2928.0209381107716, Epsilon: 0.727\n",
      "Episode 2130 finished after 3001 timesteps\n",
      "Total reward: 14872.841508046175, Epsilon: 0.727\n",
      "Episode 2131 finished after 2949 timesteps\n",
      "Total reward: 13870.793225300069, Epsilon: 0.727\n",
      "Episode 2132 finished after 567 timesteps\n",
      "Total reward: 5015.4366392097845, Epsilon: 0.727\n",
      "Episode 2133 finished after 640 timesteps\n",
      "Total reward: 6160.37586464551, Epsilon: 0.727\n",
      "Episode 2134 finished after 734 timesteps\n",
      "Total reward: 5587.69911958216, Epsilon: 0.727\n",
      "Episode 2135 finished after 1221 timesteps\n",
      "Total reward: 6424.890676670483, Epsilon: 0.727\n",
      "Episode 2136 finished after 2106 timesteps\n",
      "Total reward: 11665.999944221463, Epsilon: 0.727\n",
      "Episode 2137 finished after 3001 timesteps\n",
      "Total reward: 15495.009508299827, Epsilon: 0.727\n",
      "Episode 2138 finished after 3001 timesteps\n",
      "Total reward: 16874.850529023566, Epsilon: 0.727\n",
      "Episode 2139 finished after 2201 timesteps\n",
      "Total reward: 13257.011578165326, Epsilon: 0.727\n",
      "Episode 2140 finished after 1582 timesteps\n",
      "Total reward: 11132.187903363876, Epsilon: 0.727\n",
      "Episode 2141 finished after 3001 timesteps\n",
      "Total reward: 16143.524164762259, Epsilon: 0.726\n",
      "Episode 2142 finished after 1594 timesteps\n",
      "Total reward: 9665.680320047873, Epsilon: 0.726\n",
      "Episode 2143 finished after 3001 timesteps\n",
      "Total reward: 16406.740501230164, Epsilon: 0.726\n",
      "Episode 2144 finished after 511 timesteps\n",
      "Total reward: 3254.2701823304687, Epsilon: 0.726\n",
      "Episode 2145 finished after 3001 timesteps\n",
      "Total reward: 14708.054442143159, Epsilon: 0.726\n",
      "Episode 2146 finished after 3001 timesteps\n",
      "Total reward: 14722.25927582264, Epsilon: 0.726\n",
      "Episode 2147 finished after 322 timesteps\n",
      "Total reward: 3351.5079779953912, Epsilon: 0.726\n",
      "Episode 2148 finished after 2624 timesteps\n",
      "Total reward: 14055.225835040968, Epsilon: 0.726\n",
      "Episode 2149 finished after 2877 timesteps\n",
      "Total reward: 17648.3080660453, Epsilon: 0.726\n",
      "Episode 2150 finished after 3001 timesteps\n",
      "Total reward: 12681.979574448547, Epsilon: 0.726\n",
      "Episode 2151 finished after 999 timesteps\n",
      "Total reward: 5430.819911302363, Epsilon: 0.726\n",
      "Episode 2152 finished after 2583 timesteps\n",
      "Total reward: 13413.04940345347, Epsilon: 0.726\n",
      "Episode 2153 finished after 355 timesteps\n",
      "Total reward: 3170.1041508826656, Epsilon: 0.726\n",
      "Episode 2154 finished after 595 timesteps\n",
      "Total reward: 3961.312985468055, Epsilon: 0.726\n",
      "Episode 2155 finished after 395 timesteps\n",
      "Total reward: 4206.317956815785, Epsilon: 0.725\n",
      "Episode 2156 finished after 817 timesteps\n",
      "Total reward: 7881.517949821833, Epsilon: 0.725\n",
      "Episode 2157 finished after 3001 timesteps\n",
      "Total reward: 14320.217193077495, Epsilon: 0.725\n",
      "Episode 2158 finished after 339 timesteps\n",
      "Total reward: 2754.8276984418453, Epsilon: 0.725\n",
      "Episode 2159 finished after 2076 timesteps\n",
      "Total reward: 10360.364048632371, Epsilon: 0.725\n",
      "Episode 2160 finished after 3001 timesteps\n",
      "Total reward: 14301.995875479779, Epsilon: 0.725\n",
      "Episode 2161 finished after 2531 timesteps\n",
      "Total reward: 13061.907967101793, Epsilon: 0.725\n",
      "Episode 2162 finished after 3001 timesteps\n",
      "Total reward: 12926.266143714036, Epsilon: 0.725\n",
      "Episode 2163 finished after 761 timesteps\n",
      "Total reward: 4622.900555450377, Epsilon: 0.725\n",
      "Episode 2164 finished after 3001 timesteps\n",
      "Total reward: 13787.607905914974, Epsilon: 0.725\n",
      "Episode 2165 finished after 1516 timesteps\n",
      "Total reward: 7792.230581535541, Epsilon: 0.725\n",
      "Episode 2166 finished after 790 timesteps\n",
      "Total reward: 6013.464052969022, Epsilon: 0.725\n",
      "Episode 2167 finished after 1093 timesteps\n",
      "Total reward: 6920.10217924597, Epsilon: 0.725\n",
      "Episode 2168 finished after 391 timesteps\n",
      "Total reward: 3294.397845181517, Epsilon: 0.725\n",
      "Episode 2169 finished after 730 timesteps\n",
      "Total reward: 6539.456568725405, Epsilon: 0.724\n",
      "Episode 2170 finished after 3001 timesteps\n",
      "Total reward: 17463.698818444416, Epsilon: 0.724\n",
      "Episode 2171 finished after 1071 timesteps\n",
      "Total reward: 6761.076422087705, Epsilon: 0.724\n",
      "Episode 2172 finished after 2241 timesteps\n",
      "Total reward: 10571.213698755666, Epsilon: 0.724\n",
      "Episode 2173 finished after 2447 timesteps\n",
      "Total reward: 11535.465199816259, Epsilon: 0.724\n",
      "Episode 2174 finished after 3001 timesteps\n",
      "Total reward: 12617.832648923124, Epsilon: 0.724\n",
      "Episode 2175 finished after 3001 timesteps\n",
      "Total reward: 15206.960294799694, Epsilon: 0.724\n",
      "Episode 2176 finished after 1033 timesteps\n",
      "Total reward: 6566.676635800237, Epsilon: 0.724\n",
      "Episode 2177 finished after 1412 timesteps\n",
      "Total reward: 11527.429752158756, Epsilon: 0.724\n",
      "Episode 2178 finished after 2291 timesteps\n",
      "Total reward: 10443.802287981582, Epsilon: 0.724\n",
      "Episode 2179 finished after 1326 timesteps\n",
      "Total reward: 8874.02879176117, Epsilon: 0.724\n",
      "Episode 2180 finished after 543 timesteps\n",
      "Total reward: 3417.28889458361, Epsilon: 0.724\n",
      "Episode 2181 finished after 1553 timesteps\n",
      "Total reward: 7569.729438502926, Epsilon: 0.724\n",
      "Episode 2182 finished after 1781 timesteps\n",
      "Total reward: 8643.62142552917, Epsilon: 0.723\n",
      "Episode 2183 finished after 1888 timesteps\n",
      "Total reward: 8866.56392086553, Epsilon: 0.723\n",
      "Episode 2184 finished after 3001 timesteps\n",
      "Total reward: 21571.943113970316, Epsilon: 0.723\n",
      "Episode 2185 finished after 1219 timesteps\n",
      "Total reward: 8003.384271942343, Epsilon: 0.723\n",
      "Episode 2186 finished after 2461 timesteps\n",
      "Total reward: 14270.43442238993, Epsilon: 0.723\n",
      "Episode 2187 finished after 1037 timesteps\n",
      "Total reward: 6607.339127912416, Epsilon: 0.723\n",
      "Episode 2188 finished after 3001 timesteps\n",
      "Total reward: 15286.46717179739, Epsilon: 0.723\n",
      "Episode 2189 finished after 555 timesteps\n",
      "Total reward: 3982.98771962592, Epsilon: 0.723\n",
      "Episode 2190 finished after 2791 timesteps\n",
      "Total reward: 15749.922832882181, Epsilon: 0.723\n",
      "Episode 2191 finished after 453 timesteps\n",
      "Total reward: 3481.957664126135, Epsilon: 0.723\n",
      "Episode 2192 finished after 1315 timesteps\n",
      "Total reward: 9612.707518020223, Epsilon: 0.723\n",
      "Episode 2193 finished after 3001 timesteps\n",
      "Total reward: 15749.140381981722, Epsilon: 0.723\n",
      "Episode 2194 finished after 3001 timesteps\n",
      "Total reward: 15602.896191369566, Epsilon: 0.723\n",
      "Episode 2195 finished after 1994 timesteps\n",
      "Total reward: 11378.136488969636, Epsilon: 0.723\n",
      "Episode 2196 finished after 346 timesteps\n",
      "Total reward: 3507.3054981249197, Epsilon: 0.722\n",
      "Episode 2197 finished after 1893 timesteps\n",
      "Total reward: 9725.32921152664, Epsilon: 0.722\n",
      "Episode 2198 finished after 418 timesteps\n",
      "Total reward: 3478.8271326034696, Epsilon: 0.722\n",
      "Episode 2199 finished after 3001 timesteps\n",
      "Total reward: 16827.023405038766, Epsilon: 0.722\n",
      "Episode 2200 finished after 1703 timesteps\n",
      "Total reward: 10992.88163605944, Epsilon: 0.722\n",
      "Episode 2201 finished after 863 timesteps\n",
      "Total reward: 6021.400776435708, Epsilon: 0.722\n",
      "Episode 2202 finished after 508 timesteps\n",
      "Total reward: 3742.0347246935803, Epsilon: 0.722\n",
      "Episode 2203 finished after 3001 timesteps\n",
      "Total reward: 14853.857374845109, Epsilon: 0.722\n",
      "Episode 2204 finished after 3001 timesteps\n",
      "Total reward: 13420.673912260057, Epsilon: 0.722\n",
      "Episode 2205 finished after 222 timesteps\n",
      "Total reward: 2310.791241414436, Epsilon: 0.722\n",
      "Episode 2206 finished after 2756 timesteps\n",
      "Total reward: 15334.887631532667, Epsilon: 0.722\n",
      "Episode 2207 finished after 891 timesteps\n",
      "Total reward: 4501.908259723196, Epsilon: 0.722\n",
      "Episode 2208 finished after 3001 timesteps\n",
      "Total reward: 14427.13970305254, Epsilon: 0.722\n",
      "Episode 2209 finished after 1492 timesteps\n",
      "Total reward: 8510.862279755955, Epsilon: 0.722\n",
      "Episode 2210 finished after 866 timesteps\n",
      "Total reward: 5072.243389710722, Epsilon: 0.721\n",
      "Episode 2211 finished after 2326 timesteps\n",
      "Total reward: 12561.612736835545, Epsilon: 0.721\n",
      "Episode 2212 finished after 3001 timesteps\n",
      "Total reward: 14009.081426759001, Epsilon: 0.721\n",
      "Episode 2213 finished after 1384 timesteps\n",
      "Total reward: 7959.623222743561, Epsilon: 0.721\n",
      "Episode 2214 finished after 2791 timesteps\n",
      "Total reward: 14186.92657438258, Epsilon: 0.721\n",
      "Episode 2215 finished after 3001 timesteps\n",
      "Total reward: 15780.347972540907, Epsilon: 0.721\n",
      "Episode 2216 finished after 1014 timesteps\n",
      "Total reward: 7146.42669227911, Epsilon: 0.721\n",
      "Episode 2217 finished after 3001 timesteps\n",
      "Total reward: 13451.894813830007, Epsilon: 0.721\n",
      "Episode 2218 finished after 3001 timesteps\n",
      "Total reward: 14306.151539406705, Epsilon: 0.721\n",
      "Episode 2219 finished after 601 timesteps\n",
      "Total reward: 7541.96688702352, Epsilon: 0.721\n",
      "Episode 2220 finished after 3001 timesteps\n",
      "Total reward: 14158.348643984036, Epsilon: 0.721\n",
      "Episode 2221 finished after 919 timesteps\n",
      "Total reward: 6358.351911742483, Epsilon: 0.721\n",
      "Episode 2222 finished after 445 timesteps\n",
      "Total reward: 3931.6462206597453, Epsilon: 0.721\n",
      "Episode 2223 finished after 1255 timesteps\n",
      "Total reward: 6376.784485198672, Epsilon: 0.721\n",
      "Episode 2224 finished after 1366 timesteps\n",
      "Total reward: 6445.283495836961, Epsilon: 0.720\n",
      "Episode 2225 finished after 3001 timesteps\n",
      "Total reward: 13913.800242969575, Epsilon: 0.720\n",
      "Episode 2226 finished after 3001 timesteps\n",
      "Total reward: 16193.163757897932, Epsilon: 0.720\n",
      "Episode 2227 finished after 688 timesteps\n",
      "Total reward: 4492.806867160817, Epsilon: 0.720\n",
      "Episode 2228 finished after 2841 timesteps\n",
      "Total reward: 14875.535562126377, Epsilon: 0.720\n",
      "Episode 2229 finished after 957 timesteps\n",
      "Total reward: 5514.313584972224, Epsilon: 0.720\n",
      "Episode 2230 finished after 1221 timesteps\n",
      "Total reward: 7802.473726302439, Epsilon: 0.720\n",
      "Episode 2231 finished after 737 timesteps\n",
      "Total reward: 5295.032143647981, Epsilon: 0.720\n",
      "Episode 2232 finished after 1119 timesteps\n",
      "Total reward: 7531.752227989506, Epsilon: 0.720\n",
      "Episode 2233 finished after 2667 timesteps\n",
      "Total reward: 16136.002910558462, Epsilon: 0.720\n",
      "Episode 2234 finished after 3001 timesteps\n",
      "Total reward: 14345.837058322039, Epsilon: 0.720\n",
      "Episode 2235 finished after 814 timesteps\n",
      "Total reward: 4616.634064241788, Epsilon: 0.720\n",
      "Episode 2236 finished after 2943 timesteps\n",
      "Total reward: 16727.94701556521, Epsilon: 0.720\n",
      "Episode 2237 finished after 3001 timesteps\n",
      "Total reward: 13477.461098041475, Epsilon: 0.720\n",
      "Episode 2238 finished after 394 timesteps\n",
      "Total reward: 4013.7603962294243, Epsilon: 0.719\n",
      "Episode 2239 finished after 3001 timesteps\n",
      "Total reward: 15215.675859233335, Epsilon: 0.719\n",
      "Episode 2240 finished after 580 timesteps\n",
      "Total reward: 3772.951438028143, Epsilon: 0.719\n",
      "Episode 2241 finished after 263 timesteps\n",
      "Total reward: 2070.5292578053522, Epsilon: 0.719\n",
      "Episode 2242 finished after 3001 timesteps\n",
      "Total reward: 15980.461698055406, Epsilon: 0.719\n",
      "Episode 2243 finished after 1371 timesteps\n",
      "Total reward: 7496.986473518223, Epsilon: 0.719\n",
      "Episode 2244 finished after 1420 timesteps\n",
      "Total reward: 9598.822538257098, Epsilon: 0.719\n",
      "Episode 2245 finished after 331 timesteps\n",
      "Total reward: 3955.6065951884875, Epsilon: 0.719\n",
      "Episode 2246 finished after 1415 timesteps\n",
      "Total reward: 9002.175097609166, Epsilon: 0.719\n",
      "Episode 2247 finished after 1746 timesteps\n",
      "Total reward: 11016.310729372659, Epsilon: 0.719\n",
      "Episode 2248 finished after 3001 timesteps\n",
      "Total reward: 15811.109328562314, Epsilon: 0.719\n",
      "Episode 2249 finished after 811 timesteps\n",
      "Total reward: 6126.198434402227, Epsilon: 0.719\n",
      "Episode 2250 finished after 3001 timesteps\n",
      "Total reward: 14613.816644429819, Epsilon: 0.719\n",
      "Episode 2251 finished after 1029 timesteps\n",
      "Total reward: 5146.730694222007, Epsilon: 0.719\n",
      "Episode 2252 finished after 477 timesteps\n",
      "Total reward: 3226.375016201553, Epsilon: 0.718\n",
      "Episode 2253 finished after 869 timesteps\n",
      "Total reward: 5230.131812626606, Epsilon: 0.718\n",
      "Episode 2254 finished after 1191 timesteps\n",
      "Total reward: 9141.661668842953, Epsilon: 0.718\n",
      "Episode 2255 finished after 501 timesteps\n",
      "Total reward: 4424.595422649673, Epsilon: 0.718\n",
      "Episode 2256 finished after 3001 timesteps\n",
      "Total reward: 16570.91210973028, Epsilon: 0.718\n",
      "Episode 2257 finished after 319 timesteps\n",
      "Total reward: 2882.688032740821, Epsilon: 0.718\n",
      "Episode 2258 finished after 3001 timesteps\n",
      "Total reward: 15705.051757702144, Epsilon: 0.718\n",
      "Episode 2259 finished after 1082 timesteps\n",
      "Total reward: 6893.149996965448, Epsilon: 0.718\n",
      "Episode 2260 finished after 2218 timesteps\n",
      "Total reward: 15430.928320445744, Epsilon: 0.718\n",
      "Episode 2261 finished after 3001 timesteps\n",
      "Total reward: 13120.180673442013, Epsilon: 0.718\n",
      "Episode 2262 finished after 3001 timesteps\n",
      "Total reward: 15835.740270011616, Epsilon: 0.718\n",
      "Episode 2263 finished after 3001 timesteps\n",
      "Total reward: 14510.42458982936, Epsilon: 0.718\n",
      "Episode 2264 finished after 1378 timesteps\n",
      "Total reward: 8976.378020269474, Epsilon: 0.718\n",
      "Episode 2265 finished after 1283 timesteps\n",
      "Total reward: 6064.754715695415, Epsilon: 0.718\n",
      "Episode 2266 finished after 499 timesteps\n",
      "Total reward: 3516.708307511228, Epsilon: 0.717\n",
      "Episode 2267 finished after 1340 timesteps\n",
      "Total reward: 9753.185443776962, Epsilon: 0.717\n",
      "Episode 2268 finished after 1710 timesteps\n",
      "Total reward: 9839.240121739644, Epsilon: 0.717\n",
      "Episode 2269 finished after 681 timesteps\n",
      "Total reward: 5210.803297340475, Epsilon: 0.717\n",
      "Episode 2270 finished after 2132 timesteps\n",
      "Total reward: 11803.865212910601, Epsilon: 0.717\n",
      "Episode 2271 finished after 3001 timesteps\n",
      "Total reward: 13397.319292461925, Epsilon: 0.717\n",
      "Episode 2272 finished after 1928 timesteps\n",
      "Total reward: 12182.042661387108, Epsilon: 0.717\n",
      "Episode 2273 finished after 1967 timesteps\n",
      "Total reward: 11113.211206877342, Epsilon: 0.717\n",
      "Episode 2274 finished after 720 timesteps\n",
      "Total reward: 4682.2408554039985, Epsilon: 0.717\n",
      "Episode 2275 finished after 445 timesteps\n",
      "Total reward: 3918.736723664346, Epsilon: 0.717\n",
      "Episode 2276 finished after 2240 timesteps\n",
      "Total reward: 11371.939879957728, Epsilon: 0.717\n",
      "Episode 2277 finished after 3001 timesteps\n",
      "Total reward: 14838.069195830678, Epsilon: 0.717\n",
      "Episode 2278 finished after 1843 timesteps\n",
      "Total reward: 10258.605355828036, Epsilon: 0.717\n",
      "Episode 2279 finished after 746 timesteps\n",
      "Total reward: 4701.230377150731, Epsilon: 0.717\n",
      "Episode 2280 finished after 1815 timesteps\n",
      "Total reward: 9932.16006841176, Epsilon: 0.716\n",
      "Episode 2281 finished after 965 timesteps\n",
      "Total reward: 5676.092249800388, Epsilon: 0.716\n",
      "Episode 2282 finished after 891 timesteps\n",
      "Total reward: 7113.550762565729, Epsilon: 0.716\n",
      "Episode 2283 finished after 1441 timesteps\n",
      "Total reward: 10755.949466469225, Epsilon: 0.716\n",
      "Episode 2284 finished after 1293 timesteps\n",
      "Total reward: 9026.131042226032, Epsilon: 0.716\n",
      "Episode 2285 finished after 1702 timesteps\n",
      "Total reward: 13681.19942792728, Epsilon: 0.716\n",
      "Episode 2286 finished after 1448 timesteps\n",
      "Total reward: 7282.914698054196, Epsilon: 0.716\n",
      "Episode 2287 finished after 2018 timesteps\n",
      "Total reward: 10711.01328639644, Epsilon: 0.716\n",
      "Episode 2288 finished after 846 timesteps\n",
      "Total reward: 5765.754984908518, Epsilon: 0.716\n",
      "Episode 2289 finished after 3001 timesteps\n",
      "Total reward: 19196.69046536469, Epsilon: 0.716\n",
      "Episode 2290 finished after 1945 timesteps\n",
      "Total reward: 10212.014626133045, Epsilon: 0.716\n",
      "Episode 2291 finished after 3001 timesteps\n",
      "Total reward: 13954.161012175027, Epsilon: 0.716\n",
      "Episode 2292 finished after 1079 timesteps\n",
      "Total reward: 7915.827596532898, Epsilon: 0.716\n",
      "Episode 2293 finished after 1089 timesteps\n",
      "Total reward: 8556.567677288349, Epsilon: 0.716\n",
      "Episode 2294 finished after 1126 timesteps\n",
      "Total reward: 5841.731461323374, Epsilon: 0.715\n",
      "Episode 2295 finished after 1361 timesteps\n",
      "Total reward: 10192.750150402371, Epsilon: 0.715\n",
      "Episode 2296 finished after 607 timesteps\n",
      "Total reward: 4006.1142762770155, Epsilon: 0.715\n",
      "Episode 2297 finished after 1059 timesteps\n",
      "Total reward: 8242.04662841131, Epsilon: 0.715\n",
      "Episode 2298 finished after 1254 timesteps\n",
      "Total reward: 7783.743855458372, Epsilon: 0.715\n",
      "Episode 2299 finished after 975 timesteps\n",
      "Total reward: 7499.07512943487, Epsilon: 0.715\n",
      "Episode 2300 finished after 2128 timesteps\n",
      "Total reward: 11791.895111393971, Epsilon: 0.715\n",
      "Episode 2301 finished after 1763 timesteps\n",
      "Total reward: 10478.704549841754, Epsilon: 0.715\n",
      "Episode 2302 finished after 699 timesteps\n",
      "Total reward: 6330.525860763307, Epsilon: 0.715\n",
      "Episode 2303 finished after 371 timesteps\n",
      "Total reward: 2920.04352616352, Epsilon: 0.715\n",
      "Episode 2304 finished after 377 timesteps\n",
      "Total reward: 3142.335578758521, Epsilon: 0.715\n",
      "Episode 2305 finished after 815 timesteps\n",
      "Total reward: 5972.788181289044, Epsilon: 0.715\n",
      "Episode 2306 finished after 1663 timesteps\n",
      "Total reward: 9457.80586525305, Epsilon: 0.715\n",
      "Episode 2307 finished after 2281 timesteps\n",
      "Total reward: 11706.987180536484, Epsilon: 0.715\n",
      "Episode 2308 finished after 716 timesteps\n",
      "Total reward: 5354.747114687185, Epsilon: 0.714\n",
      "Episode 2309 finished after 2261 timesteps\n",
      "Total reward: 12564.886131553509, Epsilon: 0.714\n",
      "Episode 2310 finished after 3001 timesteps\n",
      "Total reward: 13718.200904006802, Epsilon: 0.714\n",
      "Episode 2311 finished after 3001 timesteps\n",
      "Total reward: 13865.301479108799, Epsilon: 0.714\n",
      "Episode 2312 finished after 1912 timesteps\n",
      "Total reward: 13490.340858151658, Epsilon: 0.714\n",
      "Episode 2313 finished after 496 timesteps\n",
      "Total reward: 4181.196907424317, Epsilon: 0.714\n",
      "Episode 2314 finished after 1480 timesteps\n",
      "Total reward: 7515.776289165343, Epsilon: 0.714\n",
      "Episode 2315 finished after 3001 timesteps\n",
      "Total reward: 18274.795130128, Epsilon: 0.714\n",
      "Episode 2316 finished after 892 timesteps\n",
      "Total reward: 6719.8286075638, Epsilon: 0.714\n",
      "Episode 2317 finished after 1481 timesteps\n",
      "Total reward: 9382.49947143567, Epsilon: 0.714\n",
      "Episode 2318 finished after 3001 timesteps\n",
      "Total reward: 13376.72591138513, Epsilon: 0.714\n",
      "Episode 2319 finished after 686 timesteps\n",
      "Total reward: 4023.838694388555, Epsilon: 0.714\n",
      "Episode 2320 finished after 1271 timesteps\n",
      "Total reward: 8043.600687455616, Epsilon: 0.714\n",
      "Episode 2321 finished after 3001 timesteps\n",
      "Total reward: 18458.23652944659, Epsilon: 0.714\n",
      "Episode 2322 finished after 3001 timesteps\n",
      "Total reward: 16304.001161505867, Epsilon: 0.713\n",
      "Episode 2323 finished after 1139 timesteps\n",
      "Total reward: 6891.134281275504, Epsilon: 0.713\n",
      "Episode 2324 finished after 3001 timesteps\n",
      "Total reward: 13647.498325047884, Epsilon: 0.713\n",
      "Episode 2325 finished after 3001 timesteps\n",
      "Total reward: 12520.27430861925, Epsilon: 0.713\n",
      "Episode 2326 finished after 1225 timesteps\n",
      "Total reward: 6300.877834525364, Epsilon: 0.713\n",
      "Episode 2327 finished after 2428 timesteps\n",
      "Total reward: 13041.518962609607, Epsilon: 0.713\n",
      "Episode 2328 finished after 3001 timesteps\n",
      "Total reward: 15867.93825284947, Epsilon: 0.713\n",
      "Episode 2329 finished after 1817 timesteps\n",
      "Total reward: 10678.059975662829, Epsilon: 0.713\n",
      "Episode 2330 finished after 3001 timesteps\n",
      "Total reward: 13499.568103910871, Epsilon: 0.713\n",
      "Episode 2331 finished after 3001 timesteps\n",
      "Total reward: 15492.626339474624, Epsilon: 0.713\n",
      "Episode 2332 finished after 2823 timesteps\n",
      "Total reward: 14370.34310665172, Epsilon: 0.713\n",
      "Episode 2333 finished after 3001 timesteps\n",
      "Total reward: 13838.850779735509, Epsilon: 0.713\n",
      "Episode 2334 finished after 3001 timesteps\n",
      "Total reward: 20334.701555713702, Epsilon: 0.713\n",
      "Episode 2335 finished after 2333 timesteps\n",
      "Total reward: 14321.827966281082, Epsilon: 0.713\n",
      "Episode 2336 finished after 795 timesteps\n",
      "Total reward: 5438.759638007799, Epsilon: 0.712\n",
      "Episode 2337 finished after 1067 timesteps\n",
      "Total reward: 6394.371740277343, Epsilon: 0.712\n",
      "Episode 2338 finished after 3001 timesteps\n",
      "Total reward: 15973.393346494106, Epsilon: 0.712\n",
      "Episode 2339 finished after 966 timesteps\n",
      "Total reward: 7624.514535621588, Epsilon: 0.712\n",
      "Episode 2340 finished after 792 timesteps\n",
      "Total reward: 5059.384677789681, Epsilon: 0.712\n",
      "Episode 2341 finished after 663 timesteps\n",
      "Total reward: 4589.814648126077, Epsilon: 0.712\n",
      "Episode 2342 finished after 3001 timesteps\n",
      "Total reward: 15690.66815815507, Epsilon: 0.712\n",
      "Episode 2343 finished after 3001 timesteps\n",
      "Total reward: 13789.665571009176, Epsilon: 0.712\n",
      "Episode 2344 finished after 3001 timesteps\n",
      "Total reward: 13506.793280700245, Epsilon: 0.712\n",
      "Episode 2345 finished after 3001 timesteps\n",
      "Total reward: 14585.541675565024, Epsilon: 0.712\n",
      "Episode 2346 finished after 1389 timesteps\n",
      "Total reward: 7452.157376891876, Epsilon: 0.712\n",
      "Episode 2347 finished after 3001 timesteps\n",
      "Total reward: 13941.87529281124, Epsilon: 0.712\n",
      "Episode 2348 finished after 743 timesteps\n",
      "Total reward: 4749.152904595996, Epsilon: 0.712\n",
      "Episode 2349 finished after 947 timesteps\n",
      "Total reward: 6980.017212003795, Epsilon: 0.712\n",
      "Episode 2350 finished after 1038 timesteps\n",
      "Total reward: 6034.0828356491165, Epsilon: 0.711\n",
      "Episode 2351 finished after 779 timesteps\n",
      "Total reward: 4529.432854482239, Epsilon: 0.711\n",
      "Episode 2352 finished after 546 timesteps\n",
      "Total reward: 4451.115714186246, Epsilon: 0.711\n",
      "Episode 2353 finished after 931 timesteps\n",
      "Total reward: 4948.019947570155, Epsilon: 0.711\n",
      "Episode 2354 finished after 873 timesteps\n",
      "Total reward: 4801.265775550095, Epsilon: 0.711\n",
      "Episode 2355 finished after 1696 timesteps\n",
      "Total reward: 9247.252246372995, Epsilon: 0.711\n",
      "Episode 2356 finished after 644 timesteps\n",
      "Total reward: 3949.8628149417646, Epsilon: 0.711\n",
      "Episode 2357 finished after 1589 timesteps\n",
      "Total reward: 8205.11833209463, Epsilon: 0.711\n",
      "Episode 2358 finished after 3001 timesteps\n",
      "Total reward: 14220.971139699164, Epsilon: 0.711\n",
      "Episode 2359 finished after 931 timesteps\n",
      "Total reward: 6051.016486152091, Epsilon: 0.711\n",
      "Episode 2360 finished after 3001 timesteps\n",
      "Total reward: 13714.448018172921, Epsilon: 0.711\n",
      "Episode 2361 finished after 1454 timesteps\n",
      "Total reward: 11269.691138066433, Epsilon: 0.711\n",
      "Episode 2362 finished after 3001 timesteps\n",
      "Total reward: 17246.399127904027, Epsilon: 0.711\n",
      "Episode 2363 finished after 3001 timesteps\n",
      "Total reward: 15357.796722442557, Epsilon: 0.711\n",
      "Episode 2364 finished after 3001 timesteps\n",
      "Total reward: 15840.423723633578, Epsilon: 0.710\n",
      "Episode 2365 finished after 838 timesteps\n",
      "Total reward: 4559.572359735295, Epsilon: 0.710\n",
      "Episode 2366 finished after 1338 timesteps\n",
      "Total reward: 8240.779715785864, Epsilon: 0.710\n",
      "Episode 2367 finished after 3001 timesteps\n",
      "Total reward: 14172.582182648392, Epsilon: 0.710\n",
      "Episode 2368 finished after 295 timesteps\n",
      "Total reward: 2524.8533720453997, Epsilon: 0.710\n",
      "Episode 2369 finished after 2303 timesteps\n",
      "Total reward: 13084.46754268564, Epsilon: 0.710\n",
      "Episode 2370 finished after 1716 timesteps\n",
      "Total reward: 10443.241712847104, Epsilon: 0.710\n",
      "Episode 2371 finished after 2286 timesteps\n",
      "Total reward: 10864.375478549984, Epsilon: 0.710\n",
      "Episode 2372 finished after 803 timesteps\n",
      "Total reward: 4564.860177454613, Epsilon: 0.710\n",
      "Episode 2373 finished after 811 timesteps\n",
      "Total reward: 6030.760136704893, Epsilon: 0.710\n",
      "Episode 2374 finished after 3001 timesteps\n",
      "Total reward: 15840.331389787352, Epsilon: 0.710\n",
      "Episode 2375 finished after 1635 timesteps\n",
      "Total reward: 13899.302567712497, Epsilon: 0.710\n",
      "Episode 2376 finished after 1573 timesteps\n",
      "Total reward: 9518.951647559163, Epsilon: 0.710\n",
      "Episode 2377 finished after 3001 timesteps\n",
      "Total reward: 12591.851504787932, Epsilon: 0.710\n",
      "Episode 2378 finished after 2296 timesteps\n",
      "Total reward: 10839.629045830065, Epsilon: 0.709\n",
      "Episode 2379 finished after 2900 timesteps\n",
      "Total reward: 18412.70077555618, Epsilon: 0.709\n",
      "Episode 2380 finished after 3001 timesteps\n",
      "Total reward: 15745.99823077835, Epsilon: 0.709\n",
      "Episode 2381 finished after 3001 timesteps\n",
      "Total reward: 12690.639135677762, Epsilon: 0.709\n",
      "Episode 2382 finished after 3001 timesteps\n",
      "Total reward: 17275.18059355011, Epsilon: 0.709\n",
      "Episode 2383 finished after 984 timesteps\n",
      "Total reward: 7259.533897284196, Epsilon: 0.709\n",
      "Episode 2384 finished after 1777 timesteps\n",
      "Total reward: 9806.55010748971, Epsilon: 0.709\n",
      "Episode 2385 finished after 3001 timesteps\n",
      "Total reward: 13459.707441598584, Epsilon: 0.709\n",
      "Episode 2386 finished after 1018 timesteps\n",
      "Total reward: 6573.504085852148, Epsilon: 0.709\n",
      "Episode 2387 finished after 1559 timesteps\n",
      "Total reward: 8791.810965368846, Epsilon: 0.709\n",
      "Episode 2388 finished after 3001 timesteps\n",
      "Total reward: 13070.188714034348, Epsilon: 0.709\n",
      "Episode 2389 finished after 922 timesteps\n",
      "Total reward: 5295.490038169628, Epsilon: 0.709\n",
      "Episode 2390 finished after 3001 timesteps\n",
      "Total reward: 15390.911616146099, Epsilon: 0.709\n",
      "Episode 2391 finished after 1875 timesteps\n",
      "Total reward: 11384.447215853776, Epsilon: 0.709\n",
      "Episode 2392 finished after 800 timesteps\n",
      "Total reward: 5212.7078131835215, Epsilon: 0.708\n",
      "Episode 2393 finished after 2814 timesteps\n",
      "Total reward: 13860.717808689258, Epsilon: 0.708\n",
      "Episode 2394 finished after 904 timesteps\n",
      "Total reward: 5331.3650406836105, Epsilon: 0.708\n",
      "Episode 2395 finished after 1313 timesteps\n",
      "Total reward: 7703.430086395167, Epsilon: 0.708\n",
      "Episode 2396 finished after 666 timesteps\n",
      "Total reward: 4368.616417345822, Epsilon: 0.708\n",
      "Episode 2397 finished after 747 timesteps\n",
      "Total reward: 6767.04638904705, Epsilon: 0.708\n",
      "Episode 2398 finished after 2251 timesteps\n",
      "Total reward: 12080.180461952405, Epsilon: 0.708\n",
      "Episode 2399 finished after 1866 timesteps\n",
      "Total reward: 10515.280786470938, Epsilon: 0.708\n",
      "Episode 2400 finished after 3001 timesteps\n",
      "Total reward: 13145.723012235052, Epsilon: 0.708\n",
      "Episode 2401 finished after 1435 timesteps\n",
      "Total reward: 9692.349210007442, Epsilon: 0.708\n",
      "Episode 2402 finished after 379 timesteps\n",
      "Total reward: 2675.5531628502117, Epsilon: 0.708\n",
      "Episode 2403 finished after 2802 timesteps\n",
      "Total reward: 14000.929152434559, Epsilon: 0.708\n",
      "Episode 2404 finished after 3001 timesteps\n",
      "Total reward: 14493.601972547047, Epsilon: 0.708\n",
      "Episode 2405 finished after 914 timesteps\n",
      "Total reward: 5332.174834973465, Epsilon: 0.708\n",
      "Episode 2406 finished after 476 timesteps\n",
      "Total reward: 4941.101422551474, Epsilon: 0.707\n",
      "Episode 2407 finished after 2873 timesteps\n",
      "Total reward: 13642.322773062695, Epsilon: 0.707\n",
      "Episode 2408 finished after 2058 timesteps\n",
      "Total reward: 10445.240026964133, Epsilon: 0.707\n",
      "Episode 2409 finished after 1656 timesteps\n",
      "Total reward: 9706.379832185774, Epsilon: 0.707\n",
      "Episode 2410 finished after 3001 timesteps\n",
      "Total reward: 13543.75960657266, Epsilon: 0.707\n",
      "Episode 2411 finished after 1862 timesteps\n",
      "Total reward: 11533.506086489218, Epsilon: 0.707\n",
      "Episode 2412 finished after 1392 timesteps\n",
      "Total reward: 8319.61513279495, Epsilon: 0.707\n",
      "Episode 2413 finished after 2809 timesteps\n",
      "Total reward: 18152.40002034868, Epsilon: 0.707\n",
      "Episode 2414 finished after 1711 timesteps\n",
      "Total reward: 10288.68421848209, Epsilon: 0.707\n",
      "Episode 2415 finished after 1786 timesteps\n",
      "Total reward: 12686.83928253757, Epsilon: 0.707\n",
      "Episode 2416 finished after 1645 timesteps\n",
      "Total reward: 9670.042819337757, Epsilon: 0.707\n",
      "Episode 2417 finished after 370 timesteps\n",
      "Total reward: 3240.837224490777, Epsilon: 0.707\n",
      "Episode 2418 finished after 2901 timesteps\n",
      "Total reward: 14792.596532923395, Epsilon: 0.707\n",
      "Episode 2419 finished after 3001 timesteps\n",
      "Total reward: 13150.44759199302, Epsilon: 0.707\n",
      "Episode 2420 finished after 1287 timesteps\n",
      "Total reward: 6616.179572201376, Epsilon: 0.706\n",
      "Episode 2421 finished after 321 timesteps\n",
      "Total reward: 3315.22123436927, Epsilon: 0.706\n",
      "Episode 2422 finished after 3001 timesteps\n",
      "Total reward: 15181.395526470496, Epsilon: 0.706\n",
      "Episode 2423 finished after 592 timesteps\n",
      "Total reward: 3470.6023684459774, Epsilon: 0.706\n",
      "Episode 2424 finished after 3001 timesteps\n",
      "Total reward: 13746.922440402013, Epsilon: 0.706\n",
      "Episode 2425 finished after 957 timesteps\n",
      "Total reward: 4657.1853091026915, Epsilon: 0.706\n",
      "Episode 2426 finished after 3001 timesteps\n",
      "Total reward: 13818.542453161625, Epsilon: 0.706\n",
      "Episode 2427 finished after 3001 timesteps\n",
      "Total reward: 16201.738174846649, Epsilon: 0.706\n",
      "Episode 2428 finished after 1678 timesteps\n",
      "Total reward: 9954.268558874259, Epsilon: 0.706\n",
      "Episode 2429 finished after 929 timesteps\n",
      "Total reward: 6424.526760172165, Epsilon: 0.706\n",
      "Episode 2430 finished after 1137 timesteps\n",
      "Total reward: 8223.566067612308, Epsilon: 0.706\n",
      "Episode 2431 finished after 3001 timesteps\n",
      "Total reward: 14678.621220701087, Epsilon: 0.706\n",
      "Episode 2432 finished after 3001 timesteps\n",
      "Total reward: 14571.302350707425, Epsilon: 0.706\n",
      "Episode 2433 finished after 3001 timesteps\n",
      "Total reward: 12708.35327600997, Epsilon: 0.706\n",
      "Episode 2434 finished after 1020 timesteps\n",
      "Total reward: 5853.771690755553, Epsilon: 0.705\n",
      "Episode 2435 finished after 1062 timesteps\n",
      "Total reward: 6903.368239489654, Epsilon: 0.705\n",
      "Episode 2436 finished after 1853 timesteps\n",
      "Total reward: 11003.253734333292, Epsilon: 0.705\n",
      "Episode 2437 finished after 1659 timesteps\n",
      "Total reward: 9904.165108938378, Epsilon: 0.705\n",
      "Episode 2438 finished after 593 timesteps\n",
      "Total reward: 3630.9122039698623, Epsilon: 0.705\n",
      "Episode 2439 finished after 1143 timesteps\n",
      "Total reward: 7296.6484516523415, Epsilon: 0.705\n",
      "Episode 2440 finished after 996 timesteps\n",
      "Total reward: 5256.583467258952, Epsilon: 0.705\n",
      "Episode 2441 finished after 3001 timesteps\n",
      "Total reward: 17341.978918191086, Epsilon: 0.705\n",
      "Episode 2442 finished after 237 timesteps\n",
      "Total reward: 2313.7707925032746, Epsilon: 0.705\n",
      "Episode 2443 finished after 1697 timesteps\n",
      "Total reward: 9873.833947944413, Epsilon: 0.705\n",
      "Episode 2444 finished after 1946 timesteps\n",
      "Total reward: 12380.888625212348, Epsilon: 0.705\n",
      "Episode 2445 finished after 3001 timesteps\n",
      "Total reward: 13817.847945176858, Epsilon: 0.705\n",
      "Episode 2446 finished after 577 timesteps\n",
      "Total reward: 4495.787875583719, Epsilon: 0.705\n",
      "Episode 2447 finished after 1895 timesteps\n",
      "Total reward: 9435.300773725206, Epsilon: 0.705\n",
      "Episode 2448 finished after 3001 timesteps\n",
      "Total reward: 14361.423213539942, Epsilon: 0.704\n",
      "Episode 2449 finished after 1924 timesteps\n",
      "Total reward: 11346.092022761475, Epsilon: 0.704\n",
      "Episode 2450 finished after 932 timesteps\n",
      "Total reward: 6777.297765771137, Epsilon: 0.704\n",
      "Episode 2451 finished after 1895 timesteps\n",
      "Total reward: 10353.21713052834, Epsilon: 0.704\n",
      "Episode 2452 finished after 1187 timesteps\n",
      "Total reward: 6407.605585715644, Epsilon: 0.704\n",
      "Episode 2453 finished after 1231 timesteps\n",
      "Total reward: 9396.149894663087, Epsilon: 0.704\n",
      "Episode 2454 finished after 378 timesteps\n",
      "Total reward: 2960.362458782732, Epsilon: 0.704\n",
      "Episode 2455 finished after 192 timesteps\n",
      "Total reward: 1949.7339028755353, Epsilon: 0.704\n",
      "Episode 2456 finished after 1726 timesteps\n",
      "Total reward: 10563.84877884121, Epsilon: 0.704\n",
      "Episode 2457 finished after 3001 timesteps\n",
      "Total reward: 13275.037571975325, Epsilon: 0.704\n",
      "Episode 2458 finished after 2423 timesteps\n",
      "Total reward: 11977.98348591983, Epsilon: 0.704\n",
      "Episode 2459 finished after 2402 timesteps\n",
      "Total reward: 12739.187326221589, Epsilon: 0.704\n",
      "Episode 2460 finished after 3001 timesteps\n",
      "Total reward: 18882.064545899608, Epsilon: 0.704\n",
      "Episode 2461 finished after 645 timesteps\n",
      "Total reward: 4778.994494044038, Epsilon: 0.704\n",
      "Episode 2462 finished after 3001 timesteps\n",
      "Total reward: 15326.882963370535, Epsilon: 0.704\n",
      "Episode 2463 finished after 3001 timesteps\n",
      "Total reward: 12740.950487757611, Epsilon: 0.703\n",
      "Episode 2464 finished after 819 timesteps\n",
      "Total reward: 5969.563845857128, Epsilon: 0.703\n",
      "Episode 2465 finished after 910 timesteps\n",
      "Total reward: 5064.572187072006, Epsilon: 0.703\n",
      "Episode 2466 finished after 3001 timesteps\n",
      "Total reward: 18793.85567159566, Epsilon: 0.703\n",
      "Episode 2467 finished after 2436 timesteps\n",
      "Total reward: 12601.015153531569, Epsilon: 0.703\n",
      "Episode 2468 finished after 3001 timesteps\n",
      "Total reward: 13171.744984816776, Epsilon: 0.703\n",
      "Episode 2469 finished after 2166 timesteps\n",
      "Total reward: 11007.218828289071, Epsilon: 0.703\n",
      "Episode 2470 finished after 661 timesteps\n",
      "Total reward: 3655.649956302927, Epsilon: 0.703\n",
      "Episode 2471 finished after 1753 timesteps\n",
      "Total reward: 9880.72217355093, Epsilon: 0.703\n",
      "Episode 2472 finished after 3001 timesteps\n",
      "Total reward: 13963.2192643272, Epsilon: 0.703\n",
      "Episode 2473 finished after 233 timesteps\n",
      "Total reward: 2643.351246848962, Epsilon: 0.703\n",
      "Episode 2474 finished after 3001 timesteps\n",
      "Total reward: 16438.383525367706, Epsilon: 0.703\n",
      "Episode 2475 finished after 1109 timesteps\n",
      "Total reward: 8738.589734686044, Epsilon: 0.703\n",
      "Episode 2476 finished after 3001 timesteps\n",
      "Total reward: 13907.382608743177, Epsilon: 0.703\n",
      "Episode 2477 finished after 186 timesteps\n",
      "Total reward: 1996.2510553377012, Epsilon: 0.702\n",
      "Episode 2478 finished after 940 timesteps\n",
      "Total reward: 5576.351957694615, Epsilon: 0.702\n",
      "Episode 2479 finished after 1606 timesteps\n",
      "Total reward: 9460.324824140436, Epsilon: 0.702\n",
      "Episode 2480 finished after 644 timesteps\n",
      "Total reward: 5940.373963032462, Epsilon: 0.702\n",
      "Episode 2481 finished after 3001 timesteps\n",
      "Total reward: 17554.380517026, Epsilon: 0.702\n",
      "Episode 2482 finished after 1401 timesteps\n",
      "Total reward: 7816.734638761047, Epsilon: 0.702\n",
      "Episode 2483 finished after 3001 timesteps\n",
      "Total reward: 15793.137996051308, Epsilon: 0.702\n",
      "Episode 2484 finished after 1470 timesteps\n",
      "Total reward: 8078.345512624674, Epsilon: 0.702\n",
      "Episode 2485 finished after 917 timesteps\n",
      "Total reward: 5414.007446791868, Epsilon: 0.702\n",
      "Episode 2486 finished after 1299 timesteps\n",
      "Total reward: 7641.305631916774, Epsilon: 0.702\n",
      "Episode 2487 finished after 1022 timesteps\n",
      "Total reward: 6291.900300196173, Epsilon: 0.702\n",
      "Episode 2488 finished after 3001 timesteps\n",
      "Total reward: 12824.368490019295, Epsilon: 0.702\n",
      "Episode 2489 finished after 536 timesteps\n",
      "Total reward: 3672.783541604434, Epsilon: 0.702\n",
      "Episode 2490 finished after 2679 timesteps\n",
      "Total reward: 13290.899718285873, Epsilon: 0.702\n",
      "Episode 2491 finished after 1919 timesteps\n",
      "Total reward: 14468.777169020912, Epsilon: 0.701\n",
      "Episode 2492 finished after 1873 timesteps\n",
      "Total reward: 10212.144361866822, Epsilon: 0.701\n",
      "Episode 2493 finished after 3001 timesteps\n",
      "Total reward: 15500.546769138387, Epsilon: 0.701\n",
      "Episode 2494 finished after 3001 timesteps\n",
      "Total reward: 13900.985670514601, Epsilon: 0.701\n",
      "Episode 2495 finished after 1317 timesteps\n",
      "Total reward: 7041.916611039086, Epsilon: 0.701\n",
      "Episode 2496 finished after 3001 timesteps\n",
      "Total reward: 13676.655641769981, Epsilon: 0.701\n",
      "Episode 2497 finished after 3001 timesteps\n",
      "Total reward: 16577.033871530315, Epsilon: 0.701\n",
      "Episode 2498 finished after 1112 timesteps\n",
      "Total reward: 7892.923720616302, Epsilon: 0.701\n",
      "Episode 2499 finished after 932 timesteps\n",
      "Total reward: 6767.860837228053, Epsilon: 0.701\n",
      "Episode 2500 finished after 1762 timesteps\n",
      "Total reward: 9921.319509426357, Epsilon: 0.701\n",
      "Episode 2501 finished after 1746 timesteps\n",
      "Total reward: 11099.051644856667, Epsilon: 0.701\n",
      "Episode 2502 finished after 1259 timesteps\n",
      "Total reward: 6347.018673708895, Epsilon: 0.701\n",
      "Episode 2503 finished after 2159 timesteps\n",
      "Total reward: 10908.111307339052, Epsilon: 0.701\n",
      "Episode 2504 finished after 2761 timesteps\n",
      "Total reward: 14745.977415350437, Epsilon: 0.701\n",
      "Episode 2505 finished after 432 timesteps\n",
      "Total reward: 5190.323640851538, Epsilon: 0.700\n",
      "Episode 2506 finished after 1262 timesteps\n",
      "Total reward: 8050.862501695572, Epsilon: 0.700\n",
      "Episode 2507 finished after 3001 timesteps\n",
      "Total reward: 15079.498863486124, Epsilon: 0.700\n",
      "Episode 2508 finished after 807 timesteps\n",
      "Total reward: 4295.886248674688, Epsilon: 0.700\n",
      "Episode 2509 finished after 3001 timesteps\n",
      "Total reward: 15883.001448554583, Epsilon: 0.700\n",
      "Episode 2510 finished after 1963 timesteps\n",
      "Total reward: 9897.277883609482, Epsilon: 0.700\n",
      "Episode 2511 finished after 3001 timesteps\n",
      "Total reward: 15490.646276557101, Epsilon: 0.700\n",
      "Episode 2512 finished after 851 timesteps\n",
      "Total reward: 4587.829597628877, Epsilon: 0.700\n",
      "Episode 2513 finished after 1122 timesteps\n",
      "Total reward: 5380.71781104451, Epsilon: 0.700\n",
      "Episode 2514 finished after 808 timesteps\n",
      "Total reward: 5563.347315829407, Epsilon: 0.700\n",
      "Episode 2515 finished after 453 timesteps\n",
      "Total reward: 3054.568496280004, Epsilon: 0.700\n",
      "Episode 2516 finished after 3001 timesteps\n",
      "Total reward: 17478.653893784987, Epsilon: 0.700\n",
      "Episode 2517 finished after 475 timesteps\n",
      "Total reward: 4424.091199617197, Epsilon: 0.700\n",
      "Episode 2518 finished after 1187 timesteps\n",
      "Total reward: 6351.566699613081, Epsilon: 0.700\n",
      "Episode 2519 finished after 2373 timesteps\n",
      "Total reward: 10477.533795026306, Epsilon: 0.700\n",
      "Episode 2520 finished after 224 timesteps\n",
      "Total reward: 2272.6633730865647, Epsilon: 0.699\n",
      "Episode 2521 finished after 2431 timesteps\n",
      "Total reward: 13904.087157546117, Epsilon: 0.699\n",
      "Episode 2522 finished after 1029 timesteps\n",
      "Total reward: 6401.987322347076, Epsilon: 0.699\n",
      "Episode 2523 finished after 3001 timesteps\n",
      "Total reward: 13364.09687170491, Epsilon: 0.699\n",
      "Episode 2524 finished after 1387 timesteps\n",
      "Total reward: 8211.81317294692, Epsilon: 0.699\n",
      "Episode 2525 finished after 3001 timesteps\n",
      "Total reward: 14305.971988316447, Epsilon: 0.699\n",
      "Episode 2526 finished after 3001 timesteps\n",
      "Total reward: 14664.931763034925, Epsilon: 0.699\n",
      "Episode 2527 finished after 1088 timesteps\n",
      "Total reward: 7131.007150518393, Epsilon: 0.699\n",
      "Episode 2528 finished after 3001 timesteps\n",
      "Total reward: 15075.963288737761, Epsilon: 0.699\n",
      "Episode 2529 finished after 1867 timesteps\n",
      "Total reward: 10251.182468577255, Epsilon: 0.699\n",
      "Episode 2530 finished after 3001 timesteps\n",
      "Total reward: 13067.031128546438, Epsilon: 0.699\n",
      "Episode 2531 finished after 3001 timesteps\n",
      "Total reward: 18626.69702974186, Epsilon: 0.699\n",
      "Episode 2532 finished after 2361 timesteps\n",
      "Total reward: 14205.85976075996, Epsilon: 0.699\n",
      "Episode 2533 finished after 3001 timesteps\n",
      "Total reward: 17873.795669221854, Epsilon: 0.699\n",
      "Episode 2534 finished after 3001 timesteps\n",
      "Total reward: 17060.24256889439, Epsilon: 0.698\n",
      "Episode 2535 finished after 3001 timesteps\n",
      "Total reward: 18307.064752803177, Epsilon: 0.698\n",
      "Episode 2536 finished after 3001 timesteps\n",
      "Total reward: 14803.483323562465, Epsilon: 0.698\n",
      "Episode 2537 finished after 3001 timesteps\n",
      "Total reward: 13449.92795266462, Epsilon: 0.698\n",
      "Episode 2538 finished after 2677 timesteps\n",
      "Total reward: 18577.37989730947, Epsilon: 0.698\n",
      "Episode 2539 finished after 3001 timesteps\n",
      "Total reward: 14373.638562909746, Epsilon: 0.698\n",
      "Episode 2540 finished after 877 timesteps\n",
      "Total reward: 5320.86926566182, Epsilon: 0.698\n",
      "Episode 2541 finished after 596 timesteps\n",
      "Total reward: 4595.841395004514, Epsilon: 0.698\n",
      "Episode 2542 finished after 3001 timesteps\n",
      "Total reward: 11905.908588787901, Epsilon: 0.698\n",
      "Episode 2543 finished after 3001 timesteps\n",
      "Total reward: 18044.541699033667, Epsilon: 0.698\n",
      "Episode 2544 finished after 3001 timesteps\n",
      "Total reward: 14487.591550966064, Epsilon: 0.698\n",
      "Episode 2545 finished after 739 timesteps\n",
      "Total reward: 4484.683934254611, Epsilon: 0.698\n",
      "Episode 2546 finished after 1891 timesteps\n",
      "Total reward: 11794.324830145708, Epsilon: 0.698\n",
      "Episode 2547 finished after 645 timesteps\n",
      "Total reward: 4200.518228003202, Epsilon: 0.698\n",
      "Episode 2548 finished after 773 timesteps\n",
      "Total reward: 4416.085666657315, Epsilon: 0.697\n",
      "Episode 2549 finished after 2037 timesteps\n",
      "Total reward: 11226.427698253105, Epsilon: 0.697\n",
      "Episode 2550 finished after 2893 timesteps\n",
      "Total reward: 15414.15404077408, Epsilon: 0.697\n",
      "Episode 2551 finished after 638 timesteps\n",
      "Total reward: 3755.1725384028514, Epsilon: 0.697\n",
      "Episode 2552 finished after 3001 timesteps\n",
      "Total reward: 14341.043540538594, Epsilon: 0.697\n",
      "Episode 2553 finished after 3001 timesteps\n",
      "Total reward: 14584.170414668166, Epsilon: 0.697\n",
      "Episode 2554 finished after 996 timesteps\n",
      "Total reward: 6700.230316180709, Epsilon: 0.697\n",
      "Episode 2555 finished after 1412 timesteps\n",
      "Total reward: 8564.54744999185, Epsilon: 0.697\n",
      "Episode 2556 finished after 576 timesteps\n",
      "Total reward: 3878.353938938915, Epsilon: 0.697\n",
      "Episode 2557 finished after 1507 timesteps\n",
      "Total reward: 8699.167435366488, Epsilon: 0.697\n",
      "Episode 2558 finished after 3001 timesteps\n",
      "Total reward: 18624.587302324788, Epsilon: 0.697\n",
      "Episode 2559 finished after 1793 timesteps\n",
      "Total reward: 10475.372317681828, Epsilon: 0.697\n",
      "Episode 2560 finished after 1379 timesteps\n",
      "Total reward: 9059.49822732161, Epsilon: 0.697\n",
      "Episode 2561 finished after 2137 timesteps\n",
      "Total reward: 10686.676534221258, Epsilon: 0.697\n",
      "Episode 2562 finished after 883 timesteps\n",
      "Total reward: 5218.625204557687, Epsilon: 0.697\n",
      "Episode 2563 finished after 1697 timesteps\n",
      "Total reward: 9961.747339292095, Epsilon: 0.696\n",
      "Episode 2564 finished after 344 timesteps\n",
      "Total reward: 3146.0984527124037, Epsilon: 0.696\n",
      "Episode 2565 finished after 1381 timesteps\n",
      "Total reward: 10955.7247470866, Epsilon: 0.696\n",
      "Episode 2566 finished after 437 timesteps\n",
      "Total reward: 3661.7756941901794, Epsilon: 0.696\n",
      "Episode 2567 finished after 3001 timesteps\n",
      "Total reward: 16196.628178584953, Epsilon: 0.696\n",
      "Episode 2568 finished after 2010 timesteps\n",
      "Total reward: 12388.327159335624, Epsilon: 0.696\n",
      "Episode 2569 finished after 597 timesteps\n",
      "Total reward: 5639.801265138727, Epsilon: 0.696\n",
      "Episode 2570 finished after 3001 timesteps\n",
      "Total reward: 14290.067108464016, Epsilon: 0.696\n",
      "Episode 2571 finished after 345 timesteps\n",
      "Total reward: 2672.9030214263294, Epsilon: 0.696\n",
      "Episode 2572 finished after 1755 timesteps\n",
      "Total reward: 9507.099480748775, Epsilon: 0.696\n",
      "Episode 2573 finished after 3001 timesteps\n",
      "Total reward: 17797.883333762635, Epsilon: 0.696\n",
      "Episode 2574 finished after 1820 timesteps\n",
      "Total reward: 9407.490415025335, Epsilon: 0.696\n",
      "Episode 2575 finished after 275 timesteps\n",
      "Total reward: 2082.4096534052596, Epsilon: 0.696\n",
      "Episode 2576 finished after 2437 timesteps\n",
      "Total reward: 13065.069515578221, Epsilon: 0.696\n",
      "Episode 2577 finished after 3001 timesteps\n",
      "Total reward: 14400.016126907103, Epsilon: 0.695\n",
      "Episode 2578 finished after 1216 timesteps\n",
      "Total reward: 7603.502003574774, Epsilon: 0.695\n",
      "Episode 2579 finished after 3001 timesteps\n",
      "Total reward: 11752.36822474583, Epsilon: 0.695\n",
      "Episode 2580 finished after 543 timesteps\n",
      "Total reward: 4320.967932377673, Epsilon: 0.695\n",
      "Episode 2581 finished after 2453 timesteps\n",
      "Total reward: 14592.889563997778, Epsilon: 0.695\n",
      "Episode 2582 finished after 1148 timesteps\n",
      "Total reward: 8718.583216520723, Epsilon: 0.695\n",
      "Episode 2583 finished after 1866 timesteps\n",
      "Total reward: 10564.826156841493, Epsilon: 0.695\n",
      "Episode 2584 finished after 1332 timesteps\n",
      "Total reward: 8153.4333034915035, Epsilon: 0.695\n",
      "Episode 2585 finished after 3001 timesteps\n",
      "Total reward: 14162.196268257721, Epsilon: 0.695\n",
      "Episode 2586 finished after 3001 timesteps\n",
      "Total reward: 19796.471369072806, Epsilon: 0.695\n",
      "Episode 2587 finished after 3001 timesteps\n",
      "Total reward: 13358.404982390934, Epsilon: 0.695\n",
      "Episode 2588 finished after 209 timesteps\n",
      "Total reward: 1919.683051419762, Epsilon: 0.695\n",
      "Episode 2589 finished after 2533 timesteps\n",
      "Total reward: 14318.973709048933, Epsilon: 0.695\n",
      "Episode 2590 finished after 1078 timesteps\n",
      "Total reward: 5249.659870544731, Epsilon: 0.695\n",
      "Episode 2591 finished after 590 timesteps\n",
      "Total reward: 4473.864549945654, Epsilon: 0.694\n",
      "Episode 2592 finished after 457 timesteps\n",
      "Total reward: 3323.562069526864, Epsilon: 0.694\n",
      "Episode 2593 finished after 3001 timesteps\n",
      "Total reward: 13839.229754449545, Epsilon: 0.694\n",
      "Episode 2594 finished after 3001 timesteps\n",
      "Total reward: 20843.464613265573, Epsilon: 0.694\n",
      "Episode 2595 finished after 2125 timesteps\n",
      "Total reward: 14083.938939845537, Epsilon: 0.694\n",
      "Episode 2596 finished after 350 timesteps\n",
      "Total reward: 2586.026624989285, Epsilon: 0.694\n",
      "Episode 2597 finished after 3001 timesteps\n",
      "Total reward: 15401.417831934057, Epsilon: 0.694\n",
      "Episode 2598 finished after 1247 timesteps\n",
      "Total reward: 6727.4569037966985, Epsilon: 0.694\n",
      "Episode 2599 finished after 3001 timesteps\n",
      "Total reward: 14590.883786845221, Epsilon: 0.694\n",
      "Episode 2600 finished after 534 timesteps\n",
      "Total reward: 4120.498496378241, Epsilon: 0.694\n",
      "Episode 2601 finished after 3001 timesteps\n",
      "Total reward: 15733.989150575262, Epsilon: 0.694\n",
      "Episode 2602 finished after 1747 timesteps\n",
      "Total reward: 13265.187298553343, Epsilon: 0.694\n",
      "Episode 2603 finished after 1033 timesteps\n",
      "Total reward: 5795.715873566109, Epsilon: 0.694\n",
      "Episode 2604 finished after 3001 timesteps\n",
      "Total reward: 13484.074980745301, Epsilon: 0.694\n",
      "Episode 2605 finished after 333 timesteps\n",
      "Total reward: 2818.637190463003, Epsilon: 0.694\n",
      "Episode 2606 finished after 511 timesteps\n",
      "Total reward: 3190.7032199091777, Epsilon: 0.693\n",
      "Episode 2607 finished after 3001 timesteps\n",
      "Total reward: 16679.59650600414, Epsilon: 0.693\n",
      "Episode 2608 finished after 2854 timesteps\n",
      "Total reward: 16413.584515602764, Epsilon: 0.693\n",
      "Episode 2609 finished after 3001 timesteps\n",
      "Total reward: 14539.115017626336, Epsilon: 0.693\n",
      "Episode 2610 finished after 1784 timesteps\n",
      "Total reward: 8552.21491939276, Epsilon: 0.693\n",
      "Episode 2611 finished after 554 timesteps\n",
      "Total reward: 3858.5892279905333, Epsilon: 0.693\n",
      "Episode 2612 finished after 2618 timesteps\n",
      "Total reward: 12649.180962114791, Epsilon: 0.693\n",
      "Episode 2613 finished after 1896 timesteps\n",
      "Total reward: 9692.380772994395, Epsilon: 0.693\n",
      "Episode 2614 finished after 443 timesteps\n",
      "Total reward: 3931.90870701359, Epsilon: 0.693\n",
      "Episode 2615 finished after 1484 timesteps\n",
      "Total reward: 7605.647202150769, Epsilon: 0.693\n",
      "Episode 2616 finished after 3001 timesteps\n",
      "Total reward: 14285.56001966624, Epsilon: 0.693\n",
      "Episode 2617 finished after 3001 timesteps\n",
      "Total reward: 21055.63051139694, Epsilon: 0.693\n",
      "Episode 2618 finished after 3001 timesteps\n",
      "Total reward: 18390.193612409577, Epsilon: 0.693\n",
      "Episode 2619 finished after 896 timesteps\n",
      "Total reward: 4798.796244296312, Epsilon: 0.693\n",
      "Episode 2620 finished after 259 timesteps\n",
      "Total reward: 2167.7349225153816, Epsilon: 0.692\n",
      "Episode 2621 finished after 441 timesteps\n",
      "Total reward: 2735.5651783247586, Epsilon: 0.692\n",
      "Episode 2622 finished after 432 timesteps\n",
      "Total reward: 4219.015236519388, Epsilon: 0.692\n",
      "Episode 2623 finished after 3001 timesteps\n",
      "Total reward: 18801.199714675444, Epsilon: 0.692\n",
      "Episode 2624 finished after 2154 timesteps\n",
      "Total reward: 11504.589464528668, Epsilon: 0.692\n",
      "Episode 2625 finished after 1757 timesteps\n",
      "Total reward: 9469.905055942456, Epsilon: 0.692\n",
      "Episode 2626 finished after 2263 timesteps\n",
      "Total reward: 13223.223016268115, Epsilon: 0.692\n",
      "Episode 2627 finished after 524 timesteps\n",
      "Total reward: 3346.376980000954, Epsilon: 0.692\n",
      "Episode 2628 finished after 1864 timesteps\n",
      "Total reward: 10940.947684484763, Epsilon: 0.692\n",
      "Episode 2629 finished after 3001 timesteps\n",
      "Total reward: 17680.829733472157, Epsilon: 0.692\n",
      "Episode 2630 finished after 605 timesteps\n",
      "Total reward: 3662.75005924459, Epsilon: 0.692\n",
      "Episode 2631 finished after 257 timesteps\n",
      "Total reward: 2536.0310976952715, Epsilon: 0.692\n",
      "Episode 2632 finished after 754 timesteps\n",
      "Total reward: 3752.127687328398, Epsilon: 0.692\n",
      "Episode 2633 finished after 1551 timesteps\n",
      "Total reward: 11244.735091148348, Epsilon: 0.692\n",
      "Episode 2634 finished after 3001 timesteps\n",
      "Total reward: 14810.845174192635, Epsilon: 0.692\n",
      "Episode 2635 finished after 1187 timesteps\n",
      "Total reward: 7047.0837790073365, Epsilon: 0.691\n",
      "Episode 2636 finished after 1897 timesteps\n",
      "Total reward: 10678.479814608108, Epsilon: 0.691\n",
      "Episode 2637 finished after 3001 timesteps\n",
      "Total reward: 13496.055219681315, Epsilon: 0.691\n",
      "Episode 2638 finished after 815 timesteps\n",
      "Total reward: 6913.972464519281, Epsilon: 0.691\n",
      "Episode 2639 finished after 3001 timesteps\n",
      "Total reward: 11792.840528524352, Epsilon: 0.691\n",
      "Episode 2640 finished after 1967 timesteps\n",
      "Total reward: 12464.840395428297, Epsilon: 0.691\n",
      "Episode 2641 finished after 1036 timesteps\n",
      "Total reward: 7511.546361881717, Epsilon: 0.691\n",
      "Episode 2642 finished after 826 timesteps\n",
      "Total reward: 8134.290954414308, Epsilon: 0.691\n",
      "Episode 2643 finished after 2217 timesteps\n",
      "Total reward: 12682.926238616297, Epsilon: 0.691\n",
      "Episode 2644 finished after 3001 timesteps\n",
      "Total reward: 12747.418991568438, Epsilon: 0.691\n",
      "Episode 2645 finished after 2684 timesteps\n",
      "Total reward: 14879.973705190061, Epsilon: 0.691\n",
      "Episode 2646 finished after 1938 timesteps\n",
      "Total reward: 14306.009445988642, Epsilon: 0.691\n",
      "Episode 2647 finished after 1846 timesteps\n",
      "Total reward: 8968.412063713777, Epsilon: 0.691\n",
      "Episode 2648 finished after 1528 timesteps\n",
      "Total reward: 9829.308338488285, Epsilon: 0.691\n",
      "Episode 2649 finished after 801 timesteps\n",
      "Total reward: 5768.305682191082, Epsilon: 0.690\n",
      "Episode 2650 finished after 1350 timesteps\n",
      "Total reward: 7915.790313390699, Epsilon: 0.690\n",
      "Episode 2651 finished after 989 timesteps\n",
      "Total reward: 7008.151404807903, Epsilon: 0.690\n",
      "Episode 2652 finished after 343 timesteps\n",
      "Total reward: 3820.8531150310773, Epsilon: 0.690\n",
      "Episode 2653 finished after 546 timesteps\n",
      "Total reward: 3514.0779561329136, Epsilon: 0.690\n",
      "Episode 2654 finished after 3001 timesteps\n",
      "Total reward: 14776.605941075131, Epsilon: 0.690\n",
      "Episode 2655 finished after 478 timesteps\n",
      "Total reward: 2964.718836301617, Epsilon: 0.690\n",
      "Episode 2656 finished after 1451 timesteps\n",
      "Total reward: 9166.292282878021, Epsilon: 0.690\n",
      "Episode 2657 finished after 1912 timesteps\n",
      "Total reward: 12755.77595216974, Epsilon: 0.690\n",
      "Episode 2658 finished after 2470 timesteps\n",
      "Total reward: 14034.377206728986, Epsilon: 0.690\n",
      "Episode 2659 finished after 3001 timesteps\n",
      "Total reward: 15007.00845590003, Epsilon: 0.690\n",
      "Episode 2660 finished after 236 timesteps\n",
      "Total reward: 2010.1223317036304, Epsilon: 0.690\n",
      "Episode 2661 finished after 2045 timesteps\n",
      "Total reward: 12134.593257024282, Epsilon: 0.690\n",
      "Episode 2662 finished after 1207 timesteps\n",
      "Total reward: 6310.147897542518, Epsilon: 0.690\n",
      "Episode 2663 finished after 837 timesteps\n",
      "Total reward: 8045.932191297551, Epsilon: 0.690\n",
      "Episode 2664 finished after 1352 timesteps\n",
      "Total reward: 9670.914706819596, Epsilon: 0.689\n",
      "Episode 2665 finished after 1164 timesteps\n",
      "Total reward: 8134.381570573987, Epsilon: 0.689\n",
      "Episode 2666 finished after 3001 timesteps\n",
      "Total reward: 14227.334692629518, Epsilon: 0.689\n",
      "Episode 2667 finished after 3001 timesteps\n",
      "Total reward: 13842.387143687298, Epsilon: 0.689\n",
      "Episode 2668 finished after 497 timesteps\n",
      "Total reward: 4734.50784599774, Epsilon: 0.689\n",
      "Episode 2669 finished after 1162 timesteps\n",
      "Total reward: 8610.540344580351, Epsilon: 0.689\n",
      "Episode 2670 finished after 838 timesteps\n",
      "Total reward: 4624.176145794359, Epsilon: 0.689\n",
      "Episode 2671 finished after 366 timesteps\n",
      "Total reward: 2874.62967729657, Epsilon: 0.689\n",
      "Episode 2672 finished after 859 timesteps\n",
      "Total reward: 4852.190976374121, Epsilon: 0.689\n",
      "Episode 2673 finished after 513 timesteps\n",
      "Total reward: 4396.661032467474, Epsilon: 0.689\n",
      "Episode 2674 finished after 1651 timesteps\n",
      "Total reward: 9975.482659645879, Epsilon: 0.689\n",
      "Episode 2675 finished after 2288 timesteps\n",
      "Total reward: 11822.740243124204, Epsilon: 0.689\n",
      "Episode 2676 finished after 2324 timesteps\n",
      "Total reward: 12630.16219635672, Epsilon: 0.689\n",
      "Episode 2677 finished after 1181 timesteps\n",
      "Total reward: 7266.107225168077, Epsilon: 0.689\n",
      "Episode 2678 finished after 1011 timesteps\n",
      "Total reward: 5883.653724591284, Epsilon: 0.688\n",
      "Episode 2679 finished after 1027 timesteps\n",
      "Total reward: 6367.688872634653, Epsilon: 0.688\n",
      "Episode 2680 finished after 1074 timesteps\n",
      "Total reward: 5637.335503157635, Epsilon: 0.688\n",
      "Episode 2681 finished after 2811 timesteps\n",
      "Total reward: 14809.057558610284, Epsilon: 0.688\n",
      "Episode 2682 finished after 746 timesteps\n",
      "Total reward: 5460.459912179831, Epsilon: 0.688\n",
      "Episode 2683 finished after 3001 timesteps\n",
      "Total reward: 18783.951855397623, Epsilon: 0.688\n",
      "Episode 2684 finished after 179 timesteps\n",
      "Total reward: 1884.9001889330048, Epsilon: 0.688\n",
      "Episode 2685 finished after 698 timesteps\n",
      "Total reward: 4683.288554883099, Epsilon: 0.688\n",
      "Episode 2686 finished after 1726 timesteps\n",
      "Total reward: 8625.842358579828, Epsilon: 0.688\n",
      "Episode 2687 finished after 1037 timesteps\n",
      "Total reward: 7069.564479135393, Epsilon: 0.688\n",
      "Episode 2688 finished after 1692 timesteps\n",
      "Total reward: 10313.884078975103, Epsilon: 0.688\n",
      "Episode 2689 finished after 2162 timesteps\n",
      "Total reward: 11139.42336692729, Epsilon: 0.688\n",
      "Episode 2690 finished after 1435 timesteps\n",
      "Total reward: 7430.047845711013, Epsilon: 0.688\n",
      "Episode 2691 finished after 2686 timesteps\n",
      "Total reward: 16839.217502270938, Epsilon: 0.688\n",
      "Episode 2692 finished after 321 timesteps\n",
      "Total reward: 2699.6678334631365, Epsilon: 0.688\n",
      "Episode 2693 finished after 2826 timesteps\n",
      "Total reward: 13791.948485430094, Epsilon: 0.687\n",
      "Episode 2694 finished after 1611 timesteps\n",
      "Total reward: 10316.764071369978, Epsilon: 0.687\n",
      "Episode 2695 finished after 1356 timesteps\n",
      "Total reward: 9004.556167517783, Epsilon: 0.687\n",
      "Episode 2696 finished after 2248 timesteps\n",
      "Total reward: 13049.667794450368, Epsilon: 0.687\n",
      "Episode 2697 finished after 918 timesteps\n",
      "Total reward: 4562.950944147, Epsilon: 0.687\n",
      "Episode 2698 finished after 1903 timesteps\n",
      "Total reward: 9403.698086551094, Epsilon: 0.687\n",
      "Episode 2699 finished after 2129 timesteps\n",
      "Total reward: 13598.77229208275, Epsilon: 0.687\n",
      "Episode 2700 finished after 497 timesteps\n",
      "Total reward: 3692.0634671873686, Epsilon: 0.687\n",
      "Episode 2701 finished after 2358 timesteps\n",
      "Total reward: 15987.720857042057, Epsilon: 0.687\n",
      "Episode 2702 finished after 1821 timesteps\n",
      "Total reward: 8622.532902801831, Epsilon: 0.687\n",
      "Episode 2703 finished after 1773 timesteps\n",
      "Total reward: 9131.90177492662, Epsilon: 0.687\n",
      "Episode 2704 finished after 2969 timesteps\n",
      "Total reward: 15160.119979803578, Epsilon: 0.687\n",
      "Episode 2705 finished after 3001 timesteps\n",
      "Total reward: 16234.01387340824, Epsilon: 0.687\n",
      "Episode 2706 finished after 2470 timesteps\n",
      "Total reward: 16978.36314696875, Epsilon: 0.687\n",
      "Episode 2707 finished after 1200 timesteps\n",
      "Total reward: 7181.8469172187315, Epsilon: 0.686\n",
      "Episode 2708 finished after 1675 timesteps\n",
      "Total reward: 9716.83550355461, Epsilon: 0.686\n",
      "Episode 2709 finished after 384 timesteps\n",
      "Total reward: 3657.8510629710363, Epsilon: 0.686\n",
      "Episode 2710 finished after 665 timesteps\n",
      "Total reward: 5184.122700352366, Epsilon: 0.686\n",
      "Episode 2711 finished after 2509 timesteps\n",
      "Total reward: 13900.098704074248, Epsilon: 0.686\n",
      "Episode 2712 finished after 3001 timesteps\n",
      "Total reward: 13756.801703104418, Epsilon: 0.686\n",
      "Episode 2713 finished after 3001 timesteps\n",
      "Total reward: 12707.364424106609, Epsilon: 0.686\n",
      "Episode 2714 finished after 1339 timesteps\n",
      "Total reward: 8800.756791310696, Epsilon: 0.686\n",
      "Episode 2715 finished after 2497 timesteps\n",
      "Total reward: 15647.415154774348, Epsilon: 0.686\n",
      "Episode 2716 finished after 1209 timesteps\n",
      "Total reward: 9975.824674851438, Epsilon: 0.686\n",
      "Episode 2717 finished after 1363 timesteps\n",
      "Total reward: 10468.614670327544, Epsilon: 0.686\n",
      "Episode 2718 finished after 1818 timesteps\n",
      "Total reward: 10776.737589948312, Epsilon: 0.686\n",
      "Episode 2719 finished after 789 timesteps\n",
      "Total reward: 4629.429343137083, Epsilon: 0.686\n",
      "Episode 2720 finished after 1159 timesteps\n",
      "Total reward: 6368.9776334556045, Epsilon: 0.686\n",
      "Episode 2721 finished after 1404 timesteps\n",
      "Total reward: 7682.483411615503, Epsilon: 0.686\n",
      "Episode 2722 finished after 2412 timesteps\n",
      "Total reward: 11701.068641080677, Epsilon: 0.685\n",
      "Episode 2723 finished after 2378 timesteps\n",
      "Total reward: 13095.339980079983, Epsilon: 0.685\n",
      "Episode 2724 finished after 1192 timesteps\n",
      "Total reward: 6824.193945955611, Epsilon: 0.685\n",
      "Episode 2725 finished after 1201 timesteps\n",
      "Total reward: 7796.540806369675, Epsilon: 0.685\n",
      "Episode 2726 finished after 1001 timesteps\n",
      "Total reward: 5747.506189470756, Epsilon: 0.685\n",
      "Episode 2727 finished after 1183 timesteps\n",
      "Total reward: 5605.9682390897015, Epsilon: 0.685\n",
      "Episode 2728 finished after 1480 timesteps\n",
      "Total reward: 9227.18094014586, Epsilon: 0.685\n",
      "Episode 2729 finished after 554 timesteps\n",
      "Total reward: 3404.8787753572765, Epsilon: 0.685\n",
      "Episode 2730 finished after 364 timesteps\n",
      "Total reward: 2976.787993554987, Epsilon: 0.685\n",
      "Episode 2731 finished after 997 timesteps\n",
      "Total reward: 5542.771881355767, Epsilon: 0.685\n",
      "Episode 2732 finished after 1485 timesteps\n",
      "Total reward: 7733.152222579604, Epsilon: 0.685\n",
      "Episode 2733 finished after 1131 timesteps\n",
      "Total reward: 6900.827985492936, Epsilon: 0.685\n",
      "Episode 2734 finished after 1246 timesteps\n",
      "Total reward: 6739.881915177107, Epsilon: 0.685\n",
      "Episode 2735 finished after 1950 timesteps\n",
      "Total reward: 9899.788904534003, Epsilon: 0.685\n",
      "Episode 2736 finished after 2219 timesteps\n",
      "Total reward: 13817.310107659132, Epsilon: 0.684\n",
      "Episode 2737 finished after 2271 timesteps\n",
      "Total reward: 13194.426987157667, Epsilon: 0.684\n",
      "Episode 2738 finished after 3001 timesteps\n",
      "Total reward: 13106.333293565996, Epsilon: 0.684\n",
      "Episode 2739 finished after 2047 timesteps\n",
      "Total reward: 10707.324426387246, Epsilon: 0.684\n",
      "Episode 2740 finished after 1405 timesteps\n",
      "Total reward: 6873.863457296638, Epsilon: 0.684\n",
      "Episode 2741 finished after 1077 timesteps\n",
      "Total reward: 6762.630096320642, Epsilon: 0.684\n",
      "Episode 2742 finished after 3001 timesteps\n",
      "Total reward: 14062.675329183488, Epsilon: 0.684\n",
      "Episode 2743 finished after 3001 timesteps\n",
      "Total reward: 14868.91645677882, Epsilon: 0.684\n",
      "Episode 2744 finished after 1420 timesteps\n",
      "Total reward: 10897.354110073566, Epsilon: 0.684\n",
      "Episode 2745 finished after 3001 timesteps\n",
      "Total reward: 18402.73109639926, Epsilon: 0.684\n",
      "Episode 2746 finished after 319 timesteps\n",
      "Total reward: 2347.219551173863, Epsilon: 0.684\n",
      "Episode 2747 finished after 3001 timesteps\n",
      "Total reward: 15934.725332847784, Epsilon: 0.684\n",
      "Episode 2748 finished after 1205 timesteps\n",
      "Total reward: 7110.790536252788, Epsilon: 0.684\n",
      "Episode 2749 finished after 3001 timesteps\n",
      "Total reward: 13528.841776638224, Epsilon: 0.684\n",
      "Episode 2750 finished after 1950 timesteps\n",
      "Total reward: 10543.476246752303, Epsilon: 0.684\n",
      "Episode 2751 finished after 1244 timesteps\n",
      "Total reward: 8654.582309045014, Epsilon: 0.683\n",
      "Episode 2752 finished after 3001 timesteps\n",
      "Total reward: 13929.302672169508, Epsilon: 0.683\n",
      "Episode 2753 finished after 804 timesteps\n",
      "Total reward: 5531.731295152817, Epsilon: 0.683\n",
      "Episode 2754 finished after 1181 timesteps\n",
      "Total reward: 5414.387024486393, Epsilon: 0.683\n",
      "Episode 2755 finished after 1144 timesteps\n",
      "Total reward: 7917.4963980109305, Epsilon: 0.683\n",
      "Episode 2756 finished after 780 timesteps\n",
      "Total reward: 5605.372266997509, Epsilon: 0.683\n",
      "Episode 2757 finished after 939 timesteps\n",
      "Total reward: 5723.11987877887, Epsilon: 0.683\n",
      "Episode 2758 finished after 830 timesteps\n",
      "Total reward: 5269.7733550496105, Epsilon: 0.683\n",
      "Episode 2759 finished after 1327 timesteps\n",
      "Total reward: 6832.935961289477, Epsilon: 0.683\n",
      "Episode 2760 finished after 2302 timesteps\n",
      "Total reward: 13345.934962229081, Epsilon: 0.683\n",
      "Episode 2761 finished after 999 timesteps\n",
      "Total reward: 6051.569150159052, Epsilon: 0.683\n",
      "Episode 2762 finished after 991 timesteps\n",
      "Total reward: 6353.142882774892, Epsilon: 0.683\n",
      "Episode 2763 finished after 1050 timesteps\n",
      "Total reward: 6491.48100996103, Epsilon: 0.683\n",
      "Episode 2764 finished after 3001 timesteps\n",
      "Total reward: 15715.193761492716, Epsilon: 0.683\n",
      "Episode 2765 finished after 1993 timesteps\n",
      "Total reward: 12891.598536046173, Epsilon: 0.683\n",
      "Episode 2766 finished after 1302 timesteps\n",
      "Total reward: 8526.31348842615, Epsilon: 0.682\n",
      "Episode 2767 finished after 3001 timesteps\n",
      "Total reward: 13472.428916416773, Epsilon: 0.682\n",
      "Episode 2768 finished after 929 timesteps\n",
      "Total reward: 7149.975017734294, Epsilon: 0.682\n",
      "Episode 2769 finished after 866 timesteps\n",
      "Total reward: 5385.273013019645, Epsilon: 0.682\n",
      "Episode 2770 finished after 3001 timesteps\n",
      "Total reward: 13563.395880702908, Epsilon: 0.682\n",
      "Episode 2771 finished after 382 timesteps\n",
      "Total reward: 3152.8627853043045, Epsilon: 0.682\n",
      "Episode 2772 finished after 1475 timesteps\n",
      "Total reward: 8725.759508917363, Epsilon: 0.682\n",
      "Episode 2773 finished after 3001 timesteps\n",
      "Total reward: 13479.75634163557, Epsilon: 0.682\n",
      "Episode 2774 finished after 285 timesteps\n",
      "Total reward: 2774.195913476135, Epsilon: 0.682\n",
      "Episode 2775 finished after 3001 timesteps\n",
      "Total reward: 13423.551198944451, Epsilon: 0.682\n",
      "Episode 2776 finished after 897 timesteps\n",
      "Total reward: 5125.69167164308, Epsilon: 0.682\n",
      "Episode 2777 finished after 1261 timesteps\n",
      "Total reward: 9783.425259100346, Epsilon: 0.682\n",
      "Episode 2778 finished after 1210 timesteps\n",
      "Total reward: 10902.599342359737, Epsilon: 0.682\n",
      "Episode 2779 finished after 1718 timesteps\n",
      "Total reward: 8116.365050717392, Epsilon: 0.682\n",
      "Episode 2780 finished after 3001 timesteps\n",
      "Total reward: 14879.365046146158, Epsilon: 0.681\n",
      "Episode 2781 finished after 3001 timesteps\n",
      "Total reward: 13637.135018296172, Epsilon: 0.681\n",
      "Episode 2782 finished after 836 timesteps\n",
      "Total reward: 5317.439797502181, Epsilon: 0.681\n",
      "Episode 2783 finished after 3001 timesteps\n",
      "Total reward: 14286.234155046654, Epsilon: 0.681\n",
      "Episode 2784 finished after 657 timesteps\n",
      "Total reward: 4315.77575029215, Epsilon: 0.681\n",
      "Episode 2785 finished after 1079 timesteps\n",
      "Total reward: 6992.133189749157, Epsilon: 0.681\n",
      "Episode 2786 finished after 429 timesteps\n",
      "Total reward: 4518.092503787474, Epsilon: 0.681\n",
      "Episode 2787 finished after 451 timesteps\n",
      "Total reward: 3485.5125753303714, Epsilon: 0.681\n",
      "Episode 2788 finished after 3001 timesteps\n",
      "Total reward: 16477.11168804669, Epsilon: 0.681\n",
      "Episode 2789 finished after 627 timesteps\n",
      "Total reward: 4023.668786278144, Epsilon: 0.681\n",
      "Episode 2790 finished after 2931 timesteps\n",
      "Total reward: 14426.611743603049, Epsilon: 0.681\n",
      "Episode 2791 finished after 2303 timesteps\n",
      "Total reward: 10882.173478503299, Epsilon: 0.681\n",
      "Episode 2792 finished after 739 timesteps\n",
      "Total reward: 6090.467999821578, Epsilon: 0.681\n",
      "Episode 2793 finished after 3001 timesteps\n",
      "Total reward: 19224.25620806665, Epsilon: 0.681\n",
      "Episode 2794 finished after 278 timesteps\n",
      "Total reward: 2315.282265582002, Epsilon: 0.681\n",
      "Episode 2795 finished after 825 timesteps\n",
      "Total reward: 6124.018422640352, Epsilon: 0.680\n",
      "Episode 2796 finished after 907 timesteps\n",
      "Total reward: 5882.691602024469, Epsilon: 0.680\n",
      "Episode 2797 finished after 2658 timesteps\n",
      "Total reward: 14999.237796369125, Epsilon: 0.680\n",
      "Episode 2798 finished after 1071 timesteps\n",
      "Total reward: 5858.056136868568, Epsilon: 0.680\n",
      "Episode 2799 finished after 635 timesteps\n",
      "Total reward: 4587.5958161002445, Epsilon: 0.680\n",
      "Episode 2800 finished after 269 timesteps\n",
      "Total reward: 1982.7452636465355, Epsilon: 0.680\n",
      "Episode 2801 finished after 437 timesteps\n",
      "Total reward: 3892.8682555771634, Epsilon: 0.680\n",
      "Episode 2802 finished after 1079 timesteps\n",
      "Total reward: 7746.015118902358, Epsilon: 0.680\n",
      "Episode 2803 finished after 2235 timesteps\n",
      "Total reward: 11713.35429768122, Epsilon: 0.680\n",
      "Episode 2804 finished after 2707 timesteps\n",
      "Total reward: 13600.199228893132, Epsilon: 0.680\n",
      "Episode 2805 finished after 3001 timesteps\n",
      "Total reward: 13861.081875797696, Epsilon: 0.680\n",
      "Episode 2806 finished after 3001 timesteps\n",
      "Total reward: 15097.628807323417, Epsilon: 0.680\n",
      "Episode 2807 finished after 3001 timesteps\n",
      "Total reward: 15243.279121702493, Epsilon: 0.680\n",
      "Episode 2808 finished after 2012 timesteps\n",
      "Total reward: 10897.882947963848, Epsilon: 0.680\n",
      "Episode 2809 finished after 2001 timesteps\n",
      "Total reward: 13002.781356942549, Epsilon: 0.680\n",
      "Episode 2810 finished after 416 timesteps\n",
      "Total reward: 3519.4157333510007, Epsilon: 0.679\n",
      "Episode 2811 finished after 3001 timesteps\n",
      "Total reward: 18196.23099159879, Epsilon: 0.679\n",
      "Episode 2812 finished after 740 timesteps\n",
      "Total reward: 5161.7420843802465, Epsilon: 0.679\n",
      "Episode 2813 finished after 490 timesteps\n",
      "Total reward: 3632.7742236338513, Epsilon: 0.679\n",
      "Episode 2814 finished after 3001 timesteps\n",
      "Total reward: 14538.527864898306, Epsilon: 0.679\n",
      "Episode 2815 finished after 1823 timesteps\n",
      "Total reward: 9628.808957205685, Epsilon: 0.679\n",
      "Episode 2816 finished after 1410 timesteps\n",
      "Total reward: 8900.612026098283, Epsilon: 0.679\n",
      "Episode 2817 finished after 3001 timesteps\n",
      "Total reward: 14930.769776036897, Epsilon: 0.679\n",
      "Episode 2818 finished after 248 timesteps\n",
      "Total reward: 2868.757439709696, Epsilon: 0.679\n",
      "Episode 2819 finished after 857 timesteps\n",
      "Total reward: 4483.312702160708, Epsilon: 0.679\n",
      "Episode 2820 finished after 1928 timesteps\n",
      "Total reward: 13804.249263284502, Epsilon: 0.679\n",
      "Episode 2821 finished after 3001 timesteps\n",
      "Total reward: 17154.270658013953, Epsilon: 0.679\n",
      "Episode 2822 finished after 1321 timesteps\n",
      "Total reward: 8691.635931038496, Epsilon: 0.679\n",
      "Episode 2823 finished after 2524 timesteps\n",
      "Total reward: 16082.692257682564, Epsilon: 0.679\n",
      "Episode 2824 finished after 1879 timesteps\n",
      "Total reward: 12644.609771256279, Epsilon: 0.678\n",
      "Episode 2825 finished after 113 timesteps\n",
      "Total reward: 1567.5498104419407, Epsilon: 0.678\n",
      "Episode 2826 finished after 2416 timesteps\n",
      "Total reward: 11907.305180758653, Epsilon: 0.678\n",
      "Episode 2827 finished after 536 timesteps\n",
      "Total reward: 4057.057795514571, Epsilon: 0.678\n",
      "Episode 2828 finished after 1129 timesteps\n",
      "Total reward: 7135.831716124996, Epsilon: 0.678\n",
      "Episode 2829 finished after 361 timesteps\n",
      "Total reward: 3093.789307924193, Epsilon: 0.678\n",
      "Episode 2830 finished after 1267 timesteps\n",
      "Total reward: 9286.834515898128, Epsilon: 0.678\n",
      "Episode 2831 finished after 3001 timesteps\n",
      "Total reward: 18679.55511123726, Epsilon: 0.678\n",
      "Episode 2832 finished after 362 timesteps\n",
      "Total reward: 3125.2238364679133, Epsilon: 0.678\n",
      "Episode 2833 finished after 2904 timesteps\n",
      "Total reward: 13986.534427669687, Epsilon: 0.678\n",
      "Episode 2834 finished after 1196 timesteps\n",
      "Total reward: 7391.620537050696, Epsilon: 0.678\n",
      "Episode 2835 finished after 3001 timesteps\n",
      "Total reward: 14560.991124896073, Epsilon: 0.678\n",
      "Episode 2836 finished after 2124 timesteps\n",
      "Total reward: 14054.796948825651, Epsilon: 0.678\n",
      "Episode 2837 finished after 1072 timesteps\n",
      "Total reward: 6017.1939281087725, Epsilon: 0.678\n",
      "Episode 2838 finished after 959 timesteps\n",
      "Total reward: 4870.351207077346, Epsilon: 0.678\n",
      "Episode 2839 finished after 1881 timesteps\n",
      "Total reward: 11638.517027493597, Epsilon: 0.677\n",
      "Episode 2840 finished after 3001 timesteps\n",
      "Total reward: 16948.80841679603, Epsilon: 0.677\n",
      "Episode 2841 finished after 354 timesteps\n",
      "Total reward: 4379.59696567526, Epsilon: 0.677\n",
      "Episode 2842 finished after 2594 timesteps\n",
      "Total reward: 11978.129289569042, Epsilon: 0.677\n",
      "Episode 2843 finished after 3001 timesteps\n",
      "Total reward: 14698.466772451358, Epsilon: 0.677\n",
      "Episode 2844 finished after 1694 timesteps\n",
      "Total reward: 8348.598388273356, Epsilon: 0.677\n",
      "Episode 2845 finished after 3001 timesteps\n",
      "Total reward: 15305.861199159508, Epsilon: 0.677\n",
      "Episode 2846 finished after 732 timesteps\n",
      "Total reward: 5340.532333670639, Epsilon: 0.677\n",
      "Episode 2847 finished after 2359 timesteps\n",
      "Total reward: 11767.994510213925, Epsilon: 0.677\n",
      "Episode 2848 finished after 144 timesteps\n",
      "Total reward: 1814.2232115548143, Epsilon: 0.677\n",
      "Episode 2849 finished after 389 timesteps\n",
      "Total reward: 3197.714829428461, Epsilon: 0.677\n",
      "Episode 2850 finished after 218 timesteps\n",
      "Total reward: 2075.692757522783, Epsilon: 0.677\n",
      "Episode 2851 finished after 3001 timesteps\n",
      "Total reward: 15021.886272648328, Epsilon: 0.677\n",
      "Episode 2852 finished after 3001 timesteps\n",
      "Total reward: 14156.508308094955, Epsilon: 0.677\n",
      "Episode 2853 finished after 568 timesteps\n",
      "Total reward: 3754.663229492023, Epsilon: 0.677\n",
      "Episode 2854 finished after 2310 timesteps\n",
      "Total reward: 12609.770639836786, Epsilon: 0.676\n",
      "Episode 2855 finished after 255 timesteps\n",
      "Total reward: 2369.967268750013, Epsilon: 0.676\n",
      "Episode 2856 finished after 881 timesteps\n",
      "Total reward: 5930.49219535641, Epsilon: 0.676\n",
      "Episode 2857 finished after 3001 timesteps\n",
      "Total reward: 16653.019309718486, Epsilon: 0.676\n",
      "Episode 2858 finished after 3001 timesteps\n",
      "Total reward: 16078.909071618024, Epsilon: 0.676\n",
      "Episode 2859 finished after 3001 timesteps\n",
      "Total reward: 14633.984574814562, Epsilon: 0.676\n",
      "Episode 2860 finished after 721 timesteps\n",
      "Total reward: 5643.971354526227, Epsilon: 0.676\n",
      "Episode 2861 finished after 453 timesteps\n",
      "Total reward: 3714.1530778308966, Epsilon: 0.676\n",
      "Episode 2862 finished after 2308 timesteps\n",
      "Total reward: 12249.733189648137, Epsilon: 0.676\n",
      "Episode 2863 finished after 3001 timesteps\n",
      "Total reward: 14660.095822721798, Epsilon: 0.676\n",
      "Episode 2864 finished after 1635 timesteps\n",
      "Total reward: 10801.86633087521, Epsilon: 0.676\n",
      "Episode 2865 finished after 3001 timesteps\n",
      "Total reward: 13519.630179377042, Epsilon: 0.676\n",
      "Episode 2866 finished after 2392 timesteps\n",
      "Total reward: 13770.295395056473, Epsilon: 0.676\n",
      "Episode 2867 finished after 967 timesteps\n",
      "Total reward: 6143.750865249766, Epsilon: 0.676\n",
      "Episode 2868 finished after 338 timesteps\n",
      "Total reward: 3293.2680379581107, Epsilon: 0.676\n",
      "Episode 2869 finished after 983 timesteps\n",
      "Total reward: 8675.550293056256, Epsilon: 0.675\n",
      "Episode 2870 finished after 1101 timesteps\n",
      "Total reward: 5615.424165472746, Epsilon: 0.675\n",
      "Episode 2871 finished after 3001 timesteps\n",
      "Total reward: 14116.032837250576, Epsilon: 0.675\n",
      "Episode 2872 finished after 2989 timesteps\n",
      "Total reward: 13395.1249667606, Epsilon: 0.675\n",
      "Episode 2873 finished after 1459 timesteps\n",
      "Total reward: 8536.427836735409, Epsilon: 0.675\n",
      "Episode 2874 finished after 2934 timesteps\n",
      "Total reward: 16092.05267869612, Epsilon: 0.675\n",
      "Episode 2875 finished after 283 timesteps\n",
      "Total reward: 2306.5587229274684, Epsilon: 0.675\n",
      "Episode 2876 finished after 1313 timesteps\n",
      "Total reward: 6737.5772394697515, Epsilon: 0.675\n",
      "Episode 2877 finished after 722 timesteps\n",
      "Total reward: 6175.45469930176, Epsilon: 0.675\n",
      "Episode 2878 finished after 2522 timesteps\n",
      "Total reward: 12744.671699698772, Epsilon: 0.675\n",
      "Episode 2879 finished after 655 timesteps\n",
      "Total reward: 4421.226155405469, Epsilon: 0.675\n",
      "Episode 2880 finished after 734 timesteps\n",
      "Total reward: 4989.809642915574, Epsilon: 0.675\n",
      "Episode 2881 finished after 298 timesteps\n",
      "Total reward: 2480.8471855552452, Epsilon: 0.675\n",
      "Episode 2882 finished after 1300 timesteps\n",
      "Total reward: 8334.855998037903, Epsilon: 0.675\n",
      "Episode 2883 finished after 3001 timesteps\n",
      "Total reward: 13380.659455466326, Epsilon: 0.675\n",
      "Episode 2884 finished after 1057 timesteps\n",
      "Total reward: 6045.487973387474, Epsilon: 0.674\n",
      "Episode 2885 finished after 2961 timesteps\n",
      "Total reward: 14177.685867056694, Epsilon: 0.674\n",
      "Episode 2886 finished after 565 timesteps\n",
      "Total reward: 4875.883530967975, Epsilon: 0.674\n",
      "Episode 2887 finished after 3001 timesteps\n",
      "Total reward: 11504.358329511517, Epsilon: 0.674\n",
      "Episode 2888 finished after 2077 timesteps\n",
      "Total reward: 10914.268212196963, Epsilon: 0.674\n",
      "Episode 2889 finished after 3001 timesteps\n",
      "Total reward: 14029.483637471933, Epsilon: 0.674\n",
      "Episode 2890 finished after 1865 timesteps\n",
      "Total reward: 11117.459653529408, Epsilon: 0.674\n",
      "Episode 2891 finished after 275 timesteps\n",
      "Total reward: 2859.7348240461506, Epsilon: 0.674\n",
      "Episode 2892 finished after 3001 timesteps\n",
      "Total reward: 14785.309934592893, Epsilon: 0.674\n",
      "Episode 2893 finished after 645 timesteps\n",
      "Total reward: 4530.637360397928, Epsilon: 0.674\n",
      "Episode 2894 finished after 3001 timesteps\n",
      "Total reward: 14720.458765447762, Epsilon: 0.674\n",
      "Episode 2895 finished after 3001 timesteps\n",
      "Total reward: 16977.585496521024, Epsilon: 0.674\n",
      "Episode 2896 finished after 3001 timesteps\n",
      "Total reward: 13202.972851170594, Epsilon: 0.674\n",
      "Episode 2897 finished after 2049 timesteps\n",
      "Total reward: 11107.897581321766, Epsilon: 0.674\n",
      "Episode 2898 finished after 3001 timesteps\n",
      "Total reward: 14115.434028040094, Epsilon: 0.673\n",
      "Episode 2899 finished after 789 timesteps\n",
      "Total reward: 4694.729287878649, Epsilon: 0.673\n",
      "Episode 2900 finished after 870 timesteps\n",
      "Total reward: 7207.742411402971, Epsilon: 0.673\n",
      "Episode 2901 finished after 3001 timesteps\n",
      "Total reward: 13531.093016566674, Epsilon: 0.673\n",
      "Episode 2902 finished after 344 timesteps\n",
      "Total reward: 3216.8772261855484, Epsilon: 0.673\n",
      "Episode 2903 finished after 730 timesteps\n",
      "Total reward: 5056.05766481179, Epsilon: 0.673\n",
      "Episode 2904 finished after 967 timesteps\n",
      "Total reward: 6394.184888434545, Epsilon: 0.673\n",
      "Episode 2905 finished after 2156 timesteps\n",
      "Total reward: 9954.610218085209, Epsilon: 0.673\n",
      "Episode 2906 finished after 554 timesteps\n",
      "Total reward: 5351.454755923258, Epsilon: 0.673\n",
      "Episode 2907 finished after 3001 timesteps\n",
      "Total reward: 14500.169302567427, Epsilon: 0.673\n",
      "Episode 2908 finished after 3001 timesteps\n",
      "Total reward: 13836.883310642395, Epsilon: 0.673\n",
      "Episode 2909 finished after 2300 timesteps\n",
      "Total reward: 14805.917361052207, Epsilon: 0.673\n",
      "Episode 2910 finished after 3001 timesteps\n",
      "Total reward: 12485.209299713504, Epsilon: 0.673\n",
      "Episode 2911 finished after 3001 timesteps\n",
      "Total reward: 13242.623685788245, Epsilon: 0.673\n",
      "Episode 2912 finished after 3001 timesteps\n",
      "Total reward: 17589.277248812912, Epsilon: 0.673\n",
      "Episode 2913 finished after 2789 timesteps\n",
      "Total reward: 13120.756528121807, Epsilon: 0.672\n",
      "Episode 2914 finished after 2354 timesteps\n",
      "Total reward: 13512.39563102957, Epsilon: 0.672\n",
      "Episode 2915 finished after 3001 timesteps\n",
      "Total reward: 14516.197150718735, Epsilon: 0.672\n",
      "Episode 2916 finished after 1261 timesteps\n",
      "Total reward: 9220.252163461439, Epsilon: 0.672\n",
      "Episode 2917 finished after 1112 timesteps\n",
      "Total reward: 6339.87771889611, Epsilon: 0.672\n",
      "Episode 2918 finished after 3001 timesteps\n",
      "Total reward: 16743.817710229923, Epsilon: 0.672\n",
      "Episode 2919 finished after 1824 timesteps\n",
      "Total reward: 9080.388269969802, Epsilon: 0.672\n",
      "Episode 2920 finished after 3001 timesteps\n",
      "Total reward: 16226.403137780322, Epsilon: 0.672\n",
      "Episode 2921 finished after 276 timesteps\n",
      "Total reward: 2542.5113236480574, Epsilon: 0.672\n",
      "Episode 2922 finished after 2216 timesteps\n",
      "Total reward: 12132.404422793445, Epsilon: 0.672\n",
      "Episode 2923 finished after 2595 timesteps\n",
      "Total reward: 12258.332651632116, Epsilon: 0.672\n",
      "Episode 2924 finished after 3001 timesteps\n",
      "Total reward: 19596.11940974818, Epsilon: 0.672\n",
      "Episode 2925 finished after 3001 timesteps\n",
      "Total reward: 14777.349607394472, Epsilon: 0.672\n",
      "Episode 2926 finished after 2767 timesteps\n",
      "Total reward: 15925.432282595139, Epsilon: 0.672\n",
      "Episode 2927 finished after 1522 timesteps\n",
      "Total reward: 8435.846532338688, Epsilon: 0.672\n",
      "Episode 2928 finished after 2749 timesteps\n",
      "Total reward: 13650.68674002375, Epsilon: 0.671\n",
      "Episode 2929 finished after 495 timesteps\n",
      "Total reward: 4892.839259338245, Epsilon: 0.671\n",
      "Episode 2930 finished after 879 timesteps\n",
      "Total reward: 5118.831121853403, Epsilon: 0.671\n",
      "Episode 2931 finished after 3001 timesteps\n",
      "Total reward: 12802.782338397585, Epsilon: 0.671\n",
      "Episode 2932 finished after 1603 timesteps\n",
      "Total reward: 7914.799367474444, Epsilon: 0.671\n",
      "Episode 2933 finished after 596 timesteps\n",
      "Total reward: 5065.744776120337, Epsilon: 0.671\n",
      "Episode 2934 finished after 2874 timesteps\n",
      "Total reward: 14503.738886837553, Epsilon: 0.671\n",
      "Episode 2935 finished after 3001 timesteps\n",
      "Total reward: 15358.598826788808, Epsilon: 0.671\n",
      "Episode 2936 finished after 1399 timesteps\n",
      "Total reward: 7066.459030021402, Epsilon: 0.671\n",
      "Episode 2937 finished after 2760 timesteps\n",
      "Total reward: 13835.13959655816, Epsilon: 0.671\n",
      "Episode 2938 finished after 3001 timesteps\n",
      "Total reward: 16676.869749248566, Epsilon: 0.671\n",
      "Episode 2939 finished after 1135 timesteps\n",
      "Total reward: 7561.141988494469, Epsilon: 0.671\n",
      "Episode 2940 finished after 676 timesteps\n",
      "Total reward: 5956.375027797105, Epsilon: 0.671\n",
      "Episode 2941 finished after 891 timesteps\n",
      "Total reward: 5363.792031689078, Epsilon: 0.671\n",
      "Episode 2942 finished after 601 timesteps\n",
      "Total reward: 4888.80619824771, Epsilon: 0.671\n",
      "Episode 2943 finished after 2036 timesteps\n",
      "Total reward: 11335.680317693874, Epsilon: 0.670\n",
      "Episode 2944 finished after 1424 timesteps\n",
      "Total reward: 7960.252242530884, Epsilon: 0.670\n",
      "Episode 2945 finished after 3001 timesteps\n",
      "Total reward: 14655.284491510081, Epsilon: 0.670\n",
      "Episode 2946 finished after 3001 timesteps\n",
      "Total reward: 14441.537109071336, Epsilon: 0.670\n",
      "Episode 2947 finished after 3001 timesteps\n",
      "Total reward: 13822.709944224085, Epsilon: 0.670\n",
      "Episode 2948 finished after 256 timesteps\n",
      "Total reward: 2420.8101519732586, Epsilon: 0.670\n",
      "Episode 2949 finished after 1148 timesteps\n",
      "Total reward: 6240.583281176884, Epsilon: 0.670\n",
      "Episode 2950 finished after 3001 timesteps\n",
      "Total reward: 13154.480192988725, Epsilon: 0.670\n",
      "Episode 2951 finished after 642 timesteps\n",
      "Total reward: 4359.08786525803, Epsilon: 0.670\n",
      "Episode 2952 finished after 580 timesteps\n",
      "Total reward: 3488.094053942282, Epsilon: 0.670\n",
      "Episode 2953 finished after 2952 timesteps\n",
      "Total reward: 19273.777271865227, Epsilon: 0.670\n",
      "Episode 2954 finished after 3001 timesteps\n",
      "Total reward: 13338.355179848546, Epsilon: 0.670\n",
      "Episode 2955 finished after 1706 timesteps\n",
      "Total reward: 9371.536879232273, Epsilon: 0.670\n",
      "Episode 2956 finished after 245 timesteps\n",
      "Total reward: 2642.8424449853715, Epsilon: 0.670\n",
      "Episode 2957 finished after 318 timesteps\n",
      "Total reward: 2797.5395223395267, Epsilon: 0.670\n",
      "Episode 2958 finished after 905 timesteps\n",
      "Total reward: 8082.925827956312, Epsilon: 0.669\n",
      "Episode 2959 finished after 3001 timesteps\n",
      "Total reward: 13797.474098128905, Epsilon: 0.669\n",
      "Episode 2960 finished after 3001 timesteps\n",
      "Total reward: 13943.174600728114, Epsilon: 0.669\n",
      "Episode 2961 finished after 2390 timesteps\n",
      "Total reward: 10496.45603645476, Epsilon: 0.669\n",
      "Episode 2962 finished after 1439 timesteps\n",
      "Total reward: 8728.498272875864, Epsilon: 0.669\n",
      "Episode 2963 finished after 886 timesteps\n",
      "Total reward: 5113.645668891996, Epsilon: 0.669\n",
      "Episode 2964 finished after 3001 timesteps\n",
      "Total reward: 14454.445832183492, Epsilon: 0.669\n",
      "Episode 2965 finished after 596 timesteps\n",
      "Total reward: 3770.26473649593, Epsilon: 0.669\n",
      "Episode 2966 finished after 1255 timesteps\n",
      "Total reward: 7740.974985714373, Epsilon: 0.669\n",
      "Episode 2967 finished after 2109 timesteps\n",
      "Total reward: 12871.339411888692, Epsilon: 0.669\n",
      "Episode 2968 finished after 1815 timesteps\n",
      "Total reward: 9171.130847143604, Epsilon: 0.669\n",
      "Episode 2969 finished after 3001 timesteps\n",
      "Total reward: 13212.638908949244, Epsilon: 0.669\n",
      "Episode 2970 finished after 1410 timesteps\n",
      "Total reward: 7776.867687264535, Epsilon: 0.669\n",
      "Episode 2971 finished after 822 timesteps\n",
      "Total reward: 6523.901338312771, Epsilon: 0.669\n",
      "Episode 2972 finished after 1652 timesteps\n",
      "Total reward: 11097.136760801057, Epsilon: 0.669\n",
      "Episode 2973 finished after 3001 timesteps\n",
      "Total reward: 17350.35219494828, Epsilon: 0.668\n",
      "Episode 2974 finished after 2657 timesteps\n",
      "Total reward: 15355.757055407215, Epsilon: 0.668\n",
      "Episode 2975 finished after 1159 timesteps\n",
      "Total reward: 6519.805115021542, Epsilon: 0.668\n",
      "Episode 2976 finished after 3001 timesteps\n",
      "Total reward: 13680.036111609326, Epsilon: 0.668\n",
      "Episode 2977 finished after 243 timesteps\n",
      "Total reward: 2609.2694191189066, Epsilon: 0.668\n",
      "Episode 2978 finished after 725 timesteps\n",
      "Total reward: 4247.405074787969, Epsilon: 0.668\n",
      "Episode 2979 finished after 3001 timesteps\n",
      "Total reward: 18236.976390398213, Epsilon: 0.668\n",
      "Episode 2980 finished after 959 timesteps\n",
      "Total reward: 5550.1296387733255, Epsilon: 0.668\n",
      "Episode 2981 finished after 372 timesteps\n",
      "Total reward: 2791.839630236031, Epsilon: 0.668\n",
      "Episode 2982 finished after 2074 timesteps\n",
      "Total reward: 10945.803947737211, Epsilon: 0.668\n",
      "Episode 2983 finished after 412 timesteps\n",
      "Total reward: 3212.2743684799007, Epsilon: 0.668\n",
      "Episode 2984 finished after 521 timesteps\n",
      "Total reward: 4264.344746637759, Epsilon: 0.668\n",
      "Episode 2985 finished after 3001 timesteps\n",
      "Total reward: 17546.30255215893, Epsilon: 0.668\n",
      "Episode 2986 finished after 820 timesteps\n",
      "Total reward: 5565.195883939252, Epsilon: 0.668\n",
      "Episode 2987 finished after 3001 timesteps\n",
      "Total reward: 16034.825300530956, Epsilon: 0.668\n",
      "Episode 2988 finished after 1552 timesteps\n",
      "Total reward: 9729.18946515759, Epsilon: 0.667\n",
      "Episode 2989 finished after 1350 timesteps\n",
      "Total reward: 8184.212970727358, Epsilon: 0.667\n",
      "Episode 2990 finished after 821 timesteps\n",
      "Total reward: 5903.894102522895, Epsilon: 0.667\n",
      "Episode 2991 finished after 606 timesteps\n",
      "Total reward: 4493.87483883426, Epsilon: 0.667\n",
      "Episode 2992 finished after 2231 timesteps\n",
      "Total reward: 15389.663100057129, Epsilon: 0.667\n",
      "Episode 2993 finished after 160 timesteps\n",
      "Total reward: 2148.147950409092, Epsilon: 0.667\n",
      "Episode 2994 finished after 2911 timesteps\n",
      "Total reward: 17756.173905328305, Epsilon: 0.667\n",
      "Episode 2995 finished after 1866 timesteps\n",
      "Total reward: 13696.312992525436, Epsilon: 0.667\n",
      "Episode 2996 finished after 1310 timesteps\n",
      "Total reward: 7663.4753998426995, Epsilon: 0.667\n",
      "Episode 2997 finished after 1451 timesteps\n",
      "Total reward: 7691.072581347411, Epsilon: 0.667\n",
      "Episode 2998 finished after 768 timesteps\n",
      "Total reward: 4728.706959588599, Epsilon: 0.667\n",
      "Episode 2999 finished after 3001 timesteps\n",
      "Total reward: 17159.275606212803, Epsilon: 0.667\n",
      "Episode 3000 finished after 3001 timesteps\n",
      "Total reward: 14185.026253189564, Epsilon: 0.667\n",
      "Episode 3001 finished after 2477 timesteps\n",
      "Total reward: 13851.252199772212, Epsilon: 0.667\n",
      "Episode 3002 finished after 3001 timesteps\n",
      "Total reward: 13872.027862457588, Epsilon: 0.667\n",
      "Episode 3003 finished after 1084 timesteps\n",
      "Total reward: 8233.949942310725, Epsilon: 0.666\n",
      "Episode 3004 finished after 3001 timesteps\n",
      "Total reward: 16909.698621517193, Epsilon: 0.666\n",
      "Episode 3005 finished after 3001 timesteps\n",
      "Total reward: 15722.634530718018, Epsilon: 0.666\n",
      "Episode 3006 finished after 2495 timesteps\n",
      "Total reward: 17141.75229001557, Epsilon: 0.666\n",
      "Episode 3007 finished after 306 timesteps\n",
      "Total reward: 2585.086245002244, Epsilon: 0.666\n",
      "Episode 3008 finished after 867 timesteps\n",
      "Total reward: 7284.644993261926, Epsilon: 0.666\n",
      "Episode 3009 finished after 1131 timesteps\n",
      "Total reward: 7318.457594150718, Epsilon: 0.666\n",
      "Episode 3010 finished after 1651 timesteps\n",
      "Total reward: 9521.188806016607, Epsilon: 0.666\n",
      "Episode 3011 finished after 1560 timesteps\n",
      "Total reward: 11333.906746904426, Epsilon: 0.666\n",
      "Episode 3012 finished after 3001 timesteps\n",
      "Total reward: 15450.061069826894, Epsilon: 0.666\n",
      "Episode 3013 finished after 2399 timesteps\n",
      "Total reward: 12808.614859871059, Epsilon: 0.666\n",
      "Episode 3014 finished after 116 timesteps\n",
      "Total reward: 1495.501201631699, Epsilon: 0.666\n",
      "Episode 3015 finished after 2926 timesteps\n",
      "Total reward: 13795.179226114928, Epsilon: 0.666\n",
      "Episode 3016 finished after 3001 timesteps\n",
      "Total reward: 14268.958121330807, Epsilon: 0.666\n",
      "Episode 3017 finished after 314 timesteps\n",
      "Total reward: 3236.325185994631, Epsilon: 0.666\n",
      "Episode 3018 finished after 1379 timesteps\n",
      "Total reward: 10241.70595399374, Epsilon: 0.665\n",
      "Episode 3019 finished after 3001 timesteps\n",
      "Total reward: 12368.015484526057, Epsilon: 0.665\n",
      "Episode 3020 finished after 1978 timesteps\n",
      "Total reward: 10431.125423796326, Epsilon: 0.665\n",
      "Episode 3021 finished after 1766 timesteps\n",
      "Total reward: 10017.949757361086, Epsilon: 0.665\n",
      "Episode 3022 finished after 1323 timesteps\n",
      "Total reward: 8702.02274762416, Epsilon: 0.665\n",
      "Episode 3023 finished after 972 timesteps\n",
      "Total reward: 5019.446295641911, Epsilon: 0.665\n",
      "Episode 3024 finished after 1693 timesteps\n",
      "Total reward: 10518.934158707123, Epsilon: 0.665\n",
      "Episode 3025 finished after 2893 timesteps\n",
      "Total reward: 16616.360758235125, Epsilon: 0.665\n",
      "Episode 3026 finished after 3001 timesteps\n",
      "Total reward: 13071.365854781961, Epsilon: 0.665\n",
      "Episode 3027 finished after 223 timesteps\n",
      "Total reward: 2121.460893069824, Epsilon: 0.665\n",
      "Episode 3028 finished after 3001 timesteps\n",
      "Total reward: 12214.141162537913, Epsilon: 0.665\n",
      "Episode 3029 finished after 695 timesteps\n",
      "Total reward: 4489.47995523256, Epsilon: 0.665\n",
      "Episode 3030 finished after 1546 timesteps\n",
      "Total reward: 6962.451564669724, Epsilon: 0.665\n",
      "Episode 3031 finished after 2202 timesteps\n",
      "Total reward: 13066.879291849795, Epsilon: 0.665\n",
      "Episode 3032 finished after 1395 timesteps\n",
      "Total reward: 7482.427358730029, Epsilon: 0.665\n",
      "Episode 3033 finished after 3001 timesteps\n",
      "Total reward: 14434.26399214756, Epsilon: 0.664\n",
      "Episode 3034 finished after 1671 timesteps\n",
      "Total reward: 8003.002498704631, Epsilon: 0.664\n",
      "Episode 3035 finished after 3001 timesteps\n",
      "Total reward: 16773.345521403273, Epsilon: 0.664\n",
      "Episode 3036 finished after 1830 timesteps\n",
      "Total reward: 9737.98304211773, Epsilon: 0.664\n",
      "Episode 3037 finished after 3001 timesteps\n",
      "Total reward: 14937.178642549923, Epsilon: 0.664\n",
      "Episode 3038 finished after 522 timesteps\n",
      "Total reward: 3841.4266082523004, Epsilon: 0.664\n",
      "Episode 3039 finished after 2200 timesteps\n",
      "Total reward: 11912.829168429733, Epsilon: 0.664\n",
      "Episode 3040 finished after 1374 timesteps\n",
      "Total reward: 7865.211447481808, Epsilon: 0.664\n",
      "Episode 3041 finished after 117 timesteps\n",
      "Total reward: 1547.7105562040229, Epsilon: 0.664\n",
      "Episode 3042 finished after 1292 timesteps\n",
      "Total reward: 11019.409423068408, Epsilon: 0.664\n",
      "Episode 3043 finished after 3001 timesteps\n",
      "Total reward: 14709.578130121901, Epsilon: 0.664\n",
      "Episode 3044 finished after 1842 timesteps\n",
      "Total reward: 10506.573737838939, Epsilon: 0.664\n",
      "Episode 3045 finished after 3001 timesteps\n",
      "Total reward: 15423.74526024945, Epsilon: 0.664\n",
      "Episode 3046 finished after 2339 timesteps\n",
      "Total reward: 13608.384839536282, Epsilon: 0.664\n",
      "Episode 3047 finished after 3001 timesteps\n",
      "Total reward: 15517.70098923082, Epsilon: 0.664\n",
      "Episode 3048 finished after 3001 timesteps\n",
      "Total reward: 17334.874201873263, Epsilon: 0.663\n",
      "Episode 3049 finished after 2835 timesteps\n",
      "Total reward: 14613.505366875168, Epsilon: 0.663\n",
      "Episode 3050 finished after 3001 timesteps\n",
      "Total reward: 15025.82650823642, Epsilon: 0.663\n",
      "Episode 3051 finished after 3001 timesteps\n",
      "Total reward: 14667.178146565891, Epsilon: 0.663\n",
      "Episode 3052 finished after 1963 timesteps\n",
      "Total reward: 9670.566619060577, Epsilon: 0.663\n",
      "Episode 3053 finished after 1675 timesteps\n",
      "Total reward: 9479.179677831326, Epsilon: 0.663\n",
      "Episode 3054 finished after 3001 timesteps\n",
      "Total reward: 17481.216808519905, Epsilon: 0.663\n",
      "Episode 3055 finished after 2109 timesteps\n",
      "Total reward: 13293.311842452224, Epsilon: 0.663\n",
      "Episode 3056 finished after 3001 timesteps\n",
      "Total reward: 13570.230846907594, Epsilon: 0.663\n",
      "Episode 3057 finished after 3001 timesteps\n",
      "Total reward: 13094.020137437732, Epsilon: 0.663\n",
      "Episode 3058 finished after 340 timesteps\n",
      "Total reward: 2801.3726958976727, Epsilon: 0.663\n",
      "Episode 3059 finished after 547 timesteps\n",
      "Total reward: 3867.344102994438, Epsilon: 0.663\n",
      "Episode 3060 finished after 2114 timesteps\n",
      "Total reward: 11121.145114515455, Epsilon: 0.663\n",
      "Episode 3061 finished after 3001 timesteps\n",
      "Total reward: 14375.663390505908, Epsilon: 0.663\n",
      "Episode 3062 finished after 3001 timesteps\n",
      "Total reward: 14273.194888832264, Epsilon: 0.663\n",
      "Episode 3063 finished after 1228 timesteps\n",
      "Total reward: 10954.919807231472, Epsilon: 0.662\n",
      "Episode 3064 finished after 381 timesteps\n",
      "Total reward: 2776.327046989013, Epsilon: 0.662\n",
      "Episode 3065 finished after 3001 timesteps\n",
      "Total reward: 13393.361750188189, Epsilon: 0.662\n",
      "Episode 3066 finished after 3001 timesteps\n",
      "Total reward: 14459.647480132704, Epsilon: 0.662\n",
      "Episode 3067 finished after 681 timesteps\n",
      "Total reward: 5164.318761949892, Epsilon: 0.662\n",
      "Episode 3068 finished after 2748 timesteps\n",
      "Total reward: 15811.583433051277, Epsilon: 0.662\n",
      "Episode 3069 finished after 739 timesteps\n",
      "Total reward: 6065.210698641389, Epsilon: 0.662\n",
      "Episode 3070 finished after 1112 timesteps\n",
      "Total reward: 6630.823802606258, Epsilon: 0.662\n",
      "Episode 3071 finished after 2406 timesteps\n",
      "Total reward: 14107.243381086038, Epsilon: 0.662\n",
      "Episode 3072 finished after 1132 timesteps\n",
      "Total reward: 6113.302418070768, Epsilon: 0.662\n",
      "Episode 3073 finished after 866 timesteps\n",
      "Total reward: 4767.119840364709, Epsilon: 0.662\n",
      "Episode 3074 finished after 406 timesteps\n",
      "Total reward: 3404.774643439553, Epsilon: 0.662\n",
      "Episode 3075 finished after 2588 timesteps\n",
      "Total reward: 15576.92058819204, Epsilon: 0.662\n",
      "Episode 3076 finished after 668 timesteps\n",
      "Total reward: 5328.559340938145, Epsilon: 0.662\n",
      "Episode 3077 finished after 3001 timesteps\n",
      "Total reward: 14385.190769931762, Epsilon: 0.662\n",
      "Episode 3078 finished after 1940 timesteps\n",
      "Total reward: 11855.606163154245, Epsilon: 0.661\n",
      "Episode 3079 finished after 351 timesteps\n",
      "Total reward: 2329.7680161486446, Epsilon: 0.661\n",
      "Episode 3080 finished after 271 timesteps\n",
      "Total reward: 2514.6156929411136, Epsilon: 0.661\n",
      "Episode 3081 finished after 3001 timesteps\n",
      "Total reward: 17159.0314720629, Epsilon: 0.661\n",
      "Episode 3082 finished after 2593 timesteps\n",
      "Total reward: 15601.847376690368, Epsilon: 0.661\n",
      "Episode 3083 finished after 2062 timesteps\n",
      "Total reward: 11308.97012101998, Epsilon: 0.661\n",
      "Episode 3084 finished after 3001 timesteps\n",
      "Total reward: 15832.591119917812, Epsilon: 0.661\n",
      "Episode 3085 finished after 888 timesteps\n",
      "Total reward: 7325.174937162401, Epsilon: 0.661\n",
      "Episode 3086 finished after 2557 timesteps\n",
      "Total reward: 18113.021445721657, Epsilon: 0.661\n",
      "Episode 3087 finished after 2802 timesteps\n",
      "Total reward: 13871.923187218437, Epsilon: 0.661\n",
      "Episode 3088 finished after 3001 timesteps\n",
      "Total reward: 18263.07944822616, Epsilon: 0.661\n",
      "Episode 3089 finished after 906 timesteps\n",
      "Total reward: 7075.450709142114, Epsilon: 0.661\n",
      "Episode 3090 finished after 3001 timesteps\n",
      "Total reward: 17160.287223150714, Epsilon: 0.661\n",
      "Episode 3091 finished after 343 timesteps\n",
      "Total reward: 2433.8189177745985, Epsilon: 0.661\n",
      "Episode 3092 finished after 1096 timesteps\n",
      "Total reward: 7058.624433286359, Epsilon: 0.661\n",
      "Episode 3093 finished after 854 timesteps\n",
      "Total reward: 5483.784426027741, Epsilon: 0.660\n",
      "Episode 3094 finished after 1048 timesteps\n",
      "Total reward: 8458.384593720764, Epsilon: 0.660\n",
      "Episode 3095 finished after 2032 timesteps\n",
      "Total reward: 11920.31548154163, Epsilon: 0.660\n",
      "Episode 3096 finished after 2283 timesteps\n",
      "Total reward: 12317.500102998894, Epsilon: 0.660\n",
      "Episode 3097 finished after 1803 timesteps\n",
      "Total reward: 11762.143190765528, Epsilon: 0.660\n",
      "Episode 3098 finished after 2869 timesteps\n",
      "Total reward: 17407.613190964516, Epsilon: 0.660\n",
      "Episode 3099 finished after 3001 timesteps\n",
      "Total reward: 17288.002395860058, Epsilon: 0.660\n",
      "Episode 3100 finished after 1668 timesteps\n",
      "Total reward: 8202.284893810065, Epsilon: 0.660\n",
      "Episode 3101 finished after 2332 timesteps\n",
      "Total reward: 12573.278840748435, Epsilon: 0.660\n",
      "Episode 3102 finished after 377 timesteps\n",
      "Total reward: 3210.9083329189993, Epsilon: 0.660\n",
      "Episode 3103 finished after 768 timesteps\n",
      "Total reward: 4560.203079151055, Epsilon: 0.660\n",
      "Episode 3104 finished after 3001 timesteps\n",
      "Total reward: 13601.436011762638, Epsilon: 0.660\n",
      "Episode 3105 finished after 1181 timesteps\n",
      "Total reward: 10348.75717581895, Epsilon: 0.660\n",
      "Episode 3106 finished after 854 timesteps\n",
      "Total reward: 5413.72410794101, Epsilon: 0.660\n",
      "Episode 3107 finished after 380 timesteps\n",
      "Total reward: 2519.904380750322, Epsilon: 0.660\n",
      "Episode 3108 finished after 1461 timesteps\n",
      "Total reward: 7685.277195255722, Epsilon: 0.659\n",
      "Episode 3109 finished after 1441 timesteps\n",
      "Total reward: 6611.13318785506, Epsilon: 0.659\n",
      "Episode 3110 finished after 2168 timesteps\n",
      "Total reward: 11592.429683560646, Epsilon: 0.659\n",
      "Episode 3111 finished after 551 timesteps\n",
      "Total reward: 4435.8200212011, Epsilon: 0.659\n",
      "Episode 3112 finished after 2054 timesteps\n",
      "Total reward: 11999.314556528567, Epsilon: 0.659\n",
      "Episode 3113 finished after 2750 timesteps\n",
      "Total reward: 13768.17770250348, Epsilon: 0.659\n",
      "Episode 3114 finished after 3001 timesteps\n",
      "Total reward: 16660.02676250638, Epsilon: 0.659\n",
      "Episode 3115 finished after 2027 timesteps\n",
      "Total reward: 13326.50920347043, Epsilon: 0.659\n",
      "Episode 3116 finished after 1188 timesteps\n",
      "Total reward: 6625.476433525171, Epsilon: 0.659\n",
      "Episode 3117 finished after 2519 timesteps\n",
      "Total reward: 17963.424472362083, Epsilon: 0.659\n",
      "Episode 3118 finished after 2554 timesteps\n",
      "Total reward: 14188.5598703184, Epsilon: 0.659\n",
      "Episode 3119 finished after 3001 timesteps\n",
      "Total reward: 12028.936365376825, Epsilon: 0.659\n",
      "Episode 3120 finished after 3001 timesteps\n",
      "Total reward: 14754.026271989582, Epsilon: 0.659\n",
      "Episode 3121 finished after 3001 timesteps\n",
      "Total reward: 14349.171037374095, Epsilon: 0.659\n",
      "Episode 3122 finished after 1381 timesteps\n",
      "Total reward: 11227.868355759465, Epsilon: 0.659\n",
      "Episode 3123 finished after 2776 timesteps\n",
      "Total reward: 14588.137115135407, Epsilon: 0.659\n",
      "Episode 3124 finished after 3001 timesteps\n",
      "Total reward: 15223.91183850537, Epsilon: 0.658\n",
      "Episode 3125 finished after 1553 timesteps\n",
      "Total reward: 7789.163144513898, Epsilon: 0.658\n",
      "Episode 3126 finished after 1358 timesteps\n",
      "Total reward: 8092.1800949112585, Epsilon: 0.658\n",
      "Episode 3127 finished after 3001 timesteps\n",
      "Total reward: 13116.531229658787, Epsilon: 0.658\n",
      "Episode 3128 finished after 1710 timesteps\n",
      "Total reward: 9864.060115746901, Epsilon: 0.658\n",
      "Episode 3129 finished after 3001 timesteps\n",
      "Total reward: 15853.57381415686, Epsilon: 0.658\n",
      "Episode 3130 finished after 622 timesteps\n",
      "Total reward: 4299.893301631255, Epsilon: 0.658\n",
      "Episode 3131 finished after 3001 timesteps\n",
      "Total reward: 12168.67463092901, Epsilon: 0.658\n",
      "Episode 3132 finished after 3001 timesteps\n",
      "Total reward: 16069.246490817859, Epsilon: 0.658\n",
      "Episode 3133 finished after 3001 timesteps\n",
      "Total reward: 14269.08171495851, Epsilon: 0.658\n",
      "Episode 3134 finished after 860 timesteps\n",
      "Total reward: 4770.892090157546, Epsilon: 0.658\n",
      "Episode 3135 finished after 2505 timesteps\n",
      "Total reward: 15802.38678184273, Epsilon: 0.658\n",
      "Episode 3136 finished after 3001 timesteps\n",
      "Total reward: 13030.255552796372, Epsilon: 0.658\n",
      "Episode 3137 finished after 1671 timesteps\n",
      "Total reward: 9792.718061868118, Epsilon: 0.658\n",
      "Episode 3138 finished after 1022 timesteps\n",
      "Total reward: 5075.127648155246, Epsilon: 0.658\n",
      "Episode 3139 finished after 3001 timesteps\n",
      "Total reward: 19344.659831591423, Epsilon: 0.657\n",
      "Episode 3140 finished after 1955 timesteps\n",
      "Total reward: 9408.847778216332, Epsilon: 0.657\n",
      "Episode 3141 finished after 565 timesteps\n",
      "Total reward: 4347.106038422823, Epsilon: 0.657\n",
      "Episode 3142 finished after 2108 timesteps\n",
      "Total reward: 11305.489356934087, Epsilon: 0.657\n",
      "Episode 3143 finished after 1535 timesteps\n",
      "Total reward: 8284.88719782762, Epsilon: 0.657\n",
      "Episode 3144 finished after 2565 timesteps\n",
      "Total reward: 11821.739338248974, Epsilon: 0.657\n",
      "Episode 3145 finished after 1626 timesteps\n",
      "Total reward: 9045.577540043407, Epsilon: 0.657\n",
      "Episode 3146 finished after 772 timesteps\n",
      "Total reward: 4578.813759076002, Epsilon: 0.657\n",
      "Episode 3147 finished after 1876 timesteps\n",
      "Total reward: 11011.562533692417, Epsilon: 0.657\n",
      "Episode 3148 finished after 3001 timesteps\n",
      "Total reward: 14257.896859789305, Epsilon: 0.657\n",
      "Episode 3149 finished after 2826 timesteps\n",
      "Total reward: 15525.450718676686, Epsilon: 0.657\n",
      "Episode 3150 finished after 3001 timesteps\n",
      "Total reward: 16048.582131279256, Epsilon: 0.657\n",
      "Episode 3151 finished after 3001 timesteps\n",
      "Total reward: 18204.81931524121, Epsilon: 0.657\n",
      "Episode 3152 finished after 450 timesteps\n",
      "Total reward: 3937.9258185279164, Epsilon: 0.657\n",
      "Episode 3153 finished after 3001 timesteps\n",
      "Total reward: 14921.736345578463, Epsilon: 0.657\n",
      "Episode 3154 finished after 1548 timesteps\n",
      "Total reward: 8122.452441011916, Epsilon: 0.656\n",
      "Episode 3155 finished after 3001 timesteps\n",
      "Total reward: 14676.940688537781, Epsilon: 0.656\n",
      "Episode 3156 finished after 449 timesteps\n",
      "Total reward: 3319.337478588826, Epsilon: 0.656\n",
      "Episode 3157 finished after 881 timesteps\n",
      "Total reward: 5334.016242484378, Epsilon: 0.656\n",
      "Episode 3158 finished after 1089 timesteps\n",
      "Total reward: 6575.843439897254, Epsilon: 0.656\n",
      "Episode 3159 finished after 492 timesteps\n",
      "Total reward: 4557.0046658231, Epsilon: 0.656\n",
      "Episode 3160 finished after 390 timesteps\n",
      "Total reward: 3851.436826433329, Epsilon: 0.656\n",
      "Episode 3161 finished after 3001 timesteps\n",
      "Total reward: 13296.72294834354, Epsilon: 0.656\n",
      "Episode 3162 finished after 2345 timesteps\n",
      "Total reward: 12721.04553438123, Epsilon: 0.656\n",
      "Episode 3163 finished after 795 timesteps\n",
      "Total reward: 4373.768496773845, Epsilon: 0.656\n",
      "Episode 3164 finished after 1305 timesteps\n",
      "Total reward: 7267.072489946699, Epsilon: 0.656\n",
      "Episode 3165 finished after 1561 timesteps\n",
      "Total reward: 9777.98527982472, Epsilon: 0.656\n",
      "Episode 3166 finished after 3001 timesteps\n",
      "Total reward: 12822.941572016549, Epsilon: 0.656\n",
      "Episode 3167 finished after 1092 timesteps\n",
      "Total reward: 6690.53649925892, Epsilon: 0.656\n",
      "Episode 3168 finished after 2392 timesteps\n",
      "Total reward: 12535.616045879235, Epsilon: 0.656\n",
      "Episode 3169 finished after 2093 timesteps\n",
      "Total reward: 11209.550339134285, Epsilon: 0.655\n",
      "Episode 3170 finished after 1226 timesteps\n",
      "Total reward: 7379.3392383507235, Epsilon: 0.655\n",
      "Episode 3171 finished after 1860 timesteps\n",
      "Total reward: 12064.799908186695, Epsilon: 0.655\n",
      "Episode 3172 finished after 3001 timesteps\n",
      "Total reward: 14892.988140410012, Epsilon: 0.655\n",
      "Episode 3173 finished after 1282 timesteps\n",
      "Total reward: 8817.186392963222, Epsilon: 0.655\n",
      "Episode 3174 finished after 2496 timesteps\n",
      "Total reward: 12763.961879661181, Epsilon: 0.655\n",
      "Episode 3175 finished after 3001 timesteps\n",
      "Total reward: 13361.479655549925, Epsilon: 0.655\n",
      "Episode 3176 finished after 725 timesteps\n",
      "Total reward: 4057.885361430265, Epsilon: 0.655\n",
      "Episode 3177 finished after 976 timesteps\n",
      "Total reward: 5894.868715402305, Epsilon: 0.655\n",
      "Episode 3178 finished after 1051 timesteps\n",
      "Total reward: 5853.043842327716, Epsilon: 0.655\n",
      "Episode 3179 finished after 704 timesteps\n",
      "Total reward: 5908.460693918435, Epsilon: 0.655\n",
      "Episode 3180 finished after 2560 timesteps\n",
      "Total reward: 13235.62846324642, Epsilon: 0.655\n",
      "Episode 3181 finished after 1363 timesteps\n",
      "Total reward: 7857.6622804629715, Epsilon: 0.655\n",
      "Episode 3182 finished after 1327 timesteps\n",
      "Total reward: 6642.3612562844855, Epsilon: 0.655\n",
      "Episode 3183 finished after 3001 timesteps\n",
      "Total reward: 19981.04001640385, Epsilon: 0.655\n",
      "Episode 3184 finished after 1891 timesteps\n",
      "Total reward: 13102.125417838752, Epsilon: 0.655\n",
      "Episode 3185 finished after 1694 timesteps\n",
      "Total reward: 8633.659508410858, Epsilon: 0.654\n",
      "Episode 3186 finished after 2349 timesteps\n",
      "Total reward: 15346.76429110034, Epsilon: 0.654\n",
      "Episode 3187 finished after 3001 timesteps\n",
      "Total reward: 14012.282616337998, Epsilon: 0.654\n",
      "Episode 3188 finished after 1088 timesteps\n",
      "Total reward: 8007.2703437394875, Epsilon: 0.654\n",
      "Episode 3189 finished after 2707 timesteps\n",
      "Total reward: 15973.24199268949, Epsilon: 0.654\n",
      "Episode 3190 finished after 639 timesteps\n",
      "Total reward: 4720.173445023827, Epsilon: 0.654\n",
      "Episode 3191 finished after 2572 timesteps\n",
      "Total reward: 14517.011356421186, Epsilon: 0.654\n",
      "Episode 3192 finished after 1214 timesteps\n",
      "Total reward: 6663.410022097159, Epsilon: 0.654\n",
      "Episode 3193 finished after 2363 timesteps\n",
      "Total reward: 13194.879742472709, Epsilon: 0.654\n",
      "Episode 3194 finished after 1607 timesteps\n",
      "Total reward: 8520.103333505896, Epsilon: 0.654\n",
      "Episode 3195 finished after 2624 timesteps\n",
      "Total reward: 14164.324371207294, Epsilon: 0.654\n",
      "Episode 3196 finished after 2317 timesteps\n",
      "Total reward: 14584.987070748677, Epsilon: 0.654\n",
      "Episode 3197 finished after 879 timesteps\n",
      "Total reward: 5955.337430036577, Epsilon: 0.654\n",
      "Episode 3198 finished after 1924 timesteps\n",
      "Total reward: 13194.435324296359, Epsilon: 0.654\n",
      "Episode 3199 finished after 714 timesteps\n",
      "Total reward: 5112.188944485281, Epsilon: 0.654\n",
      "Episode 3200 finished after 807 timesteps\n",
      "Total reward: 6178.148567638177, Epsilon: 0.653\n",
      "Episode 3201 finished after 1622 timesteps\n",
      "Total reward: 9470.3685978534, Epsilon: 0.653\n",
      "Episode 3202 finished after 2486 timesteps\n",
      "Total reward: 12580.232317610546, Epsilon: 0.653\n",
      "Episode 3203 finished after 1004 timesteps\n",
      "Total reward: 7399.3708242468465, Epsilon: 0.653\n",
      "Episode 3204 finished after 3001 timesteps\n",
      "Total reward: 14655.533226454654, Epsilon: 0.653\n",
      "Episode 3205 finished after 1517 timesteps\n",
      "Total reward: 10191.954089161267, Epsilon: 0.653\n",
      "Episode 3206 finished after 3001 timesteps\n",
      "Total reward: 15016.554914156904, Epsilon: 0.653\n",
      "Episode 3207 finished after 1481 timesteps\n",
      "Total reward: 9767.962985957474, Epsilon: 0.653\n",
      "Episode 3208 finished after 2362 timesteps\n",
      "Total reward: 11901.925531742172, Epsilon: 0.653\n",
      "Episode 3209 finished after 3001 timesteps\n",
      "Total reward: 15582.039038267005, Epsilon: 0.653\n",
      "Episode 3210 finished after 1213 timesteps\n",
      "Total reward: 7128.144938094421, Epsilon: 0.653\n",
      "Episode 3211 finished after 2839 timesteps\n",
      "Total reward: 14473.53952932164, Epsilon: 0.653\n",
      "Episode 3212 finished after 3001 timesteps\n",
      "Total reward: 12414.439614723186, Epsilon: 0.653\n",
      "Episode 3213 finished after 1593 timesteps\n",
      "Total reward: 12453.077277323377, Epsilon: 0.653\n",
      "Episode 3214 finished after 3001 timesteps\n",
      "Total reward: 13480.27201714952, Epsilon: 0.653\n",
      "Episode 3215 finished after 3001 timesteps\n",
      "Total reward: 14722.84012900152, Epsilon: 0.652\n",
      "Episode 3216 finished after 2269 timesteps\n",
      "Total reward: 11544.21940168052, Epsilon: 0.652\n",
      "Episode 3217 finished after 407 timesteps\n",
      "Total reward: 2999.805123798826, Epsilon: 0.652\n",
      "Episode 3218 finished after 3001 timesteps\n",
      "Total reward: 17017.786742469198, Epsilon: 0.652\n",
      "Episode 3219 finished after 2218 timesteps\n",
      "Total reward: 11541.460502583852, Epsilon: 0.652\n",
      "Episode 3220 finished after 1200 timesteps\n",
      "Total reward: 7200.54848614619, Epsilon: 0.652\n",
      "Episode 3221 finished after 3001 timesteps\n",
      "Total reward: 13585.989030802719, Epsilon: 0.652\n",
      "Episode 3222 finished after 2410 timesteps\n",
      "Total reward: 11869.73674628496, Epsilon: 0.652\n",
      "Episode 3223 finished after 2823 timesteps\n",
      "Total reward: 13289.744407092105, Epsilon: 0.652\n",
      "Episode 3224 finished after 571 timesteps\n",
      "Total reward: 4699.902407112168, Epsilon: 0.652\n",
      "Episode 3225 finished after 1475 timesteps\n",
      "Total reward: 7602.755230428025, Epsilon: 0.652\n",
      "Episode 3226 finished after 763 timesteps\n",
      "Total reward: 5046.920481808066, Epsilon: 0.652\n",
      "Episode 3227 finished after 2482 timesteps\n",
      "Total reward: 13057.004872904727, Epsilon: 0.652\n",
      "Episode 3228 finished after 1825 timesteps\n",
      "Total reward: 10436.122072594999, Epsilon: 0.652\n",
      "Episode 3229 finished after 755 timesteps\n",
      "Total reward: 5009.151614610214, Epsilon: 0.652\n",
      "Episode 3230 finished after 593 timesteps\n",
      "Total reward: 3869.569891850181, Epsilon: 0.652\n",
      "Episode 3231 finished after 338 timesteps\n",
      "Total reward: 3887.290177408295, Epsilon: 0.651\n",
      "Episode 3232 finished after 462 timesteps\n",
      "Total reward: 2759.3314373263456, Epsilon: 0.651\n",
      "Episode 3233 finished after 1813 timesteps\n",
      "Total reward: 11393.77136895988, Epsilon: 0.651\n",
      "Episode 3234 finished after 1192 timesteps\n",
      "Total reward: 8665.306357857937, Epsilon: 0.651\n",
      "Episode 3235 finished after 686 timesteps\n",
      "Total reward: 5955.564391085583, Epsilon: 0.651\n",
      "Episode 3236 finished after 617 timesteps\n",
      "Total reward: 4806.626757169105, Epsilon: 0.651\n",
      "Episode 3237 finished after 2598 timesteps\n",
      "Total reward: 11566.013306723355, Epsilon: 0.651\n",
      "Episode 3238 finished after 1717 timesteps\n",
      "Total reward: 10080.631628892826, Epsilon: 0.651\n",
      "Episode 3239 finished after 3001 timesteps\n",
      "Total reward: 16255.613601604478, Epsilon: 0.651\n",
      "Episode 3240 finished after 3001 timesteps\n",
      "Total reward: 16121.372803240049, Epsilon: 0.651\n",
      "Episode 3241 finished after 2028 timesteps\n",
      "Total reward: 15682.107912748044, Epsilon: 0.651\n",
      "Episode 3242 finished after 947 timesteps\n",
      "Total reward: 5992.9678837375695, Epsilon: 0.651\n",
      "Episode 3243 finished after 3001 timesteps\n",
      "Total reward: 13366.203526286363, Epsilon: 0.651\n",
      "Episode 3244 finished after 571 timesteps\n",
      "Total reward: 3880.955032835711, Epsilon: 0.651\n",
      "Episode 3245 finished after 2966 timesteps\n",
      "Total reward: 16205.523097844762, Epsilon: 0.651\n",
      "Episode 3246 finished after 2389 timesteps\n",
      "Total reward: 12193.64138725177, Epsilon: 0.650\n",
      "Episode 3247 finished after 537 timesteps\n",
      "Total reward: 4741.411644849582, Epsilon: 0.650\n",
      "Episode 3248 finished after 2516 timesteps\n",
      "Total reward: 14479.152391429947, Epsilon: 0.650\n",
      "Episode 3249 finished after 625 timesteps\n",
      "Total reward: 4473.844975850951, Epsilon: 0.650\n",
      "Episode 3250 finished after 887 timesteps\n",
      "Total reward: 5949.554970966682, Epsilon: 0.650\n",
      "Episode 3251 finished after 1157 timesteps\n",
      "Total reward: 7817.841984984024, Epsilon: 0.650\n",
      "Episode 3252 finished after 1751 timesteps\n",
      "Total reward: 9731.407291683203, Epsilon: 0.650\n",
      "Episode 3253 finished after 1465 timesteps\n",
      "Total reward: 8081.36668578432, Epsilon: 0.650\n",
      "Episode 3254 finished after 2828 timesteps\n",
      "Total reward: 18213.79683238973, Epsilon: 0.650\n",
      "Episode 3255 finished after 2634 timesteps\n",
      "Total reward: 15728.341593989588, Epsilon: 0.650\n",
      "Episode 3256 finished after 1264 timesteps\n",
      "Total reward: 7503.94685181997, Epsilon: 0.650\n",
      "Episode 3257 finished after 2527 timesteps\n",
      "Total reward: 15501.408699528136, Epsilon: 0.650\n",
      "Episode 3258 finished after 3001 timesteps\n",
      "Total reward: 15447.544133092382, Epsilon: 0.650\n",
      "Episode 3259 finished after 1587 timesteps\n",
      "Total reward: 8664.50232130592, Epsilon: 0.650\n",
      "Episode 3260 finished after 584 timesteps\n",
      "Total reward: 4964.13014592931, Epsilon: 0.650\n",
      "Episode 3261 finished after 3001 timesteps\n",
      "Total reward: 15082.186650712225, Epsilon: 0.649\n",
      "Episode 3262 finished after 1174 timesteps\n",
      "Total reward: 6376.503471887934, Epsilon: 0.649\n",
      "Episode 3263 finished after 1208 timesteps\n",
      "Total reward: 8021.165139579351, Epsilon: 0.649\n",
      "Episode 3264 finished after 2284 timesteps\n",
      "Total reward: 12861.38897125385, Epsilon: 0.649\n",
      "Episode 3265 finished after 3001 timesteps\n",
      "Total reward: 13481.149845319082, Epsilon: 0.649\n",
      "Episode 3266 finished after 1100 timesteps\n",
      "Total reward: 6122.360117188, Epsilon: 0.649\n",
      "Episode 3267 finished after 1482 timesteps\n",
      "Total reward: 8233.30540193118, Epsilon: 0.649\n",
      "Episode 3268 finished after 997 timesteps\n",
      "Total reward: 5733.530873288167, Epsilon: 0.649\n",
      "Episode 3269 finished after 3001 timesteps\n",
      "Total reward: 22550.69431490518, Epsilon: 0.649\n",
      "Episode 3270 finished after 482 timesteps\n",
      "Total reward: 4061.5042708687993, Epsilon: 0.649\n",
      "Episode 3271 finished after 3001 timesteps\n",
      "Total reward: 16759.967525547756, Epsilon: 0.649\n",
      "Episode 3272 finished after 2394 timesteps\n",
      "Total reward: 13964.66775587221, Epsilon: 0.649\n",
      "Episode 3273 finished after 348 timesteps\n",
      "Total reward: 3479.285784610971, Epsilon: 0.649\n",
      "Episode 3274 finished after 2290 timesteps\n",
      "Total reward: 14315.630487436627, Epsilon: 0.649\n",
      "Episode 3275 finished after 1335 timesteps\n",
      "Total reward: 7028.183990344645, Epsilon: 0.649\n",
      "Episode 3276 finished after 835 timesteps\n",
      "Total reward: 6604.700412709731, Epsilon: 0.649\n",
      "Episode 3277 finished after 2964 timesteps\n",
      "Total reward: 16651.101451942493, Epsilon: 0.648\n",
      "Episode 3278 finished after 1975 timesteps\n",
      "Total reward: 9429.064400157858, Epsilon: 0.648\n",
      "Episode 3279 finished after 2708 timesteps\n",
      "Total reward: 16169.17088566934, Epsilon: 0.648\n",
      "Episode 3280 finished after 655 timesteps\n",
      "Total reward: 3779.6148217188647, Epsilon: 0.648\n",
      "Episode 3281 finished after 1151 timesteps\n",
      "Total reward: 7682.863377746427, Epsilon: 0.648\n",
      "Episode 3282 finished after 1222 timesteps\n",
      "Total reward: 6864.347815301141, Epsilon: 0.648\n",
      "Episode 3283 finished after 3001 timesteps\n",
      "Total reward: 16802.097019248125, Epsilon: 0.648\n",
      "Episode 3284 finished after 561 timesteps\n",
      "Total reward: 3528.5887251178833, Epsilon: 0.648\n",
      "Episode 3285 finished after 1318 timesteps\n",
      "Total reward: 7612.513279018013, Epsilon: 0.648\n",
      "Episode 3286 finished after 3001 timesteps\n",
      "Total reward: 12385.337790077143, Epsilon: 0.648\n",
      "Episode 3287 finished after 1313 timesteps\n",
      "Total reward: 6939.506472277106, Epsilon: 0.648\n",
      "Episode 3288 finished after 2077 timesteps\n",
      "Total reward: 10699.924515468118, Epsilon: 0.648\n",
      "Episode 3289 finished after 2741 timesteps\n",
      "Total reward: 14399.211293556249, Epsilon: 0.648\n",
      "Episode 3290 finished after 674 timesteps\n",
      "Total reward: 3950.8485691016763, Epsilon: 0.648\n",
      "Episode 3291 finished after 1295 timesteps\n",
      "Total reward: 6387.322164565573, Epsilon: 0.648\n",
      "Episode 3292 finished after 3001 timesteps\n",
      "Total reward: 16183.772413666553, Epsilon: 0.647\n",
      "Episode 3293 finished after 2556 timesteps\n",
      "Total reward: 14502.843298830288, Epsilon: 0.647\n",
      "Episode 3294 finished after 3001 timesteps\n",
      "Total reward: 13426.764713510418, Epsilon: 0.647\n",
      "Episode 3295 finished after 3001 timesteps\n",
      "Total reward: 14869.60346453159, Epsilon: 0.647\n",
      "Episode 3296 finished after 330 timesteps\n",
      "Total reward: 2405.762521776981, Epsilon: 0.647\n",
      "Episode 3297 finished after 270 timesteps\n",
      "Total reward: 2384.305954344491, Epsilon: 0.647\n",
      "Episode 3298 finished after 1366 timesteps\n",
      "Total reward: 8139.815894400972, Epsilon: 0.647\n",
      "Episode 3299 finished after 755 timesteps\n",
      "Total reward: 4488.370663290505, Epsilon: 0.647\n",
      "Episode 3300 finished after 3001 timesteps\n",
      "Total reward: 14884.02279573279, Epsilon: 0.647\n",
      "Episode 3301 finished after 3001 timesteps\n",
      "Total reward: 12473.813837664233, Epsilon: 0.647\n",
      "Episode 3302 finished after 2664 timesteps\n",
      "Total reward: 12358.515541934341, Epsilon: 0.647\n",
      "Episode 3303 finished after 488 timesteps\n",
      "Total reward: 3460.636070496813, Epsilon: 0.647\n",
      "Episode 3304 finished after 3001 timesteps\n",
      "Total reward: 12743.648002922617, Epsilon: 0.647\n",
      "Episode 3305 finished after 3001 timesteps\n",
      "Total reward: 14073.440024355372, Epsilon: 0.647\n",
      "Episode 3306 finished after 1218 timesteps\n",
      "Total reward: 6224.846658411405, Epsilon: 0.647\n",
      "Episode 3307 finished after 797 timesteps\n",
      "Total reward: 6709.630381865266, Epsilon: 0.647\n",
      "Episode 3308 finished after 1142 timesteps\n",
      "Total reward: 8473.244690168507, Epsilon: 0.646\n",
      "Episode 3309 finished after 974 timesteps\n",
      "Total reward: 5638.12028200616, Epsilon: 0.646\n",
      "Episode 3310 finished after 3001 timesteps\n",
      "Total reward: 12811.751794451038, Epsilon: 0.646\n",
      "Episode 3311 finished after 1627 timesteps\n",
      "Total reward: 9449.056750421736, Epsilon: 0.646\n",
      "Episode 3312 finished after 3001 timesteps\n",
      "Total reward: 15767.070878449815, Epsilon: 0.646\n",
      "Episode 3313 finished after 325 timesteps\n",
      "Total reward: 2299.608715233117, Epsilon: 0.646\n",
      "Episode 3314 finished after 3001 timesteps\n",
      "Total reward: 14189.333828627767, Epsilon: 0.646\n",
      "Episode 3315 finished after 744 timesteps\n",
      "Total reward: 5094.756368691817, Epsilon: 0.646\n",
      "Episode 3316 finished after 2588 timesteps\n",
      "Total reward: 13737.662492695237, Epsilon: 0.646\n",
      "Episode 3317 finished after 1458 timesteps\n",
      "Total reward: 8877.579935021437, Epsilon: 0.646\n",
      "Episode 3318 finished after 3001 timesteps\n",
      "Total reward: 17545.988515340236, Epsilon: 0.646\n",
      "Episode 3319 finished after 2096 timesteps\n",
      "Total reward: 13049.233592414506, Epsilon: 0.646\n",
      "Episode 3320 finished after 3001 timesteps\n",
      "Total reward: 15297.227760744514, Epsilon: 0.646\n",
      "Episode 3321 finished after 2538 timesteps\n",
      "Total reward: 13984.462135929487, Epsilon: 0.646\n",
      "Episode 3322 finished after 1423 timesteps\n",
      "Total reward: 8620.14456980054, Epsilon: 0.646\n",
      "Episode 3323 finished after 2146 timesteps\n",
      "Total reward: 12052.883663877163, Epsilon: 0.645\n",
      "Episode 3324 finished after 3001 timesteps\n",
      "Total reward: 15120.142626449286, Epsilon: 0.645\n",
      "Episode 3325 finished after 3001 timesteps\n",
      "Total reward: 14788.586085537867, Epsilon: 0.645\n",
      "Episode 3326 finished after 3001 timesteps\n",
      "Total reward: 12955.498368509916, Epsilon: 0.645\n",
      "Episode 3327 finished after 1548 timesteps\n",
      "Total reward: 7871.047220728554, Epsilon: 0.645\n",
      "Episode 3328 finished after 2072 timesteps\n",
      "Total reward: 11111.91300220724, Epsilon: 0.645\n",
      "Episode 3329 finished after 3001 timesteps\n",
      "Total reward: 13677.732864992115, Epsilon: 0.645\n",
      "Episode 3330 finished after 791 timesteps\n",
      "Total reward: 6487.779197936176, Epsilon: 0.645\n",
      "Episode 3331 finished after 697 timesteps\n",
      "Total reward: 4047.157732629864, Epsilon: 0.645\n",
      "Episode 3332 finished after 927 timesteps\n",
      "Total reward: 6070.311588619345, Epsilon: 0.645\n",
      "Episode 3333 finished after 2075 timesteps\n",
      "Total reward: 9091.050169069415, Epsilon: 0.645\n",
      "Episode 3334 finished after 1099 timesteps\n",
      "Total reward: 7191.638389953526, Epsilon: 0.645\n",
      "Episode 3335 finished after 616 timesteps\n",
      "Total reward: 3901.615548791989, Epsilon: 0.645\n",
      "Episode 3336 finished after 3001 timesteps\n",
      "Total reward: 15763.07239246909, Epsilon: 0.645\n",
      "Episode 3337 finished after 540 timesteps\n",
      "Total reward: 3457.801572282476, Epsilon: 0.645\n",
      "Episode 3338 finished after 3001 timesteps\n",
      "Total reward: 16536.65601183579, Epsilon: 0.645\n",
      "Episode 3339 finished after 253 timesteps\n",
      "Total reward: 1950.0929312593141, Epsilon: 0.644\n",
      "Episode 3340 finished after 3001 timesteps\n",
      "Total reward: 13743.69181542565, Epsilon: 0.644\n",
      "Episode 3341 finished after 878 timesteps\n",
      "Total reward: 4873.882596450921, Epsilon: 0.644\n",
      "Episode 3342 finished after 1430 timesteps\n",
      "Total reward: 7267.208339095877, Epsilon: 0.644\n",
      "Episode 3343 finished after 3001 timesteps\n",
      "Total reward: 13702.540651042314, Epsilon: 0.644\n",
      "Episode 3344 finished after 2411 timesteps\n",
      "Total reward: 13085.526084682506, Epsilon: 0.644\n",
      "Episode 3345 finished after 683 timesteps\n",
      "Total reward: 4864.096502205916, Epsilon: 0.644\n",
      "Episode 3346 finished after 2973 timesteps\n",
      "Total reward: 16495.453083548473, Epsilon: 0.644\n",
      "Episode 3347 finished after 3001 timesteps\n",
      "Total reward: 15797.909954936453, Epsilon: 0.644\n",
      "Episode 3348 finished after 633 timesteps\n",
      "Total reward: 5379.557000871562, Epsilon: 0.644\n",
      "Episode 3349 finished after 566 timesteps\n",
      "Total reward: 4707.293229669139, Epsilon: 0.644\n",
      "Episode 3350 finished after 2898 timesteps\n",
      "Total reward: 14619.95645083365, Epsilon: 0.644\n",
      "Episode 3351 finished after 352 timesteps\n",
      "Total reward: 3381.210539505477, Epsilon: 0.644\n",
      "Episode 3352 finished after 3001 timesteps\n",
      "Total reward: 13315.167174424963, Epsilon: 0.644\n",
      "Episode 3353 finished after 815 timesteps\n",
      "Total reward: 5237.761645872131, Epsilon: 0.644\n",
      "Episode 3354 finished after 1421 timesteps\n",
      "Total reward: 7343.907123297338, Epsilon: 0.643\n",
      "Episode 3355 finished after 1010 timesteps\n",
      "Total reward: 6166.2126060041, Epsilon: 0.643\n",
      "Episode 3356 finished after 983 timesteps\n",
      "Total reward: 5270.5055709797925, Epsilon: 0.643\n",
      "Episode 3357 finished after 958 timesteps\n",
      "Total reward: 8086.89230808032, Epsilon: 0.643\n",
      "Episode 3358 finished after 1853 timesteps\n",
      "Total reward: 12244.362823960379, Epsilon: 0.643\n",
      "Episode 3359 finished after 3001 timesteps\n",
      "Total reward: 13468.966789563661, Epsilon: 0.643\n",
      "Episode 3360 finished after 937 timesteps\n",
      "Total reward: 6033.614889316893, Epsilon: 0.643\n",
      "Episode 3361 finished after 3001 timesteps\n",
      "Total reward: 14226.49817619977, Epsilon: 0.643\n",
      "Episode 3362 finished after 3001 timesteps\n",
      "Total reward: 13121.717762100669, Epsilon: 0.643\n",
      "Episode 3363 finished after 3001 timesteps\n",
      "Total reward: 13761.488505828544, Epsilon: 0.643\n",
      "Episode 3364 finished after 1202 timesteps\n",
      "Total reward: 7710.99090180364, Epsilon: 0.643\n",
      "Episode 3365 finished after 3001 timesteps\n",
      "Total reward: 13342.369299868398, Epsilon: 0.643\n",
      "Episode 3366 finished after 487 timesteps\n",
      "Total reward: 3219.0936770314956, Epsilon: 0.643\n",
      "Episode 3367 finished after 830 timesteps\n",
      "Total reward: 5621.569546977497, Epsilon: 0.643\n",
      "Episode 3368 finished after 3001 timesteps\n",
      "Total reward: 17011.296844019314, Epsilon: 0.643\n",
      "Episode 3369 finished after 3001 timesteps\n",
      "Total reward: 14201.311600353067, Epsilon: 0.643\n",
      "Episode 3370 finished after 1918 timesteps\n",
      "Total reward: 10092.146157019097, Epsilon: 0.642\n",
      "Episode 3371 finished after 2117 timesteps\n",
      "Total reward: 10016.874208113064, Epsilon: 0.642\n",
      "Episode 3372 finished after 700 timesteps\n",
      "Total reward: 5486.55808671377, Epsilon: 0.642\n",
      "Episode 3373 finished after 3001 timesteps\n",
      "Total reward: 13209.834102749131, Epsilon: 0.642\n",
      "Episode 3374 finished after 3001 timesteps\n",
      "Total reward: 18485.93170329966, Epsilon: 0.642\n",
      "Episode 3375 finished after 2469 timesteps\n",
      "Total reward: 14274.122080480278, Epsilon: 0.642\n",
      "Episode 3376 finished after 1802 timesteps\n",
      "Total reward: 9346.893029938261, Epsilon: 0.642\n",
      "Episode 3377 finished after 3001 timesteps\n",
      "Total reward: 12846.956070601254, Epsilon: 0.642\n",
      "Episode 3378 finished after 2945 timesteps\n",
      "Total reward: 17471.615307090527, Epsilon: 0.642\n",
      "Episode 3379 finished after 1604 timesteps\n",
      "Total reward: 9078.684820006802, Epsilon: 0.642\n",
      "Episode 3380 finished after 2289 timesteps\n",
      "Total reward: 12075.741535801071, Epsilon: 0.642\n",
      "Episode 3381 finished after 3001 timesteps\n",
      "Total reward: 14749.539366240077, Epsilon: 0.642\n",
      "Episode 3382 finished after 2947 timesteps\n",
      "Total reward: 22169.602404146313, Epsilon: 0.642\n",
      "Episode 3383 finished after 3001 timesteps\n",
      "Total reward: 14625.81633347591, Epsilon: 0.642\n",
      "Episode 3384 finished after 3001 timesteps\n",
      "Total reward: 14444.423292659636, Epsilon: 0.642\n",
      "Episode 3385 finished after 622 timesteps\n",
      "Total reward: 4771.666494502003, Epsilon: 0.641\n",
      "Episode 3386 finished after 1279 timesteps\n",
      "Total reward: 7639.205640556672, Epsilon: 0.641\n",
      "Episode 3387 finished after 3001 timesteps\n",
      "Total reward: 17778.133670452233, Epsilon: 0.641\n",
      "Episode 3388 finished after 1507 timesteps\n",
      "Total reward: 8980.767258859089, Epsilon: 0.641\n",
      "Episode 3389 finished after 3001 timesteps\n",
      "Total reward: 14763.938220543741, Epsilon: 0.641\n",
      "Episode 3390 finished after 1422 timesteps\n",
      "Total reward: 7977.755149864864, Epsilon: 0.641\n",
      "Episode 3391 finished after 1249 timesteps\n",
      "Total reward: 7084.42019888606, Epsilon: 0.641\n",
      "Episode 3392 finished after 3001 timesteps\n",
      "Total reward: 17394.768382343926, Epsilon: 0.641\n",
      "Episode 3393 finished after 450 timesteps\n",
      "Total reward: 3803.0208317125093, Epsilon: 0.641\n",
      "Episode 3394 finished after 1317 timesteps\n",
      "Total reward: 8366.244275478988, Epsilon: 0.641\n",
      "Episode 3395 finished after 950 timesteps\n",
      "Total reward: 4824.801296104632, Epsilon: 0.641\n",
      "Episode 3396 finished after 1009 timesteps\n",
      "Total reward: 6146.218595824384, Epsilon: 0.641\n",
      "Episode 3397 finished after 1572 timesteps\n",
      "Total reward: 9410.426874684797, Epsilon: 0.641\n",
      "Episode 3398 finished after 3001 timesteps\n",
      "Total reward: 16925.124609466664, Epsilon: 0.641\n",
      "Episode 3399 finished after 3001 timesteps\n",
      "Total reward: 13531.824845014002, Epsilon: 0.641\n",
      "Episode 3400 finished after 3001 timesteps\n",
      "Total reward: 14503.736062168522, Epsilon: 0.641\n",
      "Episode 3401 finished after 3001 timesteps\n",
      "Total reward: 14736.701564478657, Epsilon: 0.640\n",
      "Episode 3402 finished after 3001 timesteps\n",
      "Total reward: 17124.589612146072, Epsilon: 0.640\n",
      "Episode 3403 finished after 368 timesteps\n",
      "Total reward: 3079.7237520282324, Epsilon: 0.640\n",
      "Episode 3404 finished after 2596 timesteps\n",
      "Total reward: 12841.343572754193, Epsilon: 0.640\n",
      "Episode 3405 finished after 3001 timesteps\n",
      "Total reward: 15093.540909985368, Epsilon: 0.640\n",
      "Episode 3406 finished after 707 timesteps\n",
      "Total reward: 5111.335178507135, Epsilon: 0.640\n",
      "Episode 3407 finished after 3001 timesteps\n",
      "Total reward: 14022.291209908943, Epsilon: 0.640\n",
      "Episode 3408 finished after 1951 timesteps\n",
      "Total reward: 9516.688355727118, Epsilon: 0.640\n",
      "Episode 3409 finished after 1194 timesteps\n",
      "Total reward: 6278.274116272034, Epsilon: 0.640\n",
      "Episode 3410 finished after 3001 timesteps\n",
      "Total reward: 14638.124137518993, Epsilon: 0.640\n",
      "Episode 3411 finished after 1893 timesteps\n",
      "Total reward: 8746.329153280469, Epsilon: 0.640\n",
      "Episode 3412 finished after 544 timesteps\n",
      "Total reward: 5004.813330985911, Epsilon: 0.640\n",
      "Episode 3413 finished after 2475 timesteps\n",
      "Total reward: 16740.438823551467, Epsilon: 0.640\n",
      "Episode 3414 finished after 3001 timesteps\n",
      "Total reward: 13844.208105313735, Epsilon: 0.640\n",
      "Episode 3415 finished after 1501 timesteps\n",
      "Total reward: 9457.809110609496, Epsilon: 0.640\n",
      "Episode 3416 finished after 3001 timesteps\n",
      "Total reward: 16079.817475400547, Epsilon: 0.639\n",
      "Episode 3417 finished after 1579 timesteps\n",
      "Total reward: 9719.403466696274, Epsilon: 0.639\n",
      "Episode 3418 finished after 2458 timesteps\n",
      "Total reward: 13871.29984695991, Epsilon: 0.639\n",
      "Episode 3419 finished after 3001 timesteps\n",
      "Total reward: 13892.495521144532, Epsilon: 0.639\n",
      "Episode 3420 finished after 1696 timesteps\n",
      "Total reward: 8170.878701276339, Epsilon: 0.639\n",
      "Episode 3421 finished after 3001 timesteps\n",
      "Total reward: 13464.171840021481, Epsilon: 0.639\n",
      "Episode 3422 finished after 3001 timesteps\n",
      "Total reward: 12745.631153940038, Epsilon: 0.639\n",
      "Episode 3423 finished after 1892 timesteps\n",
      "Total reward: 9410.025251755536, Epsilon: 0.639\n",
      "Episode 3424 finished after 3001 timesteps\n",
      "Total reward: 14056.296649121146, Epsilon: 0.639\n",
      "Episode 3425 finished after 2527 timesteps\n",
      "Total reward: 13820.055477382759, Epsilon: 0.639\n",
      "Episode 3426 finished after 711 timesteps\n",
      "Total reward: 5665.435335866149, Epsilon: 0.639\n",
      "Episode 3427 finished after 1259 timesteps\n",
      "Total reward: 10055.195478175754, Epsilon: 0.639\n",
      "Episode 3428 finished after 403 timesteps\n",
      "Total reward: 2725.226983420027, Epsilon: 0.639\n",
      "Episode 3429 finished after 3001 timesteps\n",
      "Total reward: 16075.90627430454, Epsilon: 0.639\n",
      "Episode 3430 finished after 1998 timesteps\n",
      "Total reward: 10409.02897231443, Epsilon: 0.639\n",
      "Episode 3431 finished after 2323 timesteps\n",
      "Total reward: 14141.972709439735, Epsilon: 0.639\n",
      "Episode 3432 finished after 3001 timesteps\n",
      "Total reward: 15544.469470641718, Epsilon: 0.638\n",
      "Episode 3433 finished after 3001 timesteps\n",
      "Total reward: 13301.863010945079, Epsilon: 0.638\n",
      "Episode 3434 finished after 1035 timesteps\n",
      "Total reward: 6046.580127360446, Epsilon: 0.638\n",
      "Episode 3435 finished after 1029 timesteps\n",
      "Total reward: 5323.3019261278005, Epsilon: 0.638\n",
      "Episode 3436 finished after 988 timesteps\n",
      "Total reward: 5205.32904907716, Epsilon: 0.638\n",
      "Episode 3437 finished after 729 timesteps\n",
      "Total reward: 4495.078882309472, Epsilon: 0.638\n",
      "Episode 3438 finished after 978 timesteps\n",
      "Total reward: 7006.047804543444, Epsilon: 0.638\n",
      "Episode 3439 finished after 2882 timesteps\n",
      "Total reward: 13585.297111016216, Epsilon: 0.638\n",
      "Episode 3440 finished after 3001 timesteps\n",
      "Total reward: 18446.272327647977, Epsilon: 0.638\n",
      "Episode 3441 finished after 326 timesteps\n",
      "Total reward: 2679.6468389346132, Epsilon: 0.638\n",
      "Episode 3442 finished after 3001 timesteps\n",
      "Total reward: 14285.340154740426, Epsilon: 0.638\n",
      "Episode 3443 finished after 3001 timesteps\n",
      "Total reward: 12559.004172663233, Epsilon: 0.638\n",
      "Episode 3444 finished after 2157 timesteps\n",
      "Total reward: 13710.87813961658, Epsilon: 0.638\n",
      "Episode 3445 finished after 791 timesteps\n",
      "Total reward: 5206.059024171797, Epsilon: 0.638\n",
      "Episode 3446 finished after 3001 timesteps\n",
      "Total reward: 15094.032429786857, Epsilon: 0.638\n",
      "Episode 3447 finished after 3001 timesteps\n",
      "Total reward: 15488.32086532014, Epsilon: 0.638\n",
      "Episode 3448 finished after 3001 timesteps\n",
      "Total reward: 13720.971506093654, Epsilon: 0.637\n",
      "Episode 3449 finished after 2588 timesteps\n",
      "Total reward: 13546.165953559392, Epsilon: 0.637\n",
      "Episode 3450 finished after 3001 timesteps\n",
      "Total reward: 13000.919049973403, Epsilon: 0.637\n",
      "Episode 3451 finished after 1019 timesteps\n",
      "Total reward: 7083.884643415947, Epsilon: 0.637\n",
      "Episode 3452 finished after 342 timesteps\n",
      "Total reward: 2643.386669547609, Epsilon: 0.637\n",
      "Episode 3453 finished after 1691 timesteps\n",
      "Total reward: 10147.439422706833, Epsilon: 0.637\n",
      "Episode 3454 finished after 408 timesteps\n",
      "Total reward: 2874.8770232611614, Epsilon: 0.637\n",
      "Episode 3455 finished after 858 timesteps\n",
      "Total reward: 5637.329519165126, Epsilon: 0.637\n",
      "Episode 3456 finished after 3001 timesteps\n",
      "Total reward: 13419.713515779385, Epsilon: 0.637\n",
      "Episode 3457 finished after 1328 timesteps\n",
      "Total reward: 8091.078537361741, Epsilon: 0.637\n",
      "Episode 3458 finished after 1436 timesteps\n",
      "Total reward: 7937.464822708118, Epsilon: 0.637\n",
      "Episode 3459 finished after 2674 timesteps\n",
      "Total reward: 12817.488978431205, Epsilon: 0.637\n",
      "Episode 3460 finished after 2787 timesteps\n",
      "Total reward: 14482.242927002482, Epsilon: 0.637\n",
      "Episode 3461 finished after 1894 timesteps\n",
      "Total reward: 10909.64702596051, Epsilon: 0.637\n",
      "Episode 3462 finished after 358 timesteps\n",
      "Total reward: 2583.760201230235, Epsilon: 0.637\n",
      "Episode 3463 finished after 3001 timesteps\n",
      "Total reward: 13887.517203538628, Epsilon: 0.636\n",
      "Episode 3464 finished after 1425 timesteps\n",
      "Total reward: 6705.890743296689, Epsilon: 0.636\n",
      "Episode 3465 finished after 919 timesteps\n",
      "Total reward: 6369.436104140427, Epsilon: 0.636\n",
      "Episode 3466 finished after 1034 timesteps\n",
      "Total reward: 5915.2624170199315, Epsilon: 0.636\n",
      "Episode 3467 finished after 1691 timesteps\n",
      "Total reward: 10646.859578811443, Epsilon: 0.636\n",
      "Episode 3468 finished after 248 timesteps\n",
      "Total reward: 2545.816594079407, Epsilon: 0.636\n",
      "Episode 3469 finished after 1035 timesteps\n",
      "Total reward: 5592.398364964752, Epsilon: 0.636\n",
      "Episode 3470 finished after 3001 timesteps\n",
      "Total reward: 15550.66363699917, Epsilon: 0.636\n",
      "Episode 3471 finished after 3001 timesteps\n",
      "Total reward: 14189.436536201898, Epsilon: 0.636\n",
      "Episode 3472 finished after 1579 timesteps\n",
      "Total reward: 8505.169738134231, Epsilon: 0.636\n",
      "Episode 3473 finished after 3001 timesteps\n",
      "Total reward: 15268.676105758286, Epsilon: 0.636\n",
      "Episode 3474 finished after 489 timesteps\n",
      "Total reward: 3267.144860949534, Epsilon: 0.636\n",
      "Episode 3475 finished after 3001 timesteps\n",
      "Total reward: 15853.386314921114, Epsilon: 0.636\n",
      "Episode 3476 finished after 1760 timesteps\n",
      "Total reward: 9552.39530374, Epsilon: 0.636\n",
      "Episode 3477 finished after 2596 timesteps\n",
      "Total reward: 12824.434610472363, Epsilon: 0.636\n",
      "Episode 3478 finished after 2658 timesteps\n",
      "Total reward: 11887.708301079323, Epsilon: 0.636\n",
      "Episode 3479 finished after 3001 timesteps\n",
      "Total reward: 12779.784539930426, Epsilon: 0.635\n",
      "Episode 3480 finished after 280 timesteps\n",
      "Total reward: 3415.4053672860523, Epsilon: 0.635\n",
      "Episode 3481 finished after 3001 timesteps\n",
      "Total reward: 14254.513981226995, Epsilon: 0.635\n",
      "Episode 3482 finished after 3001 timesteps\n",
      "Total reward: 16224.560632368022, Epsilon: 0.635\n",
      "Episode 3483 finished after 1874 timesteps\n",
      "Total reward: 9685.27849828264, Epsilon: 0.635\n",
      "Episode 3484 finished after 1094 timesteps\n",
      "Total reward: 6273.423953373791, Epsilon: 0.635\n",
      "Episode 3485 finished after 808 timesteps\n",
      "Total reward: 4057.2184064881394, Epsilon: 0.635\n",
      "Episode 3486 finished after 391 timesteps\n",
      "Total reward: 3194.2589376350343, Epsilon: 0.635\n",
      "Episode 3487 finished after 3001 timesteps\n",
      "Total reward: 13889.198785044366, Epsilon: 0.635\n",
      "Episode 3488 finished after 3001 timesteps\n",
      "Total reward: 13587.367449793666, Epsilon: 0.635\n",
      "Episode 3489 finished after 1384 timesteps\n",
      "Total reward: 7871.5333401312255, Epsilon: 0.635\n",
      "Episode 3490 finished after 2482 timesteps\n",
      "Total reward: 14226.711440684396, Epsilon: 0.635\n",
      "Episode 3491 finished after 889 timesteps\n",
      "Total reward: 7427.837069564829, Epsilon: 0.635\n",
      "Episode 3492 finished after 1072 timesteps\n",
      "Total reward: 6302.925748439515, Epsilon: 0.635\n",
      "Episode 3493 finished after 798 timesteps\n",
      "Total reward: 4592.58431719559, Epsilon: 0.635\n",
      "Episode 3494 finished after 647 timesteps\n",
      "Total reward: 5412.644569644248, Epsilon: 0.635\n",
      "Episode 3495 finished after 1813 timesteps\n",
      "Total reward: 8830.750500656182, Epsilon: 0.634\n",
      "Episode 3496 finished after 276 timesteps\n",
      "Total reward: 2551.969322295182, Epsilon: 0.634\n",
      "Episode 3497 finished after 430 timesteps\n",
      "Total reward: 2805.7915550769226, Epsilon: 0.634\n",
      "Episode 3498 finished after 664 timesteps\n",
      "Total reward: 4539.069576215451, Epsilon: 0.634\n",
      "Episode 3499 finished after 376 timesteps\n",
      "Total reward: 3478.7942261450257, Epsilon: 0.634\n",
      "Episode 3500 finished after 3001 timesteps\n",
      "Total reward: 16571.173728360456, Epsilon: 0.634\n",
      "Episode 3501 finished after 516 timesteps\n",
      "Total reward: 5336.996200479452, Epsilon: 0.634\n",
      "Episode 3502 finished after 2294 timesteps\n",
      "Total reward: 13477.85869752117, Epsilon: 0.634\n",
      "Episode 3503 finished after 2748 timesteps\n",
      "Total reward: 16607.25415990756, Epsilon: 0.634\n",
      "Episode 3504 finished after 1270 timesteps\n",
      "Total reward: 9726.842630638084, Epsilon: 0.634\n",
      "Episode 3505 finished after 1156 timesteps\n",
      "Total reward: 5766.076040643816, Epsilon: 0.634\n",
      "Episode 3506 finished after 1540 timesteps\n",
      "Total reward: 8510.353985603522, Epsilon: 0.634\n",
      "Episode 3507 finished after 673 timesteps\n",
      "Total reward: 5503.789992972791, Epsilon: 0.634\n",
      "Episode 3508 finished after 1401 timesteps\n",
      "Total reward: 7492.340987487024, Epsilon: 0.634\n",
      "Episode 3509 finished after 1749 timesteps\n",
      "Total reward: 8648.676210579204, Epsilon: 0.634\n",
      "Episode 3510 finished after 394 timesteps\n",
      "Total reward: 2999.7026732613945, Epsilon: 0.634\n",
      "Episode 3511 finished after 995 timesteps\n",
      "Total reward: 7063.615477554141, Epsilon: 0.633\n",
      "Episode 3512 finished after 1876 timesteps\n",
      "Total reward: 12577.33107457795, Epsilon: 0.633\n",
      "Episode 3513 finished after 655 timesteps\n",
      "Total reward: 4767.33735723079, Epsilon: 0.633\n",
      "Episode 3514 finished after 3001 timesteps\n",
      "Total reward: 13190.933940610757, Epsilon: 0.633\n",
      "Episode 3515 finished after 737 timesteps\n",
      "Total reward: 6590.843404619688, Epsilon: 0.633\n",
      "Episode 3516 finished after 2231 timesteps\n",
      "Total reward: 12235.560056253405, Epsilon: 0.633\n",
      "Episode 3517 finished after 786 timesteps\n",
      "Total reward: 6305.693261737195, Epsilon: 0.633\n",
      "Episode 3518 finished after 1834 timesteps\n",
      "Total reward: 9945.413320504316, Epsilon: 0.633\n",
      "Episode 3519 finished after 2579 timesteps\n",
      "Total reward: 14033.97242233879, Epsilon: 0.633\n",
      "Episode 3520 finished after 993 timesteps\n",
      "Total reward: 5638.5998857452805, Epsilon: 0.633\n",
      "Episode 3521 finished after 1438 timesteps\n",
      "Total reward: 8239.146883265352, Epsilon: 0.633\n",
      "Episode 3522 finished after 882 timesteps\n",
      "Total reward: 5302.590795510232, Epsilon: 0.633\n",
      "Episode 3523 finished after 108 timesteps\n",
      "Total reward: 1948.0452084292538, Epsilon: 0.633\n",
      "Episode 3524 finished after 3001 timesteps\n",
      "Total reward: 12688.039932041476, Epsilon: 0.633\n",
      "Episode 3525 finished after 276 timesteps\n",
      "Total reward: 3355.0888319489527, Epsilon: 0.633\n",
      "Episode 3526 finished after 3001 timesteps\n",
      "Total reward: 14073.197435932536, Epsilon: 0.632\n",
      "Episode 3527 finished after 1270 timesteps\n",
      "Total reward: 7334.232398840977, Epsilon: 0.632\n",
      "Episode 3528 finished after 3001 timesteps\n",
      "Total reward: 14373.741246525045, Epsilon: 0.632\n",
      "Episode 3529 finished after 3001 timesteps\n",
      "Total reward: 13147.49837635994, Epsilon: 0.632\n",
      "Episode 3530 finished after 2597 timesteps\n",
      "Total reward: 11503.637156426934, Epsilon: 0.632\n",
      "Episode 3531 finished after 2424 timesteps\n",
      "Total reward: 11448.704917434028, Epsilon: 0.632\n",
      "Episode 3532 finished after 662 timesteps\n",
      "Total reward: 5516.26847752389, Epsilon: 0.632\n",
      "Episode 3533 finished after 431 timesteps\n",
      "Total reward: 4354.453869534304, Epsilon: 0.632\n",
      "Episode 3534 finished after 943 timesteps\n",
      "Total reward: 7824.4261622562935, Epsilon: 0.632\n",
      "Episode 3535 finished after 2248 timesteps\n",
      "Total reward: 12311.428575690239, Epsilon: 0.632\n",
      "Episode 3536 finished after 1856 timesteps\n",
      "Total reward: 9788.802534592216, Epsilon: 0.632\n",
      "Episode 3537 finished after 900 timesteps\n",
      "Total reward: 7151.271119041547, Epsilon: 0.632\n",
      "Episode 3538 finished after 3001 timesteps\n",
      "Total reward: 15655.484339294942, Epsilon: 0.632\n",
      "Episode 3539 finished after 1367 timesteps\n",
      "Total reward: 7254.511269772993, Epsilon: 0.632\n",
      "Episode 3540 finished after 2635 timesteps\n",
      "Total reward: 12651.169227877584, Epsilon: 0.632\n",
      "Episode 3541 finished after 2665 timesteps\n",
      "Total reward: 15508.898874434815, Epsilon: 0.632\n",
      "Episode 3542 finished after 1986 timesteps\n",
      "Total reward: 11137.528426576335, Epsilon: 0.631\n",
      "Episode 3543 finished after 596 timesteps\n",
      "Total reward: 5760.131903130879, Epsilon: 0.631\n",
      "Episode 3544 finished after 1803 timesteps\n",
      "Total reward: 12375.054245411704, Epsilon: 0.631\n",
      "Episode 3545 finished after 1492 timesteps\n",
      "Total reward: 8077.693073502683, Epsilon: 0.631\n",
      "Episode 3546 finished after 3001 timesteps\n",
      "Total reward: 14093.768160563925, Epsilon: 0.631\n",
      "Episode 3547 finished after 498 timesteps\n",
      "Total reward: 3036.077285291392, Epsilon: 0.631\n",
      "Episode 3548 finished after 1755 timesteps\n",
      "Total reward: 9127.908379578825, Epsilon: 0.631\n",
      "Episode 3549 finished after 1116 timesteps\n",
      "Total reward: 9637.999498035782, Epsilon: 0.631\n",
      "Episode 3550 finished after 810 timesteps\n",
      "Total reward: 6206.958758035544, Epsilon: 0.631\n",
      "Episode 3551 finished after 1704 timesteps\n",
      "Total reward: 10467.632770276983, Epsilon: 0.631\n",
      "Episode 3552 finished after 1187 timesteps\n",
      "Total reward: 5331.80411762834, Epsilon: 0.631\n",
      "Episode 3553 finished after 992 timesteps\n",
      "Total reward: 8181.845871077616, Epsilon: 0.631\n",
      "Episode 3554 finished after 2335 timesteps\n",
      "Total reward: 14590.209186587454, Epsilon: 0.631\n",
      "Episode 3555 finished after 3001 timesteps\n",
      "Total reward: 13279.923493197364, Epsilon: 0.631\n",
      "Episode 3556 finished after 3001 timesteps\n",
      "Total reward: 16090.05820478972, Epsilon: 0.631\n",
      "Episode 3557 finished after 2255 timesteps\n",
      "Total reward: 15553.33489851282, Epsilon: 0.631\n",
      "Episode 3558 finished after 445 timesteps\n",
      "Total reward: 2986.9969522224224, Epsilon: 0.630\n",
      "Episode 3559 finished after 1275 timesteps\n",
      "Total reward: 6678.695770950611, Epsilon: 0.630\n",
      "Episode 3560 finished after 3001 timesteps\n",
      "Total reward: 14083.667666451882, Epsilon: 0.630\n",
      "Episode 3561 finished after 1185 timesteps\n",
      "Total reward: 7560.7829710780625, Epsilon: 0.630\n",
      "Episode 3562 finished after 2154 timesteps\n",
      "Total reward: 12873.118896309586, Epsilon: 0.630\n",
      "Episode 3563 finished after 2105 timesteps\n",
      "Total reward: 10853.186755254454, Epsilon: 0.630\n",
      "Episode 3564 finished after 378 timesteps\n",
      "Total reward: 3511.8160995943704, Epsilon: 0.630\n",
      "Episode 3565 finished after 836 timesteps\n",
      "Total reward: 5065.1205600327785, Epsilon: 0.630\n",
      "Episode 3566 finished after 3001 timesteps\n",
      "Total reward: 13507.919117547292, Epsilon: 0.630\n",
      "Episode 3567 finished after 953 timesteps\n",
      "Total reward: 4578.363467114302, Epsilon: 0.630\n",
      "Episode 3568 finished after 1321 timesteps\n",
      "Total reward: 6508.445667894864, Epsilon: 0.630\n",
      "Episode 3569 finished after 730 timesteps\n",
      "Total reward: 5276.354242266293, Epsilon: 0.630\n",
      "Episode 3570 finished after 3001 timesteps\n",
      "Total reward: 16802.34644060094, Epsilon: 0.630\n",
      "Episode 3571 finished after 1740 timesteps\n",
      "Total reward: 13834.919582882741, Epsilon: 0.630\n",
      "Episode 3572 finished after 1479 timesteps\n",
      "Total reward: 9126.353672226976, Epsilon: 0.630\n",
      "Episode 3573 finished after 3001 timesteps\n",
      "Total reward: 13667.415895164517, Epsilon: 0.630\n",
      "Episode 3574 finished after 1024 timesteps\n",
      "Total reward: 5673.251129135511, Epsilon: 0.629\n",
      "Episode 3575 finished after 1476 timesteps\n",
      "Total reward: 6942.344475471291, Epsilon: 0.629\n",
      "Episode 3576 finished after 938 timesteps\n",
      "Total reward: 5959.736382657464, Epsilon: 0.629\n",
      "Episode 3577 finished after 3001 timesteps\n",
      "Total reward: 13443.709793581715, Epsilon: 0.629\n",
      "Episode 3578 finished after 1455 timesteps\n",
      "Total reward: 8442.8357117018, Epsilon: 0.629\n",
      "Episode 3579 finished after 2825 timesteps\n",
      "Total reward: 20530.79157655555, Epsilon: 0.629\n",
      "Episode 3580 finished after 2181 timesteps\n",
      "Total reward: 12335.52315347229, Epsilon: 0.629\n",
      "Episode 3581 finished after 2531 timesteps\n",
      "Total reward: 16980.132440049765, Epsilon: 0.629\n",
      "Episode 3582 finished after 2262 timesteps\n",
      "Total reward: 13994.88425387239, Epsilon: 0.629\n",
      "Episode 3583 finished after 3001 timesteps\n",
      "Total reward: 17300.843767317474, Epsilon: 0.629\n",
      "Episode 3584 finished after 2730 timesteps\n",
      "Total reward: 15629.85100598008, Epsilon: 0.629\n",
      "Episode 3585 finished after 1123 timesteps\n",
      "Total reward: 6767.624162853353, Epsilon: 0.629\n",
      "Episode 3586 finished after 1916 timesteps\n",
      "Total reward: 11346.415838489833, Epsilon: 0.629\n",
      "Episode 3587 finished after 931 timesteps\n",
      "Total reward: 4650.882442715553, Epsilon: 0.629\n",
      "Episode 3588 finished after 3001 timesteps\n",
      "Total reward: 13056.201012013458, Epsilon: 0.629\n",
      "Episode 3589 finished after 3001 timesteps\n",
      "Total reward: 13534.149219123703, Epsilon: 0.629\n",
      "Episode 3590 finished after 3001 timesteps\n",
      "Total reward: 16045.200342936043, Epsilon: 0.628\n",
      "Episode 3591 finished after 3001 timesteps\n",
      "Total reward: 16944.913269481352, Epsilon: 0.628\n",
      "Episode 3592 finished after 1219 timesteps\n",
      "Total reward: 6835.27422574497, Epsilon: 0.628\n",
      "Episode 3593 finished after 1870 timesteps\n",
      "Total reward: 10637.900718431947, Epsilon: 0.628\n",
      "Episode 3594 finished after 2203 timesteps\n",
      "Total reward: 13812.068949048253, Epsilon: 0.628\n",
      "Episode 3595 finished after 2123 timesteps\n",
      "Total reward: 12071.487867796526, Epsilon: 0.628\n",
      "Episode 3596 finished after 3001 timesteps\n",
      "Total reward: 14232.273705837979, Epsilon: 0.628\n",
      "Episode 3597 finished after 945 timesteps\n",
      "Total reward: 5555.851737632518, Epsilon: 0.628\n",
      "Episode 3598 finished after 794 timesteps\n",
      "Total reward: 5991.283155797671, Epsilon: 0.628\n",
      "Episode 3599 finished after 1600 timesteps\n",
      "Total reward: 8350.746383196796, Epsilon: 0.628\n",
      "Episode 3600 finished after 751 timesteps\n",
      "Total reward: 3998.8241552852833, Epsilon: 0.628\n",
      "Episode 3601 finished after 2009 timesteps\n",
      "Total reward: 10627.208543498788, Epsilon: 0.628\n",
      "Episode 3602 finished after 405 timesteps\n",
      "Total reward: 3836.670060605124, Epsilon: 0.628\n",
      "Episode 3603 finished after 1742 timesteps\n",
      "Total reward: 10009.095001964813, Epsilon: 0.628\n",
      "Episode 3604 finished after 2130 timesteps\n",
      "Total reward: 10030.914827426097, Epsilon: 0.628\n",
      "Episode 3605 finished after 3001 timesteps\n",
      "Total reward: 13739.206200896548, Epsilon: 0.628\n",
      "Episode 3606 finished after 805 timesteps\n",
      "Total reward: 4712.741215020559, Epsilon: 0.627\n",
      "Episode 3607 finished after 1095 timesteps\n",
      "Total reward: 7019.211299339471, Epsilon: 0.627\n",
      "Episode 3608 finished after 3001 timesteps\n",
      "Total reward: 14814.583460212129, Epsilon: 0.627\n",
      "Episode 3609 finished after 2532 timesteps\n",
      "Total reward: 13111.23804746466, Epsilon: 0.627\n",
      "Episode 3610 finished after 2356 timesteps\n",
      "Total reward: 15320.590197887497, Epsilon: 0.627\n",
      "Episode 3611 finished after 3001 timesteps\n",
      "Total reward: 12873.422971367643, Epsilon: 0.627\n",
      "Episode 3612 finished after 3001 timesteps\n",
      "Total reward: 14490.106659209474, Epsilon: 0.627\n",
      "Episode 3613 finished after 2002 timesteps\n",
      "Total reward: 10026.90631785324, Epsilon: 0.627\n",
      "Episode 3614 finished after 659 timesteps\n",
      "Total reward: 4013.4694011777674, Epsilon: 0.627\n",
      "Episode 3615 finished after 425 timesteps\n",
      "Total reward: 3448.7761458275377, Epsilon: 0.627\n",
      "Episode 3616 finished after 1542 timesteps\n",
      "Total reward: 7539.307729959418, Epsilon: 0.627\n",
      "Episode 3617 finished after 1335 timesteps\n",
      "Total reward: 7003.908149425151, Epsilon: 0.627\n",
      "Episode 3618 finished after 3001 timesteps\n",
      "Total reward: 15472.363198979074, Epsilon: 0.627\n",
      "Episode 3619 finished after 2526 timesteps\n",
      "Total reward: 11040.43353793898, Epsilon: 0.627\n",
      "Episode 3620 finished after 664 timesteps\n",
      "Total reward: 4882.859491873074, Epsilon: 0.627\n",
      "Episode 3621 finished after 1119 timesteps\n",
      "Total reward: 7535.046552236469, Epsilon: 0.627\n",
      "Episode 3622 finished after 1889 timesteps\n",
      "Total reward: 14950.942927914215, Epsilon: 0.626\n",
      "Episode 3623 finished after 3001 timesteps\n",
      "Total reward: 16482.93811050076, Epsilon: 0.626\n",
      "Episode 3624 finished after 624 timesteps\n",
      "Total reward: 4723.043146791318, Epsilon: 0.626\n",
      "Episode 3625 finished after 3001 timesteps\n",
      "Total reward: 14420.857759432281, Epsilon: 0.626\n",
      "Episode 3626 finished after 680 timesteps\n",
      "Total reward: 4895.879437540446, Epsilon: 0.626\n",
      "Episode 3627 finished after 3001 timesteps\n",
      "Total reward: 13206.076168848136, Epsilon: 0.626\n",
      "Episode 3628 finished after 474 timesteps\n",
      "Total reward: 4018.5913521817465, Epsilon: 0.626\n",
      "Episode 3629 finished after 621 timesteps\n",
      "Total reward: 5798.114104635353, Epsilon: 0.626\n",
      "Episode 3630 finished after 889 timesteps\n",
      "Total reward: 5330.685107076581, Epsilon: 0.626\n",
      "Episode 3631 finished after 2096 timesteps\n",
      "Total reward: 12902.551576042084, Epsilon: 0.626\n",
      "Episode 3632 finished after 786 timesteps\n",
      "Total reward: 5916.632638753607, Epsilon: 0.626\n",
      "Episode 3633 finished after 2181 timesteps\n",
      "Total reward: 11861.748451816537, Epsilon: 0.626\n",
      "Episode 3634 finished after 3001 timesteps\n",
      "Total reward: 14561.329824490156, Epsilon: 0.626\n",
      "Episode 3635 finished after 1022 timesteps\n",
      "Total reward: 5421.146346103639, Epsilon: 0.626\n",
      "Episode 3636 finished after 2887 timesteps\n",
      "Total reward: 14499.306972170838, Epsilon: 0.626\n",
      "Episode 3637 finished after 3001 timesteps\n",
      "Total reward: 17023.944494910425, Epsilon: 0.626\n",
      "Episode 3638 finished after 489 timesteps\n",
      "Total reward: 4553.78730963239, Epsilon: 0.625\n",
      "Episode 3639 finished after 392 timesteps\n",
      "Total reward: 4751.440390730836, Epsilon: 0.625\n",
      "Episode 3640 finished after 2484 timesteps\n",
      "Total reward: 13292.042504431747, Epsilon: 0.625\n",
      "Episode 3641 finished after 2297 timesteps\n",
      "Total reward: 12159.68642660982, Epsilon: 0.625\n",
      "Episode 3642 finished after 1112 timesteps\n",
      "Total reward: 7074.910254656282, Epsilon: 0.625\n",
      "Episode 3643 finished after 978 timesteps\n",
      "Total reward: 6364.652444122022, Epsilon: 0.625\n",
      "Episode 3644 finished after 3001 timesteps\n",
      "Total reward: 14648.37750421338, Epsilon: 0.625\n",
      "Episode 3645 finished after 831 timesteps\n",
      "Total reward: 6036.628697376883, Epsilon: 0.625\n",
      "Episode 3646 finished after 2280 timesteps\n",
      "Total reward: 15649.098044294748, Epsilon: 0.625\n",
      "Episode 3647 finished after 3001 timesteps\n",
      "Total reward: 13680.834679028363, Epsilon: 0.625\n",
      "Episode 3648 finished after 439 timesteps\n",
      "Total reward: 3252.7543050920585, Epsilon: 0.625\n",
      "Episode 3649 finished after 3001 timesteps\n",
      "Total reward: 16568.442323103685, Epsilon: 0.625\n",
      "Episode 3650 finished after 2434 timesteps\n",
      "Total reward: 18705.064399103634, Epsilon: 0.625\n",
      "Episode 3651 finished after 1835 timesteps\n",
      "Total reward: 10281.939481293082, Epsilon: 0.625\n",
      "Episode 3652 finished after 714 timesteps\n",
      "Total reward: 4488.54032161985, Epsilon: 0.625\n",
      "Episode 3653 finished after 986 timesteps\n",
      "Total reward: 6372.8880249564545, Epsilon: 0.625\n",
      "Episode 3654 finished after 1097 timesteps\n",
      "Total reward: 6702.3965568489575, Epsilon: 0.624\n",
      "Episode 3655 finished after 1302 timesteps\n",
      "Total reward: 6659.050169068589, Epsilon: 0.624\n",
      "Episode 3656 finished after 3001 timesteps\n",
      "Total reward: 13832.387999246072, Epsilon: 0.624\n",
      "Episode 3657 finished after 3001 timesteps\n",
      "Total reward: 13974.288087000836, Epsilon: 0.624\n",
      "Episode 3658 finished after 783 timesteps\n",
      "Total reward: 4549.753823907063, Epsilon: 0.624\n",
      "Episode 3659 finished after 3001 timesteps\n",
      "Total reward: 12599.534360070562, Epsilon: 0.624\n",
      "Episode 3660 finished after 3001 timesteps\n",
      "Total reward: 14180.88821379029, Epsilon: 0.624\n",
      "Episode 3661 finished after 3001 timesteps\n",
      "Total reward: 13639.630765781818, Epsilon: 0.624\n",
      "Episode 3662 finished after 1317 timesteps\n",
      "Total reward: 7320.843729673715, Epsilon: 0.624\n",
      "Episode 3663 finished after 2430 timesteps\n",
      "Total reward: 11566.644950947413, Epsilon: 0.624\n",
      "Episode 3664 finished after 1698 timesteps\n",
      "Total reward: 9913.864292328237, Epsilon: 0.624\n",
      "Episode 3665 finished after 2243 timesteps\n",
      "Total reward: 11686.006083462576, Epsilon: 0.624\n",
      "Episode 3666 finished after 2845 timesteps\n",
      "Total reward: 15073.482493680367, Epsilon: 0.624\n",
      "Episode 3667 finished after 2018 timesteps\n",
      "Total reward: 14276.26561565104, Epsilon: 0.624\n",
      "Episode 3668 finished after 1841 timesteps\n",
      "Total reward: 10714.83374431799, Epsilon: 0.624\n",
      "Episode 3669 finished after 201 timesteps\n",
      "Total reward: 2142.3179165668557, Epsilon: 0.624\n",
      "Episode 3670 finished after 2281 timesteps\n",
      "Total reward: 12373.46877117343, Epsilon: 0.623\n",
      "Episode 3671 finished after 2182 timesteps\n",
      "Total reward: 12039.235824215688, Epsilon: 0.623\n",
      "Episode 3672 finished after 919 timesteps\n",
      "Total reward: 5906.556660930093, Epsilon: 0.623\n",
      "Episode 3673 finished after 283 timesteps\n",
      "Total reward: 2578.734342869236, Epsilon: 0.623\n",
      "Episode 3674 finished after 2288 timesteps\n",
      "Total reward: 11240.618106474736, Epsilon: 0.623\n",
      "Episode 3675 finished after 1529 timesteps\n",
      "Total reward: 7117.624230144902, Epsilon: 0.623\n",
      "Episode 3676 finished after 3001 timesteps\n",
      "Total reward: 19172.542839614536, Epsilon: 0.623\n",
      "Episode 3677 finished after 1865 timesteps\n",
      "Total reward: 15666.260563542544, Epsilon: 0.623\n",
      "Episode 3678 finished after 550 timesteps\n",
      "Total reward: 4251.303671297164, Epsilon: 0.623\n",
      "Episode 3679 finished after 956 timesteps\n",
      "Total reward: 5432.316184510776, Epsilon: 0.623\n",
      "Episode 3680 finished after 1036 timesteps\n",
      "Total reward: 6734.4560104614, Epsilon: 0.623\n",
      "Episode 3681 finished after 3001 timesteps\n",
      "Total reward: 12469.176011313897, Epsilon: 0.623\n",
      "Episode 3682 finished after 829 timesteps\n",
      "Total reward: 5718.970037689989, Epsilon: 0.623\n",
      "Episode 3683 finished after 1296 timesteps\n",
      "Total reward: 10255.458264591802, Epsilon: 0.623\n",
      "Episode 3684 finished after 2869 timesteps\n",
      "Total reward: 13913.659067969542, Epsilon: 0.623\n",
      "Episode 3685 finished after 204 timesteps\n",
      "Total reward: 1751.3631622399228, Epsilon: 0.623\n",
      "Episode 3686 finished after 3001 timesteps\n",
      "Total reward: 14387.05512833999, Epsilon: 0.622\n",
      "Episode 3687 finished after 3001 timesteps\n",
      "Total reward: 15544.76761448984, Epsilon: 0.622\n",
      "Episode 3688 finished after 2622 timesteps\n",
      "Total reward: 14513.984919477136, Epsilon: 0.622\n",
      "Episode 3689 finished after 2248 timesteps\n",
      "Total reward: 11076.162057454454, Epsilon: 0.622\n",
      "Episode 3690 finished after 179 timesteps\n",
      "Total reward: 2252.144485169923, Epsilon: 0.622\n",
      "Episode 3691 finished after 321 timesteps\n",
      "Total reward: 2760.0455603287733, Epsilon: 0.622\n",
      "Episode 3692 finished after 1342 timesteps\n",
      "Total reward: 9073.080130700724, Epsilon: 0.622\n",
      "Episode 3693 finished after 3001 timesteps\n",
      "Total reward: 17169.414325929665, Epsilon: 0.622\n",
      "Episode 3694 finished after 453 timesteps\n",
      "Total reward: 3901.6094496500646, Epsilon: 0.622\n",
      "Episode 3695 finished after 3001 timesteps\n",
      "Total reward: 12548.150972199704, Epsilon: 0.622\n",
      "Episode 3696 finished after 727 timesteps\n",
      "Total reward: 4573.996088310033, Epsilon: 0.622\n",
      "Episode 3697 finished after 984 timesteps\n",
      "Total reward: 6540.016926354866, Epsilon: 0.622\n",
      "Episode 3698 finished after 3001 timesteps\n",
      "Total reward: 13419.200247078283, Epsilon: 0.622\n",
      "Episode 3699 finished after 1054 timesteps\n",
      "Total reward: 5680.876012296819, Epsilon: 0.622\n",
      "Episode 3700 finished after 253 timesteps\n",
      "Total reward: 1950.570283448374, Epsilon: 0.622\n",
      "Episode 3701 finished after 3001 timesteps\n",
      "Total reward: 12430.574706393492, Epsilon: 0.622\n",
      "Episode 3702 finished after 951 timesteps\n",
      "Total reward: 6166.53949238605, Epsilon: 0.621\n",
      "Episode 3703 finished after 1264 timesteps\n",
      "Total reward: 8747.430249601035, Epsilon: 0.621\n",
      "Episode 3704 finished after 3001 timesteps\n",
      "Total reward: 13677.431139993334, Epsilon: 0.621\n",
      "Episode 3705 finished after 2771 timesteps\n",
      "Total reward: 15983.314207140284, Epsilon: 0.621\n",
      "Episode 3706 finished after 1886 timesteps\n",
      "Total reward: 11822.651265389664, Epsilon: 0.621\n",
      "Episode 3707 finished after 2907 timesteps\n",
      "Total reward: 17283.40995269266, Epsilon: 0.621\n",
      "Episode 3708 finished after 1191 timesteps\n",
      "Total reward: 8428.310066782244, Epsilon: 0.621\n",
      "Episode 3709 finished after 3001 timesteps\n",
      "Total reward: 16689.60009226717, Epsilon: 0.621\n",
      "Episode 3710 finished after 3001 timesteps\n",
      "Total reward: 13917.18326520236, Epsilon: 0.621\n",
      "Episode 3711 finished after 3001 timesteps\n",
      "Total reward: 16765.776765481613, Epsilon: 0.621\n",
      "Episode 3712 finished after 1039 timesteps\n",
      "Total reward: 5871.935026528056, Epsilon: 0.621\n",
      "Episode 3713 finished after 1689 timesteps\n",
      "Total reward: 9065.170453233719, Epsilon: 0.621\n",
      "Episode 3714 finished after 639 timesteps\n",
      "Total reward: 5396.834362690465, Epsilon: 0.621\n",
      "Episode 3715 finished after 1449 timesteps\n",
      "Total reward: 8277.780719152506, Epsilon: 0.621\n",
      "Episode 3716 finished after 3001 timesteps\n",
      "Total reward: 20107.957822270884, Epsilon: 0.621\n",
      "Episode 3717 finished after 1132 timesteps\n",
      "Total reward: 6128.347579443144, Epsilon: 0.621\n",
      "Episode 3718 finished after 1361 timesteps\n",
      "Total reward: 7446.031449923155, Epsilon: 0.620\n",
      "Episode 3719 finished after 3001 timesteps\n",
      "Total reward: 16191.14030429575, Epsilon: 0.620\n",
      "Episode 3720 finished after 2377 timesteps\n",
      "Total reward: 15505.536509025562, Epsilon: 0.620\n",
      "Episode 3721 finished after 2454 timesteps\n",
      "Total reward: 15252.378748272255, Epsilon: 0.620\n",
      "Episode 3722 finished after 1957 timesteps\n",
      "Total reward: 10130.970482539162, Epsilon: 0.620\n",
      "Episode 3723 finished after 1014 timesteps\n",
      "Total reward: 6740.810605916276, Epsilon: 0.620\n",
      "Episode 3724 finished after 3001 timesteps\n",
      "Total reward: 12263.834814993905, Epsilon: 0.620\n",
      "Episode 3725 finished after 1919 timesteps\n",
      "Total reward: 11484.584071518515, Epsilon: 0.620\n",
      "Episode 3726 finished after 882 timesteps\n",
      "Total reward: 4749.99942548104, Epsilon: 0.620\n",
      "Episode 3727 finished after 2287 timesteps\n",
      "Total reward: 13564.89060483676, Epsilon: 0.620\n",
      "Episode 3728 finished after 2026 timesteps\n",
      "Total reward: 14861.652437099905, Epsilon: 0.620\n",
      "Episode 3729 finished after 457 timesteps\n",
      "Total reward: 3575.6024855941296, Epsilon: 0.620\n",
      "Episode 3730 finished after 370 timesteps\n",
      "Total reward: 2887.409669575344, Epsilon: 0.620\n",
      "Episode 3731 finished after 2869 timesteps\n",
      "Total reward: 15945.24762888971, Epsilon: 0.620\n",
      "Episode 3732 finished after 2266 timesteps\n",
      "Total reward: 10742.367184740839, Epsilon: 0.620\n",
      "Episode 3733 finished after 3001 timesteps\n",
      "Total reward: 12972.537612708524, Epsilon: 0.620\n",
      "Episode 3734 finished after 737 timesteps\n",
      "Total reward: 5897.020665092004, Epsilon: 0.619\n",
      "Episode 3735 finished after 617 timesteps\n",
      "Total reward: 4654.875352866393, Epsilon: 0.619\n",
      "Episode 3736 finished after 3001 timesteps\n",
      "Total reward: 14278.231016308815, Epsilon: 0.619\n",
      "Episode 3737 finished after 902 timesteps\n",
      "Total reward: 5600.113926318009, Epsilon: 0.619\n",
      "Episode 3738 finished after 660 timesteps\n",
      "Total reward: 6204.516040223554, Epsilon: 0.619\n",
      "Episode 3739 finished after 1107 timesteps\n",
      "Total reward: 7253.055728953234, Epsilon: 0.619\n",
      "Episode 3740 finished after 2057 timesteps\n",
      "Total reward: 12402.64689016636, Epsilon: 0.619\n",
      "Episode 3741 finished after 2430 timesteps\n",
      "Total reward: 12042.274130812186, Epsilon: 0.619\n",
      "Episode 3742 finished after 371 timesteps\n",
      "Total reward: 2947.7168453191075, Epsilon: 0.619\n",
      "Episode 3743 finished after 666 timesteps\n",
      "Total reward: 4937.203632958118, Epsilon: 0.619\n",
      "Episode 3744 finished after 561 timesteps\n",
      "Total reward: 4315.482311232334, Epsilon: 0.619\n",
      "Episode 3745 finished after 3001 timesteps\n",
      "Total reward: 14217.076412901797, Epsilon: 0.619\n",
      "Episode 3746 finished after 3001 timesteps\n",
      "Total reward: 13815.052199108335, Epsilon: 0.619\n",
      "Episode 3747 finished after 3001 timesteps\n",
      "Total reward: 17224.167333279718, Epsilon: 0.619\n",
      "Episode 3748 finished after 856 timesteps\n",
      "Total reward: 8198.718138871838, Epsilon: 0.619\n",
      "Episode 3749 finished after 3001 timesteps\n",
      "Total reward: 13141.142586412925, Epsilon: 0.619\n",
      "Episode 3750 finished after 3001 timesteps\n",
      "Total reward: 12474.30562767564, Epsilon: 0.618\n",
      "Episode 3751 finished after 3001 timesteps\n",
      "Total reward: 12125.146114582776, Epsilon: 0.618\n",
      "Episode 3752 finished after 2161 timesteps\n",
      "Total reward: 12250.21775501239, Epsilon: 0.618\n",
      "Episode 3753 finished after 700 timesteps\n",
      "Total reward: 6150.875112935071, Epsilon: 0.618\n",
      "Episode 3754 finished after 2169 timesteps\n",
      "Total reward: 11654.798140050509, Epsilon: 0.618\n",
      "Episode 3755 finished after 519 timesteps\n",
      "Total reward: 4218.955629675991, Epsilon: 0.618\n",
      "Episode 3756 finished after 702 timesteps\n",
      "Total reward: 5669.772271616863, Epsilon: 0.618\n",
      "Episode 3757 finished after 1836 timesteps\n",
      "Total reward: 13298.399116200204, Epsilon: 0.618\n",
      "Episode 3758 finished after 1344 timesteps\n",
      "Total reward: 8227.553355581167, Epsilon: 0.618\n",
      "Episode 3759 finished after 199 timesteps\n",
      "Total reward: 1682.5315345675217, Epsilon: 0.618\n",
      "Episode 3760 finished after 3001 timesteps\n",
      "Total reward: 14821.698434608623, Epsilon: 0.618\n",
      "Episode 3761 finished after 3001 timesteps\n",
      "Total reward: 14230.396184147967, Epsilon: 0.618\n",
      "Episode 3762 finished after 2050 timesteps\n",
      "Total reward: 13838.73810698745, Epsilon: 0.618\n",
      "Episode 3763 finished after 3001 timesteps\n",
      "Total reward: 12689.834881247787, Epsilon: 0.618\n",
      "Episode 3764 finished after 1047 timesteps\n",
      "Total reward: 7521.32420889053, Epsilon: 0.618\n",
      "Episode 3765 finished after 455 timesteps\n",
      "Total reward: 3721.858609901442, Epsilon: 0.618\n",
      "Episode 3766 finished after 781 timesteps\n",
      "Total reward: 5614.510158809119, Epsilon: 0.617\n",
      "Episode 3767 finished after 2185 timesteps\n",
      "Total reward: 12917.879389530744, Epsilon: 0.617\n",
      "Episode 3768 finished after 599 timesteps\n",
      "Total reward: 5071.968255746705, Epsilon: 0.617\n",
      "Episode 3769 finished after 2318 timesteps\n",
      "Total reward: 15280.406875566838, Epsilon: 0.617\n",
      "Episode 3770 finished after 761 timesteps\n",
      "Total reward: 4519.8529463578, Epsilon: 0.617\n",
      "Episode 3771 finished after 3001 timesteps\n",
      "Total reward: 23431.883606349453, Epsilon: 0.617\n",
      "Episode 3772 finished after 3001 timesteps\n",
      "Total reward: 13394.14607639568, Epsilon: 0.617\n",
      "Episode 3773 finished after 805 timesteps\n",
      "Total reward: 4804.935610228578, Epsilon: 0.617\n",
      "Episode 3774 finished after 985 timesteps\n",
      "Total reward: 7439.0826467611305, Epsilon: 0.617\n",
      "Episode 3775 finished after 1526 timesteps\n",
      "Total reward: 6789.381037979441, Epsilon: 0.617\n",
      "Episode 3776 finished after 2454 timesteps\n",
      "Total reward: 14339.01990271858, Epsilon: 0.617\n",
      "Episode 3777 finished after 670 timesteps\n",
      "Total reward: 5159.706347612742, Epsilon: 0.617\n",
      "Episode 3778 finished after 485 timesteps\n",
      "Total reward: 3542.256383814249, Epsilon: 0.617\n",
      "Episode 3779 finished after 3001 timesteps\n",
      "Total reward: 17316.691504115457, Epsilon: 0.617\n",
      "Episode 3780 finished after 1515 timesteps\n",
      "Total reward: 9055.217128098566, Epsilon: 0.617\n",
      "Episode 3781 finished after 3001 timesteps\n",
      "Total reward: 15135.53759931192, Epsilon: 0.617\n",
      "Episode 3782 finished after 1942 timesteps\n",
      "Total reward: 12484.125412404483, Epsilon: 0.617\n",
      "Episode 3783 finished after 3001 timesteps\n",
      "Total reward: 14621.097260473707, Epsilon: 0.616\n",
      "Episode 3784 finished after 3001 timesteps\n",
      "Total reward: 14916.711561412763, Epsilon: 0.616\n",
      "Episode 3785 finished after 3001 timesteps\n",
      "Total reward: 14333.079230613994, Epsilon: 0.616\n",
      "Episode 3786 finished after 3001 timesteps\n",
      "Total reward: 17593.268316539088, Epsilon: 0.616\n",
      "Episode 3787 finished after 950 timesteps\n",
      "Total reward: 8150.174015206256, Epsilon: 0.616\n",
      "Episode 3788 finished after 1072 timesteps\n",
      "Total reward: 9022.682098833759, Epsilon: 0.616\n",
      "Episode 3789 finished after 3001 timesteps\n",
      "Total reward: 13330.469544329866, Epsilon: 0.616\n",
      "Episode 3790 finished after 3001 timesteps\n",
      "Total reward: 14243.145104106266, Epsilon: 0.616\n",
      "Episode 3791 finished after 1976 timesteps\n",
      "Total reward: 10678.66729892002, Epsilon: 0.616\n",
      "Episode 3792 finished after 2943 timesteps\n",
      "Total reward: 17141.470711620303, Epsilon: 0.616\n",
      "Episode 3793 finished after 3001 timesteps\n",
      "Total reward: 13705.637052574622, Epsilon: 0.616\n",
      "Episode 3794 finished after 2336 timesteps\n",
      "Total reward: 13619.071771350385, Epsilon: 0.616\n",
      "Episode 3795 finished after 2637 timesteps\n",
      "Total reward: 11864.303835445893, Epsilon: 0.616\n",
      "Episode 3796 finished after 1467 timesteps\n",
      "Total reward: 10563.570593985518, Epsilon: 0.616\n",
      "Episode 3797 finished after 2552 timesteps\n",
      "Total reward: 12759.2173012883, Epsilon: 0.616\n",
      "Episode 3798 finished after 739 timesteps\n",
      "Total reward: 4270.4646894320795, Epsilon: 0.616\n",
      "Episode 3799 finished after 2044 timesteps\n",
      "Total reward: 15797.029268654333, Epsilon: 0.615\n",
      "Episode 3800 finished after 431 timesteps\n",
      "Total reward: 3500.381193352208, Epsilon: 0.615\n",
      "Episode 3801 finished after 1112 timesteps\n",
      "Total reward: 8662.179101246855, Epsilon: 0.615\n",
      "Episode 3802 finished after 2055 timesteps\n",
      "Total reward: 9833.039850935465, Epsilon: 0.615\n",
      "Episode 3803 finished after 3001 timesteps\n",
      "Total reward: 14362.072581202447, Epsilon: 0.615\n",
      "Episode 3804 finished after 3001 timesteps\n",
      "Total reward: 14962.51207135098, Epsilon: 0.615\n",
      "Episode 3805 finished after 1861 timesteps\n",
      "Total reward: 9831.600633213407, Epsilon: 0.615\n",
      "Episode 3806 finished after 619 timesteps\n",
      "Total reward: 4642.696694523928, Epsilon: 0.615\n",
      "Episode 3807 finished after 1826 timesteps\n",
      "Total reward: 11522.203144597444, Epsilon: 0.615\n",
      "Episode 3808 finished after 905 timesteps\n",
      "Total reward: 6653.474756310174, Epsilon: 0.615\n",
      "Episode 3809 finished after 2845 timesteps\n",
      "Total reward: 13628.869086783629, Epsilon: 0.615\n",
      "Episode 3810 finished after 3001 timesteps\n",
      "Total reward: 13205.908193294264, Epsilon: 0.615\n",
      "Episode 3811 finished after 3001 timesteps\n",
      "Total reward: 14887.84016077203, Epsilon: 0.615\n",
      "Episode 3812 finished after 1771 timesteps\n",
      "Total reward: 8198.083255001922, Epsilon: 0.615\n",
      "Episode 3813 finished after 753 timesteps\n",
      "Total reward: 6528.2576354364655, Epsilon: 0.615\n",
      "Episode 3814 finished after 2098 timesteps\n",
      "Total reward: 10530.410668398361, Epsilon: 0.615\n",
      "Episode 3815 finished after 798 timesteps\n",
      "Total reward: 6061.925540579164, Epsilon: 0.614\n",
      "Episode 3816 finished after 688 timesteps\n",
      "Total reward: 4622.202279763247, Epsilon: 0.614\n",
      "Episode 3817 finished after 3001 timesteps\n",
      "Total reward: 13923.849268394328, Epsilon: 0.614\n",
      "Episode 3818 finished after 2029 timesteps\n",
      "Total reward: 12616.371884746693, Epsilon: 0.614\n",
      "Episode 3819 finished after 3001 timesteps\n",
      "Total reward: 16159.363458035705, Epsilon: 0.614\n",
      "Episode 3820 finished after 3001 timesteps\n",
      "Total reward: 17359.427228515087, Epsilon: 0.614\n",
      "Episode 3821 finished after 3001 timesteps\n",
      "Total reward: 13269.318009135912, Epsilon: 0.614\n",
      "Episode 3822 finished after 1540 timesteps\n",
      "Total reward: 9296.759887967835, Epsilon: 0.614\n",
      "Episode 3823 finished after 3001 timesteps\n",
      "Total reward: 15070.756089866443, Epsilon: 0.614\n",
      "Episode 3824 finished after 844 timesteps\n",
      "Total reward: 4393.935651484588, Epsilon: 0.614\n",
      "Episode 3825 finished after 594 timesteps\n",
      "Total reward: 5786.56073212079, Epsilon: 0.614\n",
      "Episode 3826 finished after 2497 timesteps\n",
      "Total reward: 12440.122204230656, Epsilon: 0.614\n",
      "Episode 3827 finished after 3001 timesteps\n",
      "Total reward: 13909.01389487259, Epsilon: 0.614\n",
      "Episode 3828 finished after 1737 timesteps\n",
      "Total reward: 9779.425835825037, Epsilon: 0.614\n",
      "Episode 3829 finished after 3001 timesteps\n",
      "Total reward: 14049.577873131255, Epsilon: 0.614\n",
      "Episode 3830 finished after 1324 timesteps\n",
      "Total reward: 7790.859908193072, Epsilon: 0.614\n",
      "Episode 3831 finished after 3001 timesteps\n",
      "Total reward: 14459.14328104698, Epsilon: 0.613\n",
      "Episode 3832 finished after 1496 timesteps\n",
      "Total reward: 10564.775877135693, Epsilon: 0.613\n",
      "Episode 3833 finished after 3001 timesteps\n",
      "Total reward: 14503.775061008393, Epsilon: 0.613\n",
      "Episode 3834 finished after 3001 timesteps\n",
      "Total reward: 17373.18185422029, Epsilon: 0.613\n",
      "Episode 3835 finished after 3001 timesteps\n",
      "Total reward: 14432.154009876194, Epsilon: 0.613\n",
      "Episode 3836 finished after 1022 timesteps\n",
      "Total reward: 5004.349787969869, Epsilon: 0.613\n",
      "Episode 3837 finished after 1914 timesteps\n",
      "Total reward: 12138.37149223519, Epsilon: 0.613\n",
      "Episode 3838 finished after 3001 timesteps\n",
      "Total reward: 16633.916712401504, Epsilon: 0.613\n",
      "Episode 3839 finished after 307 timesteps\n",
      "Total reward: 2262.6388909924212, Epsilon: 0.613\n",
      "Episode 3840 finished after 3001 timesteps\n",
      "Total reward: 17742.58556707778, Epsilon: 0.613\n",
      "Episode 3841 finished after 192 timesteps\n",
      "Total reward: 2074.9176682486604, Epsilon: 0.613\n",
      "Episode 3842 finished after 2789 timesteps\n",
      "Total reward: 16626.374116333493, Epsilon: 0.613\n",
      "Episode 3843 finished after 1633 timesteps\n",
      "Total reward: 9923.808046803186, Epsilon: 0.613\n",
      "Episode 3844 finished after 680 timesteps\n",
      "Total reward: 3867.762918623951, Epsilon: 0.613\n",
      "Episode 3845 finished after 1016 timesteps\n",
      "Total reward: 6644.745742518512, Epsilon: 0.613\n",
      "Episode 3846 finished after 1064 timesteps\n",
      "Total reward: 5553.368236468267, Epsilon: 0.613\n",
      "Episode 3847 finished after 3001 timesteps\n",
      "Total reward: 14121.062057479594, Epsilon: 0.613\n",
      "Episode 3848 finished after 1777 timesteps\n",
      "Total reward: 12064.222536584322, Epsilon: 0.612\n",
      "Episode 3849 finished after 3001 timesteps\n",
      "Total reward: 14376.675409454363, Epsilon: 0.612\n",
      "Episode 3850 finished after 1603 timesteps\n",
      "Total reward: 11553.604131368187, Epsilon: 0.612\n",
      "Episode 3851 finished after 3001 timesteps\n",
      "Total reward: 15902.442886129715, Epsilon: 0.612\n",
      "Episode 3852 finished after 342 timesteps\n",
      "Total reward: 2460.059978326028, Epsilon: 0.612\n",
      "Episode 3853 finished after 3001 timesteps\n",
      "Total reward: 12684.689596191794, Epsilon: 0.612\n",
      "Episode 3854 finished after 3001 timesteps\n",
      "Total reward: 15977.324627679922, Epsilon: 0.612\n",
      "Episode 3855 finished after 3001 timesteps\n",
      "Total reward: 12019.693233000358, Epsilon: 0.612\n",
      "Episode 3856 finished after 1664 timesteps\n",
      "Total reward: 7869.081510626189, Epsilon: 0.612\n",
      "Episode 3857 finished after 2656 timesteps\n",
      "Total reward: 12778.337930113508, Epsilon: 0.612\n",
      "Episode 3858 finished after 1380 timesteps\n",
      "Total reward: 7431.332411811178, Epsilon: 0.612\n",
      "Episode 3859 finished after 2015 timesteps\n",
      "Total reward: 11626.372000571866, Epsilon: 0.612\n",
      "Episode 3860 finished after 547 timesteps\n",
      "Total reward: 3803.0620002552114, Epsilon: 0.612\n",
      "Episode 3861 finished after 320 timesteps\n",
      "Total reward: 2355.343998126724, Epsilon: 0.612\n",
      "Episode 3862 finished after 552 timesteps\n",
      "Total reward: 4088.732220768509, Epsilon: 0.612\n",
      "Episode 3863 finished after 2750 timesteps\n",
      "Total reward: 14354.159733919134, Epsilon: 0.612\n",
      "Episode 3864 finished after 2680 timesteps\n",
      "Total reward: 12458.338645689973, Epsilon: 0.611\n",
      "Episode 3865 finished after 3001 timesteps\n",
      "Total reward: 16370.53929899564, Epsilon: 0.611\n",
      "Episode 3866 finished after 3001 timesteps\n",
      "Total reward: 13774.737095493456, Epsilon: 0.611\n",
      "Episode 3867 finished after 2754 timesteps\n",
      "Total reward: 12157.093314464986, Epsilon: 0.611\n",
      "Episode 3868 finished after 507 timesteps\n",
      "Total reward: 3734.1427973902555, Epsilon: 0.611\n",
      "Episode 3869 finished after 2165 timesteps\n",
      "Total reward: 11383.028875930799, Epsilon: 0.611\n",
      "Episode 3870 finished after 2386 timesteps\n",
      "Total reward: 12521.402068579591, Epsilon: 0.611\n",
      "Episode 3871 finished after 628 timesteps\n",
      "Total reward: 4283.79233745105, Epsilon: 0.611\n",
      "Episode 3872 finished after 1545 timesteps\n",
      "Total reward: 8103.922116998339, Epsilon: 0.611\n",
      "Episode 3873 finished after 3001 timesteps\n",
      "Total reward: 14415.861401099342, Epsilon: 0.611\n",
      "Episode 3874 finished after 664 timesteps\n",
      "Total reward: 4328.225761676043, Epsilon: 0.611\n",
      "Episode 3875 finished after 488 timesteps\n",
      "Total reward: 3854.6344018937198, Epsilon: 0.611\n",
      "Episode 3876 finished after 3001 timesteps\n",
      "Total reward: 13404.461613964644, Epsilon: 0.611\n",
      "Episode 3877 finished after 3001 timesteps\n",
      "Total reward: 14174.979270480604, Epsilon: 0.611\n",
      "Episode 3878 finished after 1432 timesteps\n",
      "Total reward: 8025.332254863021, Epsilon: 0.611\n",
      "Episode 3879 finished after 885 timesteps\n",
      "Total reward: 6096.243513330319, Epsilon: 0.611\n",
      "Episode 3880 finished after 924 timesteps\n",
      "Total reward: 5171.1489021674515, Epsilon: 0.610\n",
      "Episode 3881 finished after 2265 timesteps\n",
      "Total reward: 14143.301287219148, Epsilon: 0.610\n",
      "Episode 3882 finished after 2282 timesteps\n",
      "Total reward: 11874.091352744636, Epsilon: 0.610\n",
      "Episode 3883 finished after 2973 timesteps\n",
      "Total reward: 16648.924254414575, Epsilon: 0.610\n",
      "Episode 3884 finished after 1379 timesteps\n",
      "Total reward: 5766.0938503218, Epsilon: 0.610\n",
      "Episode 3885 finished after 2204 timesteps\n",
      "Total reward: 12266.179051699488, Epsilon: 0.610\n",
      "Episode 3886 finished after 3001 timesteps\n",
      "Total reward: 13397.947864510697, Epsilon: 0.610\n",
      "Episode 3887 finished after 2264 timesteps\n",
      "Total reward: 12192.152050676686, Epsilon: 0.610\n",
      "Episode 3888 finished after 3001 timesteps\n",
      "Total reward: 14714.843085948327, Epsilon: 0.610\n",
      "Episode 3889 finished after 2429 timesteps\n",
      "Total reward: 14086.116607890217, Epsilon: 0.610\n",
      "Episode 3890 finished after 2813 timesteps\n",
      "Total reward: 15356.494655755881, Epsilon: 0.610\n",
      "Episode 3891 finished after 3001 timesteps\n",
      "Total reward: 15336.632625389657, Epsilon: 0.610\n",
      "Episode 3892 finished after 1331 timesteps\n",
      "Total reward: 9372.026798701321, Epsilon: 0.610\n",
      "Episode 3893 finished after 3001 timesteps\n",
      "Total reward: 12992.452966087922, Epsilon: 0.610\n",
      "Episode 3894 finished after 960 timesteps\n",
      "Total reward: 5935.104570096671, Epsilon: 0.610\n",
      "Episode 3895 finished after 3001 timesteps\n",
      "Total reward: 12560.260835580335, Epsilon: 0.610\n",
      "Episode 3896 finished after 1521 timesteps\n",
      "Total reward: 7086.50859184424, Epsilon: 0.610\n",
      "Episode 3897 finished after 1103 timesteps\n",
      "Total reward: 6569.215555036748, Epsilon: 0.609\n",
      "Episode 3898 finished after 649 timesteps\n",
      "Total reward: 4973.908430009501, Epsilon: 0.609\n",
      "Episode 3899 finished after 3001 timesteps\n",
      "Total reward: 16146.303452915558, Epsilon: 0.609\n",
      "Episode 3900 finished after 777 timesteps\n",
      "Total reward: 5557.448132065272, Epsilon: 0.609\n",
      "Episode 3901 finished after 1722 timesteps\n",
      "Total reward: 11425.259300430424, Epsilon: 0.609\n",
      "Episode 3902 finished after 985 timesteps\n",
      "Total reward: 6661.177988929136, Epsilon: 0.609\n",
      "Episode 3903 finished after 2445 timesteps\n",
      "Total reward: 13392.706003193063, Epsilon: 0.609\n",
      "Episode 3904 finished after 3001 timesteps\n",
      "Total reward: 14184.243928133941, Epsilon: 0.609\n",
      "Episode 3905 finished after 3001 timesteps\n",
      "Total reward: 14077.138389634934, Epsilon: 0.609\n",
      "Episode 3906 finished after 815 timesteps\n",
      "Total reward: 5897.573789394997, Epsilon: 0.609\n",
      "Episode 3907 finished after 1593 timesteps\n",
      "Total reward: 8291.511776421336, Epsilon: 0.609\n",
      "Episode 3908 finished after 479 timesteps\n",
      "Total reward: 3279.017841121933, Epsilon: 0.609\n",
      "Episode 3909 finished after 1244 timesteps\n",
      "Total reward: 9367.067227956522, Epsilon: 0.609\n",
      "Episode 3910 finished after 731 timesteps\n",
      "Total reward: 4915.928723611929, Epsilon: 0.609\n",
      "Episode 3911 finished after 754 timesteps\n",
      "Total reward: 4804.324163142956, Epsilon: 0.609\n",
      "Episode 3912 finished after 3001 timesteps\n",
      "Total reward: 13580.043991554285, Epsilon: 0.609\n",
      "Episode 3913 finished after 3001 timesteps\n",
      "Total reward: 12787.791075653475, Epsilon: 0.608\n",
      "Episode 3914 finished after 898 timesteps\n",
      "Total reward: 7254.899027279323, Epsilon: 0.608\n",
      "Episode 3915 finished after 2256 timesteps\n",
      "Total reward: 12658.626903067294, Epsilon: 0.608\n",
      "Episode 3916 finished after 1825 timesteps\n",
      "Total reward: 9038.005974536965, Epsilon: 0.608\n",
      "Episode 3917 finished after 3001 timesteps\n",
      "Total reward: 15566.805027486234, Epsilon: 0.608\n",
      "Episode 3918 finished after 2490 timesteps\n",
      "Total reward: 13112.914108242443, Epsilon: 0.608\n",
      "Episode 3919 finished after 2186 timesteps\n",
      "Total reward: 9508.4690240792, Epsilon: 0.608\n",
      "Episode 3920 finished after 1661 timesteps\n",
      "Total reward: 8937.97053919927, Epsilon: 0.608\n",
      "Episode 3921 finished after 3001 timesteps\n",
      "Total reward: 11892.527396768724, Epsilon: 0.608\n",
      "Episode 3922 finished after 2383 timesteps\n",
      "Total reward: 12693.752118455623, Epsilon: 0.608\n",
      "Episode 3923 finished after 1029 timesteps\n",
      "Total reward: 4930.93620364211, Epsilon: 0.608\n",
      "Episode 3924 finished after 2358 timesteps\n",
      "Total reward: 11267.30926145607, Epsilon: 0.608\n",
      "Episode 3925 finished after 3001 timesteps\n",
      "Total reward: 12994.69178227538, Epsilon: 0.608\n",
      "Episode 3926 finished after 3001 timesteps\n",
      "Total reward: 14173.33118438278, Epsilon: 0.608\n",
      "Episode 3927 finished after 3001 timesteps\n",
      "Total reward: 16982.860963606785, Epsilon: 0.608\n",
      "Episode 3928 finished after 3001 timesteps\n",
      "Total reward: 13219.906584317469, Epsilon: 0.608\n",
      "Episode 3929 finished after 3001 timesteps\n",
      "Total reward: 12296.488421160086, Epsilon: 0.608\n",
      "Episode 3930 finished after 3001 timesteps\n",
      "Total reward: 12906.526786479752, Epsilon: 0.607\n",
      "Episode 3931 finished after 1982 timesteps\n",
      "Total reward: 10470.880433655486, Epsilon: 0.607\n",
      "Episode 3932 finished after 3001 timesteps\n",
      "Total reward: 17514.167245537006, Epsilon: 0.607\n",
      "Episode 3933 finished after 3001 timesteps\n",
      "Total reward: 12645.130763991547, Epsilon: 0.607\n",
      "Episode 3934 finished after 670 timesteps\n",
      "Total reward: 5337.419350097342, Epsilon: 0.607\n",
      "Episode 3935 finished after 2467 timesteps\n",
      "Total reward: 13659.58006310438, Epsilon: 0.607\n",
      "Episode 3936 finished after 990 timesteps\n",
      "Total reward: 6188.664479961975, Epsilon: 0.607\n",
      "Episode 3937 finished after 3001 timesteps\n",
      "Total reward: 15183.474500969565, Epsilon: 0.607\n",
      "Episode 3938 finished after 563 timesteps\n",
      "Total reward: 4117.805421210876, Epsilon: 0.607\n",
      "Episode 3939 finished after 715 timesteps\n",
      "Total reward: 4001.053448498902, Epsilon: 0.607\n",
      "Episode 3940 finished after 3001 timesteps\n",
      "Total reward: 15832.792286905062, Epsilon: 0.607\n",
      "Episode 3941 finished after 3001 timesteps\n",
      "Total reward: 13711.20972657472, Epsilon: 0.607\n",
      "Episode 3942 finished after 1671 timesteps\n",
      "Total reward: 9802.911674460302, Epsilon: 0.607\n",
      "Episode 3943 finished after 2699 timesteps\n",
      "Total reward: 15153.033932661081, Epsilon: 0.607\n",
      "Episode 3944 finished after 3001 timesteps\n",
      "Total reward: 14167.857307320168, Epsilon: 0.607\n",
      "Episode 3945 finished after 1548 timesteps\n",
      "Total reward: 10455.032554068586, Epsilon: 0.607\n",
      "Episode 3946 finished after 1334 timesteps\n",
      "Total reward: 6948.015310493067, Epsilon: 0.606\n",
      "Episode 3947 finished after 3001 timesteps\n",
      "Total reward: 12198.260907723667, Epsilon: 0.606\n",
      "Episode 3948 finished after 956 timesteps\n",
      "Total reward: 6918.5284875045845, Epsilon: 0.606\n",
      "Episode 3949 finished after 962 timesteps\n",
      "Total reward: 5631.16753246631, Epsilon: 0.606\n",
      "Episode 3950 finished after 1413 timesteps\n",
      "Total reward: 8175.728339805448, Epsilon: 0.606\n",
      "Episode 3951 finished after 3001 timesteps\n",
      "Total reward: 14209.567100128555, Epsilon: 0.606\n",
      "Episode 3952 finished after 1465 timesteps\n",
      "Total reward: 7591.989629166923, Epsilon: 0.606\n",
      "Episode 3953 finished after 1333 timesteps\n",
      "Total reward: 9141.891423040335, Epsilon: 0.606\n",
      "Episode 3954 finished after 265 timesteps\n",
      "Total reward: 1946.8167985468822, Epsilon: 0.606\n",
      "Episode 3955 finished after 1321 timesteps\n",
      "Total reward: 7858.834910174084, Epsilon: 0.606\n",
      "Episode 3956 finished after 1747 timesteps\n",
      "Total reward: 10929.549346455262, Epsilon: 0.606\n",
      "Episode 3957 finished after 634 timesteps\n",
      "Total reward: 3983.015069273767, Epsilon: 0.606\n",
      "Episode 3958 finished after 2465 timesteps\n",
      "Total reward: 14361.994509822422, Epsilon: 0.606\n",
      "Episode 3959 finished after 3001 timesteps\n",
      "Total reward: 15220.665248302192, Epsilon: 0.606\n",
      "Episode 3960 finished after 2985 timesteps\n",
      "Total reward: 13645.604008974226, Epsilon: 0.606\n",
      "Episode 3961 finished after 793 timesteps\n",
      "Total reward: 3966.8085707893124, Epsilon: 0.606\n",
      "Episode 3962 finished after 891 timesteps\n",
      "Total reward: 6076.066469487695, Epsilon: 0.606\n",
      "Episode 3963 finished after 3001 timesteps\n",
      "Total reward: 14738.819157302823, Epsilon: 0.605\n",
      "Episode 3964 finished after 771 timesteps\n",
      "Total reward: 4045.20481703942, Epsilon: 0.605\n",
      "Episode 3965 finished after 2147 timesteps\n",
      "Total reward: 12466.946234134468, Epsilon: 0.605\n",
      "Episode 3966 finished after 3001 timesteps\n",
      "Total reward: 12748.307816757133, Epsilon: 0.605\n",
      "Episode 3967 finished after 3001 timesteps\n",
      "Total reward: 14357.032188407053, Epsilon: 0.605\n",
      "Episode 3968 finished after 3001 timesteps\n",
      "Total reward: 13195.5419436128, Epsilon: 0.605\n",
      "Episode 3969 finished after 1794 timesteps\n",
      "Total reward: 8594.041142912754, Epsilon: 0.605\n",
      "Episode 3970 finished after 2323 timesteps\n",
      "Total reward: 13708.724612454595, Epsilon: 0.605\n",
      "Episode 3971 finished after 1819 timesteps\n",
      "Total reward: 11731.670028482302, Epsilon: 0.605\n",
      "Episode 3972 finished after 373 timesteps\n",
      "Total reward: 2765.472598519402, Epsilon: 0.605\n",
      "Episode 3973 finished after 3001 timesteps\n",
      "Total reward: 18289.483254227056, Epsilon: 0.605\n",
      "Episode 3974 finished after 350 timesteps\n",
      "Total reward: 2632.2790054235807, Epsilon: 0.605\n",
      "Episode 3975 finished after 1587 timesteps\n",
      "Total reward: 9151.149384337985, Epsilon: 0.605\n",
      "Episode 3976 finished after 1406 timesteps\n",
      "Total reward: 10273.099001211065, Epsilon: 0.605\n",
      "Episode 3977 finished after 275 timesteps\n",
      "Total reward: 2296.952869251851, Epsilon: 0.605\n",
      "Episode 3978 finished after 2096 timesteps\n",
      "Total reward: 12920.160159508829, Epsilon: 0.605\n",
      "Episode 3979 finished after 2012 timesteps\n",
      "Total reward: 11469.060681385052, Epsilon: 0.604\n",
      "Episode 3980 finished after 3001 timesteps\n",
      "Total reward: 13172.552219041187, Epsilon: 0.604\n",
      "Episode 3981 finished after 840 timesteps\n",
      "Total reward: 5383.31150656727, Epsilon: 0.604\n",
      "Episode 3982 finished after 3001 timesteps\n",
      "Total reward: 13672.15382382712, Epsilon: 0.604\n",
      "Episode 3983 finished after 3001 timesteps\n",
      "Total reward: 13921.732132944877, Epsilon: 0.604\n",
      "Episode 3984 finished after 385 timesteps\n",
      "Total reward: 2940.1050040051878, Epsilon: 0.604\n",
      "Episode 3985 finished after 2492 timesteps\n",
      "Total reward: 12113.261061308453, Epsilon: 0.604\n",
      "Episode 3986 finished after 3001 timesteps\n",
      "Total reward: 12718.941962844321, Epsilon: 0.604\n",
      "Episode 3987 finished after 2233 timesteps\n",
      "Total reward: 11824.85155310292, Epsilon: 0.604\n",
      "Episode 3988 finished after 2719 timesteps\n",
      "Total reward: 16040.83507351439, Epsilon: 0.604\n",
      "Episode 3989 finished after 1351 timesteps\n",
      "Total reward: 9545.338126828165, Epsilon: 0.604\n",
      "Episode 3990 finished after 3001 timesteps\n",
      "Total reward: 16210.93129063528, Epsilon: 0.604\n",
      "Episode 3991 finished after 3001 timesteps\n",
      "Total reward: 15511.801712173161, Epsilon: 0.604\n",
      "Episode 3992 finished after 503 timesteps\n",
      "Total reward: 3704.42248389789, Epsilon: 0.604\n",
      "Episode 3993 finished after 881 timesteps\n",
      "Total reward: 4759.371700454807, Epsilon: 0.604\n",
      "Episode 3994 finished after 2604 timesteps\n",
      "Total reward: 14756.33634532625, Epsilon: 0.604\n",
      "Episode 3995 finished after 2592 timesteps\n",
      "Total reward: 14175.433403853953, Epsilon: 0.604\n",
      "Episode 3996 finished after 1274 timesteps\n",
      "Total reward: 6722.363618639886, Epsilon: 0.603\n",
      "Episode 3997 finished after 3001 timesteps\n",
      "Total reward: 13313.813954303292, Epsilon: 0.603\n",
      "Episode 3998 finished after 2279 timesteps\n",
      "Total reward: 11398.300178637366, Epsilon: 0.603\n",
      "Episode 3999 finished after 3001 timesteps\n",
      "Total reward: 13099.838103189855, Epsilon: 0.603\n"
     ]
    }
   ],
   "source": [
    "EPSILON = 0.9\n",
    "ALPHA = 0.1\n",
    "GAMMA = 0.6\n",
    "DECAY = 0.999\n",
    "MINEPSILON = 0.1\n",
    "DECAY_RATE = 0.9999\n",
    "\n",
    "\n",
    "env = RCMazeEnv()\n",
    "agent = QAgent(alpha=ALPHA, gamma=GAMMA, epsilon=EPSILON, min_epsilon=MINEPSILON, epsilon_decay=DECAY_RATE)\n",
    "# env.init_pygame()\n",
    "rewards = agent.train(env, 4000)\n",
    "# env.close_pygame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot rewards\n",
    "plt.plot(rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Reward History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test Q-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Total Reward: 11763.933972613984\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "env = RCMazeEnv()\n",
    "\n",
    "env.init_pygame()\n",
    "\n",
    "# Example of running the environment\n",
    "agent.test(env)\n",
    "\n",
    "\n",
    "env.close_pygame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close_pygame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusions\n",
    "\n",
    "After testing it is clear that it is able to solve the enivronment. But not at all efficient, the car gets stuck multiple times and will take go backwards often. (This is probably caused by the over engineered reward function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 12:45:28.709201: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-08 12:45:28.725898: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-08 12:45:28.725920: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-08 12:45:28.726416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-08 12:45:28.729726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-08 12:45:29.103754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np   \n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "# Import Tensorflow libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# disable eager execution (optimization)\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 12:45:29.960574: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 12:45:29.976580: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 12:45:29.976681: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "###### Tensorflow-GPU ########\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import pygame\n",
    "\n",
    "class RCMazeEnv(gym.Env):\n",
    "    def __init__(self, maze_size_x=12, maze_size_y=12):\n",
    "        self.maze_size_x = maze_size_x\n",
    "        self.maze_size_y = maze_size_y\n",
    "        self.maze = self.generate_maze()\n",
    "        self.car_position = (1, 1)\n",
    "        self.possible_actions = range(3)\n",
    "        self.car_orientation = 'N'\n",
    "        self.sensor_readings = {'front': 0, 'left': 0, 'right': 0}\n",
    "        self.steps = 0\n",
    "        self.previous_distance = 0\n",
    "        self.goal = (10, 10)\n",
    "        self.previous_steps = 0\n",
    "        self.visited_positions = set()\n",
    "        self.reset()\n",
    "\n",
    "            \n",
    "    def generate_maze(self):\n",
    "        # For simplicity, create a static maze with walls\n",
    "        # '1' represents a wall, and '0' represents an open path\n",
    "        maze = np.zeros((self.maze_size_y, self.maze_size_x), dtype=int)\n",
    "        # Add walls to the maze (this can be customized)\n",
    "\n",
    "        \n",
    "        layout = [\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
    "            [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
    "            [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
    "            [1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
    "            [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1],\n",
    "            [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "        \n",
    "     \n",
    "        maze = np.array(layout)\n",
    "\n",
    "        return maze\n",
    "\n",
    "    def reset(self):\n",
    "        self.car_position = (1, 1)\n",
    "        self.car_orientation = 'N'\n",
    "        self.update_sensor_readings()\n",
    "        self.steps = 0\n",
    "        self.previous_distance = 0\n",
    "        self.previous_steps = 0\n",
    "        self.visited_positions.clear()  # Clear the visited positions\n",
    "        self.visited_positions.add(self.car_position)\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.move_forward()\n",
    "        elif action == 1:\n",
    "            self.turn_left()\n",
    "        elif action == 2:\n",
    "            self.turn_right()\n",
    "        self.update_sensor_readings()\n",
    "        self.visited_positions.add(self.car_position)\n",
    "        reward = self.compute_reward()\n",
    "        self.steps += 1\n",
    "        done = self.is_done()\n",
    "        return self.get_state(), reward, done\n",
    "\n",
    "    \n",
    "    def move_forward(self):\n",
    "        x, y = self.car_position\n",
    "        if self.car_orientation == 'N' and y > 0 and self.maze[y - 1][x] != 1:\n",
    "            self.car_position = (x, y - 1)\n",
    "        elif self.car_orientation == 'S' and y < self.maze_size_y - 1 and self.maze[y + 1][x] != 1:\n",
    "            self.car_position = (x, y + 1)\n",
    "        elif self.car_orientation == 'E' and x < self.maze_size_x - 1 and self.maze[y][x + 1] != 1:\n",
    "            self.car_position = (x + 1, y)\n",
    "        elif self.car_orientation == 'W' and x > 0 and self.maze[y][x - 1] != 1:\n",
    "            self.car_position = (x - 1, y)\n",
    "        \n",
    "\n",
    "    def turn_left(self):\n",
    "        orientations = ['N', 'W', 'S', 'E']\n",
    "        idx = orientations.index(self.car_orientation)\n",
    "        self.car_orientation = orientations[(idx + 1) % 4]\n",
    "\n",
    "    def turn_right(self):\n",
    "        orientations = ['N', 'E', 'S', 'W']\n",
    "        idx = orientations.index(self.car_orientation)\n",
    "        self.car_orientation = orientations[(idx + 1) % 4]\n",
    "\n",
    "    def update_sensor_readings(self):\n",
    "        # Simple sensor implementation: counts steps to the nearest wall\n",
    "        self.sensor_readings['front'] = self.distance_to_wall('front')\n",
    "        self.sensor_readings['left'] = self.distance_to_wall('left')\n",
    "        self.sensor_readings['right'] = self.distance_to_wall('right')\n",
    "\n",
    "    def distance_to_wall(self, direction):\n",
    "        x, y = self.car_position\n",
    "        distance = 0\n",
    "        max_distance = self.maze_size_x if direction in ['left', 'right'] else self.maze_size_y\n",
    "\n",
    "        \n",
    "        if direction == 'front':\n",
    "            if self.car_orientation == 'N':\n",
    "                while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'S':\n",
    "                while y + distance < self.maze_size_y and self.maze[y + distance][x] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'E':\n",
    "                while x + distance < self.maze_size_x and self.maze[y][x + distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'W':\n",
    "                while x - distance >= 0 and self.maze[y][x - distance] != 1:\n",
    "                    distance += 1\n",
    "        elif direction == 'left':\n",
    "            if self.car_orientation == 'N':\n",
    "                while x - distance >= 0 and self.maze[y][x - distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'S':\n",
    "                while x + distance < self.maze_size_x and self.maze[y][x + distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'E':\n",
    "                while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'W':\n",
    "                while y + distance < self.maze_size_y and self.maze[y + distance][x] != 1:\n",
    "                    distance += 1\n",
    "        elif direction == 'right':\n",
    "            if self.car_orientation == 'N':\n",
    "                while x + distance < self.maze_size_x and self.maze[y][x + distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'S':\n",
    "                while x - distance >= 0 and self.maze[y][x - distance] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'E':\n",
    "                while y + distance < self.maze_size_y and self.maze[y + distance][x] != 1:\n",
    "                    distance += 1\n",
    "            elif self.car_orientation == 'W':\n",
    "                while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                    distance += 1\n",
    "        \n",
    "            # Normalize the measured distance\n",
    "        normalized_distance = (max_distance - distance - 1) / (max_distance - 1)\n",
    "\n",
    "        # Ensure the value is within the range [0, 1]\n",
    "        normalized_distance = max(0, min(normalized_distance, 1))\n",
    "\n",
    "        return normalized_distance\n",
    "    \n",
    "    def compute_reward(self):\n",
    "        # Initialize reward\n",
    "        reward = 0\n",
    "\n",
    "        # Check for collision or out of bounds\n",
    "        if any(self.sensor_readings[direction] == 0 for direction in ['front', 'left', 'right']):\n",
    "            reward -= 20\n",
    "\n",
    "        # Check if goal is reached\n",
    "        if self.car_position == self.goal:\n",
    "            reward += 500\n",
    "            # Additional penalty if it takes too many steps to reach the goal\n",
    "            if self.steps > 1000:\n",
    "                reward -= 200\n",
    "            return reward  # Return immediately as this is the terminal state\n",
    "\n",
    "        # Calculate the Euclidean distance to the goal\n",
    "        distance_to_goal = ((self.car_position[0] - self.goal[0]) ** 2 + (self.car_position[1] - self.goal[1]) ** 2) ** 0.5\n",
    "\n",
    "        # Define a maximum reward when the car is at the goal\n",
    "        max_reward_at_goal = 50\n",
    "\n",
    "        # Reward based on proximity to the goal\n",
    "        reward += max_reward_at_goal / (distance_to_goal + 1)  # Adding 1 to avoid division by zero\n",
    "\n",
    "        # # Reward or penalize based on movement towards or away from the goal\n",
    "        if distance_to_goal < self.previous_distance:\n",
    "            reward += 50  # Positive reward for moving closer to the goal\n",
    "        elif distance_to_goal > self.previous_distance:\n",
    "            reward -= 25  # Negative reward for moving farther from the goal\n",
    "\n",
    "        if self.car_position in self.visited_positions:\n",
    "            # Apply a penalty for revisiting the same position\n",
    "            reward -= 10\n",
    "            \n",
    "        # Penalize for each step taken to encourage efficiency\n",
    "        reward -= 2\n",
    "        \n",
    "        # Update the previous_distance for the next step\n",
    "        self.previous_distance = distance_to_goal\n",
    "        return reward\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def is_done(self):\n",
    "        #is done if it reaches the goal or goes out of bounds or takes more than 3000 steps\n",
    "        return self.car_position == self.goal or self.steps > 3000 or self.car_position[0] < 0 or self.car_position[1] < 0 or self.car_position[0] > 11 or self.car_position[1] > 11\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_state(self):\n",
    "        car_position = [float(coord) for coord in self.car_position]\n",
    "        sensor_readings = [float(value) for value in self.sensor_readings.values()]\n",
    "        \n",
    "        state = car_position + [self.car_orientation] + sensor_readings\n",
    "        \n",
    "        # cast state to this ['1.0' '1.0' 'N' '1.0' '1.0' '10.0']\n",
    "        state = np.array(state, dtype=str)\n",
    "        \n",
    "        #get the orientation and convert do label encoding\n",
    "        if state[2] == 'N':\n",
    "            state[2] = 0\n",
    "        elif state[2] == 'E':\n",
    "            state[2] = 1\n",
    "        elif state[2] == 'S':\n",
    "            state[2] = 2\n",
    "        elif state[2] == 'W':\n",
    "            state[2] = 3\n",
    "            \n",
    "        state = np.array(state, dtype=float)\n",
    "        \n",
    "        return state\n",
    "\n",
    "    \n",
    "    def init_pygame(self):\n",
    "        # Initialize Pygame and set up the display\n",
    "        pygame.init()\n",
    "        self.cell_size = 40  # Size of each cell in pixels\n",
    "        self.maze_size_x = 12  # Assuming the maze size_x is 12\n",
    "        self.maze_size_y = 12  # Assuming the maze size_y is 12\n",
    "        self.width = 600\n",
    "        self.height = 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "    def render(self, framerate=60, delay=0):\n",
    "        # Render the environment using Pygame\n",
    "        for y in range(self.maze_size_y):\n",
    "            for x in range(self.maze_size_x):\n",
    "                rect = pygame.Rect(x * self.cell_size, y * self.cell_size, self.cell_size, self.cell_size)\n",
    "                if (x, y) == self.goal:  # Goal position\n",
    "                    color = (0, 255, 0)  # Green color for the goal\n",
    "                elif self.maze[y][x] == 0:\n",
    "                    color = (255, 255, 255)  # White color for empty space\n",
    "                else:\n",
    "                    color = (0, 0, 0)  # Black color for walls\n",
    "                pygame.draw.rect(self.screen, color, rect)\n",
    "        \n",
    "        # Draw the car\n",
    "        car_x, car_y = self.car_position\n",
    "        car_rect = pygame.Rect(car_x * self.cell_size, car_y * self.cell_size, self.cell_size, self.cell_size)\n",
    "        pygame.draw.rect(self.screen, (255, 0, 0), car_rect)  # Red color for the car\n",
    "        pygame.time.delay(delay)\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(framerate)  # Limit the frame rate to 60 FPS\n",
    "\n",
    "\n",
    "    def close_pygame(self):\n",
    "        # Close the Pygame window\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "class DQAgent:\n",
    "    def __init__(self, replayCapacity, inputShape, outputShape):\n",
    "        ## Initialize replay memory\n",
    "        self.capacity = replayCapacity\n",
    "        self.memory = collections.deque(maxlen=self.capacity)\n",
    "        self.populated = False\n",
    "        ## Policiy model\n",
    "        self.inputShape = inputShape\n",
    "        self.outputShape = outputShape\n",
    "        self.policy_model = self.buildNetwork()\n",
    "\n",
    "        ## Target model\n",
    "        self.target_model = self.buildNetwork()\n",
    "        self.target_model.set_weights(self.policy_model.get_weights())\n",
    "\n",
    "    def addToReplayMemory(self, step):\n",
    "        self.step = step\n",
    "        self.memory.append(self.step)\n",
    "\n",
    "    def sampleFromReplayMemory(self, batchSize):\n",
    "        self.batchSize = batchSize\n",
    "        if self.batchSize > len(self.memory):\n",
    "            self.populated = False\n",
    "            return self.populated\n",
    "        else:\n",
    "            return random.sample(self.memory, self.batchSize)\n",
    "\n",
    "\n",
    "    def buildNetwork(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_shape=self.inputShape, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(self.outputShape, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['MeanSquaredError'])\n",
    "        return model\n",
    "\n",
    "    def policy_network_fit(self,batch, batchSize):\n",
    "        self.batchSize = batchSize\n",
    "        self.batch = batch\n",
    "\n",
    "\n",
    "    def policy_network_predict(self, state):\n",
    "        self.state = state\n",
    "        self.qPolicy = self.policy_model.predict(self.state)\n",
    "        return self.qPolicy\n",
    "\n",
    "    def target_network_predict(self, state):\n",
    "        self.state = state\n",
    "        self.qTarget = self.target_model.predict(self.state)\n",
    "        return self.qTarget\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_model.set_weights(self.policy_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 12:45:50.173062: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 12:45:50.173164: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 12:45:50.173207: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 12:45:50.226151: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 12:45:50.226229: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 12:45:50.226279: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 12:45:50.226323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12222 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-01-08 12:45:50.230526: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-08 12:45:50.243773: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_6/bias/Assign' id:207 op device:{requested: '', assigned: ''} def:{{{node dense_6/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_6/bias, dense_6/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/home/lucasdriessens/.local/lib/python3.11/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2024-01-08 12:45:50.547111: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_4/BiasAdd' id:121 op device:{requested: '', assigned: ''} def:{{{node dense_4/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_4/MatMul, dense_4/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-01-08 12:45:50.626951: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_9/BiasAdd' id:284 op device:{requested: '', assigned: ''} def:{{{node dense_9/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_9/MatMul, dense_9/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-01-08 12:45:50.689611: W tensorflow/c/c_api.cc:305] Operation '{name:'loss/mul' id:164 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/dense_4_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-01-08 12:45:50.703512: W tensorflow/c/c_api.cc:305] Operation '{name:'training/Adam/dense_4/bias/v/Assign' id:607 op device:{requested: '', assigned: ''} def:{{{node training/Adam/dense_4/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/dense_4/bias/v, training/Adam/dense_4/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodeReward for episode  0 =  -2485.9072786282477 with epsilon =  0.8807722660973293\n",
      "episodeReward for episode  1 =  -202.20886105172076 with epsilon =  0.845981153866556\n",
      "episodeReward for episode  2 =  336.92126257727546 with epsilon =  0.8088349164463933\n",
      "episodeReward for episode  3 =  1269.235143957906 with epsilon =  0.7893372089993652\n",
      "episodeReward for episode  4 =  -7881.940058086577 with epsilon =  0.5846881401775113\n",
      "episodeReward for episode  5 =  -9628.990299366791 with epsilon =  0.44955826643125446\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 84\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m             y[i,miniBatch_actions[i]] \u001b[38;5;241m=\u001b[39m miniBatch_rewards[i] \u001b[38;5;241m+\u001b[39m DISCOUNT \u001b[38;5;241m*\u001b[39m  max_q_next_state[i]\n\u001b[0;32m---> 84\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminiBatch_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m#todo: add early stopping\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/engine/training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    855\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/engine/training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m         )\n\u001b[1;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/engine/training_arrays_v1.py:285\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m epoch_logs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m ModeKeys\u001b[38;5;241m.\u001b[39mPREDICT:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Collecting and resetting metrics has non-zero cost and will\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# needlessly slow down model.predict.\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m ModeKeys\u001b[38;5;241m.\u001b[39mTRAIN:\n\u001b[1;32m    287\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch, epoch_logs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/engine/training_v1.py:1075\u001b[0m, in \u001b[0;36mModel.reset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1073\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_training_eval_metrics()\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[0;32m-> 1075\u001b[0m     \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;66;03m# Reset metrics on all the distributed (cloned) models.\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/metrics/base_metric.py:265\u001b[0m, in \u001b[0;36mMetric.reset_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/backend.py:4338\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   4336\u001b[0m     assign_ops\u001b[38;5;241m.\u001b[39mappend(assign_op)\n\u001b[1;32m   4337\u001b[0m     feed_dict[assign_placeholder] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m-> 4338\u001b[0m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43massign_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/client/session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/client/session.py:1215\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1215\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/client/session.py:1395\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/client/session.py:1402\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1401\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1404\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/client/session.py:1385\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1383\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/client/session.py:1478\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = RCMazeEnv()\n",
    "state = env.reset()\n",
    "\n",
    "env.init_pygame()\n",
    "\n",
    "# Model parameters\n",
    "REPLAY_MEMORY_CAPACITY = 20000\n",
    "# MIN_REPLAY_MEMORY_SIZE = 1_000  # Minimum number of steps in a memory to start training\n",
    "POSSIBLE_ACTIONS = env.possible_actions\n",
    "\n",
    "# state = state[0]\n",
    "# create DQN agent\n",
    "agent = DQAgent(replayCapacity=REPLAY_MEMORY_CAPACITY, inputShape=state.shape, outputShape=len(POSSIBLE_ACTIONS))\n",
    "\n",
    "\n",
    "# reset the parameters\n",
    "DISCOUNT = 0.90\n",
    "BATCH_SIZE = 64  # How many steps (samples) to use for training\n",
    "UPDATE_TARGET_INTERVAL = 500\n",
    "EPSILON = 0.99 # Exploration percentage\n",
    "MIN_EPSILON = 0.01\n",
    "DECAY = 0.9999\n",
    "EPISODE_AMOUNT = 170\n",
    "\n",
    "# Fill the replay memory with the first batch of samples\n",
    "updateCounter = 0\n",
    "rewardHistory = []\n",
    "epsilonHistory = []\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "for episode in range(EPISODE_AMOUNT):\n",
    "    episodeReward = 0\n",
    "    stepCounter = 0  # count the number of successful steps within the episode\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    epsilonHistory.append(EPSILON)\n",
    "\n",
    "    while not done:\n",
    "        env.render(delay=0, framerate=240)\n",
    "\n",
    "        if random.random() <= EPSILON:\n",
    "            action = random.sample(POSSIBLE_ACTIONS, 1)[0]\n",
    "        else:\n",
    "            qValues = agent.policy_network_predict(state.reshape(1,-1))\n",
    "            action = np.argmax(qValues[0])\n",
    "\n",
    "        newState, reward, done = env.step(action)\n",
    "\n",
    "        stepCounter +=1\n",
    "\n",
    "        # store step in replay memory\n",
    "        step = (state, action, reward, newState, done)\n",
    "        agent.addToReplayMemory(step)\n",
    "        state = newState\n",
    "        episodeReward += reward\n",
    "        # When enough steps in replay memory -> train policy network\n",
    "        if len(agent.memory) >= (BATCH_SIZE):\n",
    "            EPSILON = DECAY * EPSILON\n",
    "            if EPSILON < MIN_EPSILON:\n",
    "                EPSILON = MIN_EPSILON\n",
    "            # sample minibatch from replay memory\n",
    "            \n",
    "            miniBatch = agent.sampleFromReplayMemory(BATCH_SIZE)\n",
    "            miniBatch_states = np.asarray(list(zip(*miniBatch))[0],dtype=float)\n",
    "            miniBatch_actions = np.asarray(list(zip(*miniBatch))[1], dtype = int)\n",
    "            miniBatch_rewards = np.asarray(list(zip(*miniBatch))[2], dtype = float)\n",
    "            miniBatch_next_state = np.asarray(list(zip(*miniBatch))[3],dtype=float)\n",
    "            miniBatch_done = np.asarray(list(zip(*miniBatch))[4],dtype=bool)\n",
    "            \n",
    "            # current state q values1tch_states)\n",
    "            y = agent.policy_network_predict(miniBatch_states)\n",
    "\n",
    "            next_state_q_values = agent.target_network_predict(miniBatch_next_state)\n",
    "            max_q_next_state = np.max(next_state_q_values,axis=1)\n",
    "\n",
    "            for i in range(BATCH_SIZE):\n",
    "                if miniBatch_done[i]:\n",
    "                    y[i,miniBatch_actions[i]] = miniBatch_rewards[i]\n",
    "                else:\n",
    "                    y[i,miniBatch_actions[i]] = miniBatch_rewards[i] + DISCOUNT *  max_q_next_state[i]\n",
    "\n",
    "            agent.policy_model.fit(miniBatch_states, y, batch_size=2048, verbose = 0)\n",
    "            \n",
    "            #todo: add early stopping\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        if updateCounter == UPDATE_TARGET_INTERVAL:\n",
    "            agent.update_target_network()\n",
    "            updateCounter = 0\n",
    "        updateCounter += 1\n",
    "    print('episodeReward for episode ', episode, '= ', episodeReward, 'with epsilon = ', EPSILON)\n",
    "    env.render(delay=0, framerate=240)\n",
    "    rewardHistory.append(episodeReward)\n",
    "env.close_pygame()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close_pygame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot rewards\n",
    "plt.plot(rewardHistory)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Reward History for DQN')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucasdriessens/.local/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "agent.policy_model.save('./models/DQN_RCmaze_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 12:47:26.144459: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_29/kernel/Assign' id:1776 op device:{requested: '', assigned: ''} def:{{{node dense_29/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_29/kernel, dense_29/kernel/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-01-08 12:47:26.260517: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_52_1/bias/Assign' id:1951 op device:{requested: '', assigned: ''} def:{{{node dense_52_1/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_52_1/bias, dense_52_1/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-01-08 12:47:26.358993: W tensorflow/c/c_api.cc:305] Operation '{name:'total_7/Assign' id:2049 op device:{requested: '', assigned: ''} def:{{{node total_7/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](total_7, total_7/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-01-08 12:47:26.542194: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_54_1/BiasAdd' id:2004 op device:{requested: '', assigned: ''} def:{{{node dense_54_1/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_54_1/MatMul, dense_54_1/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in  34 steps\n",
      "1296.992428778307\n"
     ]
    }
   ],
   "source": [
    "# try it out\n",
    "# load model\n",
    "env = RCMazeEnv()\n",
    "state = env.reset()\n",
    "\n",
    "env.init_pygame()\n",
    "\n",
    "REPLAY_MEMORY_CAPACITY = 20000\n",
    "POSSIBLE_ACTIONS = env.possible_actions\n",
    "\n",
    "# create DQN agent\n",
    "test_agent = DQAgent(replayCapacity=REPLAY_MEMORY_CAPACITY, inputShape=state.shape, outputShape=len(POSSIBLE_ACTIONS))\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "test_agent.policy_model = load_model('./models/DQN_RCmaze_v2.h5')\n",
    "\n",
    "\n",
    "done = False\n",
    "\n",
    "rewards = []\n",
    "\n",
    "while not done:\n",
    "    env.render(delay=100, framerate=60)\n",
    "    xd = state\n",
    "    qValues = test_agent.policy_network_predict(np.array([state]))\n",
    "    action = np.argmax(qValues[0])\n",
    "    state, reward, done = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    \n",
    "    env.render()\n",
    "    if done:\n",
    "        print('done in ', len(rewards), 'steps')\n",
    "        break\n",
    "env.close()\n",
    "print(sum(rewards))\n",
    "env.close_pygame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot rewards and distance to goal\n",
    "plt.plot(rewards)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Reward History for DQN')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusions\n",
    "\n",
    "The DQN is able to solve the environment in 34 steps, which is a great improvement over the Q-agent. The car now goes straight to the goal, so this is something I can work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3d env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLUT import *\n",
    "from OpenGL.GLU import *\n",
    "\n",
    "import pygame\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCMazeEnv(gym.Env):\n",
    "   def __init__(self, maze_size_x=12, maze_size_y=12):\n",
    "      self.maze_size_x = maze_size_x\n",
    "      self.maze_size_y = maze_size_y\n",
    "      self.maze = self.generate_maze()\n",
    "      self.car_position = (1, 1)\n",
    "      self.possible_actions = range(3)\n",
    "      self.car_orientation = 'N'\n",
    "      self.sensor_readings = {'front': 0, 'left': 0, 'right': 0}\n",
    "      self.steps = 0\n",
    "      self.previous_distance = 0\n",
    "      self.goal = (10, 10)\n",
    "      self.previous_steps = 0\n",
    "      self.visited_positions = set()\n",
    "      self.reset()\n",
    "\n",
    "         \n",
    "   def generate_maze(self):\n",
    "      # For simplicity, create a static maze with walls\n",
    "      # '1' represents a wall, and '0' represents an open path\n",
    "      maze = np.zeros((self.maze_size_y, self.maze_size_x), dtype=int)\n",
    "      # Add walls to the maze (this can be customized)\n",
    "\n",
    "      \n",
    "      layout = [\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "         [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
    "         [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "         [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
    "         [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "         [1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
    "         [1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
    "         [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "         [1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1],\n",
    "         [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "      \n",
    "   \n",
    "      maze = np.array(layout)\n",
    "\n",
    "      return maze\n",
    "\n",
    "   def reset(self):\n",
    "      self.car_position = (1, 1)\n",
    "      self.car_orientation = 'N'\n",
    "      self.update_sensor_readings()\n",
    "      self.steps = 0\n",
    "      self.previous_distance = 0\n",
    "      self.previous_steps = 0\n",
    "      self.visited_positions.clear()  # Clear the visited positions\n",
    "      self.visited_positions.add(self.car_position)\n",
    "      return self.get_state()\n",
    "\n",
    "   def step(self, action):\n",
    "      if action == 0:\n",
    "         self.move_forward()\n",
    "      elif action == 1:\n",
    "         self.turn_left()\n",
    "      elif action == 2:\n",
    "         self.turn_right()\n",
    "      self.update_sensor_readings()\n",
    "      self.visited_positions.add(self.car_position)\n",
    "      reward = self.compute_reward()\n",
    "      self.steps += 1\n",
    "      done = self.is_done()\n",
    "      return self.get_state(), reward, done\n",
    "\n",
    "   \n",
    "   def move_forward(self):\n",
    "      x, y = self.car_position\n",
    "      if self.car_orientation == 'N' and y > 0 and self.maze[y - 1][x] != 1:\n",
    "         self.car_position = (x, y - 1)\n",
    "      elif self.car_orientation == 'S' and y < self.maze_size_y - 1 and self.maze[y + 1][x] != 1:\n",
    "         self.car_position = (x, y + 1)\n",
    "      elif self.car_orientation == 'E' and x < self.maze_size_x - 1 and self.maze[y][x + 1] != 1:\n",
    "         self.car_position = (x + 1, y)\n",
    "      elif self.car_orientation == 'W' and x > 0 and self.maze[y][x - 1] != 1:\n",
    "         self.car_position = (x - 1, y)\n",
    "      \n",
    "\n",
    "   def turn_left(self):\n",
    "      orientations = ['N', 'W', 'S', 'E']\n",
    "      idx = orientations.index(self.car_orientation)\n",
    "      self.car_orientation = orientations[(idx + 1) % 4]\n",
    "\n",
    "   def turn_right(self):\n",
    "      orientations = ['N', 'E', 'S', 'W']\n",
    "      idx = orientations.index(self.car_orientation)\n",
    "      self.car_orientation = orientations[(idx + 1) % 4]\n",
    "\n",
    "   def update_sensor_readings(self):\n",
    "      # Simple sensor implementation: counts steps to the nearest wall\n",
    "      self.sensor_readings['front'] = self.distance_to_wall('front')\n",
    "      self.sensor_readings['left'] = self.distance_to_wall('left')\n",
    "      self.sensor_readings['right'] = self.distance_to_wall('right')\n",
    "\n",
    "   def distance_to_wall(self, direction):\n",
    "      x, y = self.car_position\n",
    "      distance = 0\n",
    "      max_distance = self.maze_size_x if direction in ['left', 'right'] else self.maze_size_y\n",
    "      \n",
    "      if direction == 'front':\n",
    "         if self.car_orientation == 'N':\n",
    "               while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                  distance += 1\n",
    "         elif self.car_orientation == 'S':\n",
    "               while y + distance < self.maze_size_y and self.maze[y + distance][x] != 1:\n",
    "                  distance += 1\n",
    "         elif self.car_orientation == 'E':\n",
    "               while x + distance < self.maze_size_x and self.maze[y][x + distance] != 1:     \n",
    "                  distance += 1\n",
    "         elif self.car_orientation == 'W':\n",
    "               while x - distance >= 0 and self.maze[y][x - distance] != 1:\n",
    "                  distance += 1\n",
    "      elif direction == 'left':\n",
    "         if self.car_orientation == 'N':\n",
    "               while x - distance >= 0 and self.maze[y][x - distance] != 1:\n",
    "                  distance += 1\n",
    "         elif self.car_orientation == 'S':\n",
    "               while x + distance < self.maze_size_x and self.maze[y][x + distance] != 1:\n",
    "                  distance += 1\n",
    "         elif self.car_orientation == 'E':\n",
    "               while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                  distance += 1\n",
    "         elif self.car_orientation == 'W':\n",
    "               while y + distance < self.maze_size_y and self.maze[y + distance][x] != 1:\n",
    "                  distance += 1\n",
    "      elif direction == 'right':\n",
    "         if self.car_orientation == 'N':\n",
    "               while x + distance < self.maze_size_x and self.maze[y][x + distance] != 1:\n",
    "                  distance += 1\n",
    "         elif self.car_orientation == 'S':\n",
    "               while x - distance >= 0 and self.maze[y][x - distance] != 1:\n",
    "                  distance += 1\n",
    "         elif self.car_orientation == 'E':\n",
    "               while y + distance < self.maze_size_y and self.maze[y + distance][x] != 1:\n",
    "                  distance += 1\n",
    "         elif self.car_orientation == 'W':\n",
    "               while y - distance >= 0 and self.maze[y - distance][x] != 1:\n",
    "                  distance += 1\n",
    "      \n",
    "         # Normalize the measured distance\n",
    "      normalized_distance = (max_distance - distance - 1) / (max_distance - 1)\n",
    "\n",
    "      # Ensure the value is within the range [0, 1]\n",
    "      normalized_distance = max(0, min(normalized_distance, 1))\n",
    "\n",
    "      return normalized_distance\n",
    "   \n",
    "   def compute_reward(self):\n",
    "      # Initialize reward\n",
    "      reward = 0\n",
    "\n",
    "      # Check for collision or out of bounds\n",
    "      if any(self.sensor_readings[direction] == 0 for direction in ['front', 'left', 'right']):\n",
    "         reward -= 20\n",
    "\n",
    "      # Check if goal is reached\n",
    "      if self.car_position == self.goal:\n",
    "         reward += 500\n",
    "         # Additional penalty if it takes too many steps to reach the goal\n",
    "         if self.steps > 1000:\n",
    "               reward -= 200\n",
    "         return reward  # Return immediately as this is the terminal state\n",
    "\n",
    "      # Calculate the Euclidean distance to the goal\n",
    "      distance_to_goal = ((self.car_position[0] - self.goal[0]) ** 2 + (self.car_position[1] - self.goal[1]) ** 2) ** 0.5\n",
    "\n",
    "      # Define a maximum reward when the car is at the goal\n",
    "      max_reward_at_goal = 50\n",
    "\n",
    "      # Reward based on proximity to the goal\n",
    "      reward += max_reward_at_goal / (distance_to_goal + 1)  # Adding 1 to avoid division by zero\n",
    "\n",
    "      # # Reward or penalize based on movement towards or away from the goal\n",
    "      if distance_to_goal < self.previous_distance:\n",
    "         reward += 50  # Positive reward for moving closer to the goal\n",
    "      elif distance_to_goal > self.previous_distance:\n",
    "         reward -= 25  # Negative reward for moving farther from the goal\n",
    "\n",
    "      if self.car_position in self.visited_positions:\n",
    "         # Apply a penalty for revisiting the same position\n",
    "         reward -= 10\n",
    "         \n",
    "      # Penalize for each step taken to encourage efficiency\n",
    "      reward -= 2\n",
    "      \n",
    "      # Update the previous_distance for the next step\n",
    "      self.previous_distance = distance_to_goal\n",
    "      return reward\n",
    "\n",
    "   def is_done(self):\n",
    "      #is done if it reaches the goal or goes out of bounds or takes more than 3000 steps\n",
    "      return self.car_position == self.goal or self.steps > 3000 or self.car_position[0] < 0 or self.car_position[1] < 0 or self.car_position[0] > 11 or self.car_position[1] > 11\n",
    "      \n",
    "   def get_state(self):\n",
    "      car_position = [float(coord) for coord in self.car_position]\n",
    "      sensor_readings = [float(value) for value in self.sensor_readings.values()]\n",
    "      \n",
    "      state = car_position + [self.car_orientation] + sensor_readings\n",
    "      \n",
    "      # cast state to this ['1.0' '1.0' 'N' '1.0' '1.0' '10.0']\n",
    "      state = np.array(state, dtype=str)\n",
    "      \n",
    "      #get the orientation and convert do label encoding\n",
    "      if state[2] == 'N':\n",
    "         state[2] = 0\n",
    "      elif state[2] == 'E':\n",
    "         state[2] = 1\n",
    "      elif state[2] == 'S':\n",
    "         state[2] = 2\n",
    "      elif state[2] == 'W':\n",
    "         state[2] = 3\n",
    "         \n",
    "      state = np.array(state, dtype=float)\n",
    "      \n",
    "      return state\n",
    "\n",
    "   def init_opengl(self):\n",
    "      # Initialize OpenGL context\n",
    "      glutInit()\n",
    "      glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE | GLUT_DEPTH)\n",
    "      glutInitWindowSize(1200, 1200)\n",
    "      glutCreateWindow(\"RC Maze Environment\")\n",
    "\n",
    "      # Set up OpenGL environment\n",
    "      glEnable(GL_DEPTH_TEST)\n",
    "      glClearColor(0.0, 0.0, 0.0, 0.0)  # Clear to a grey color\n",
    "\n",
    "      # Set up lighting (optional)\n",
    "      glEnable(GL_LIGHTING)\n",
    "      glEnable(GL_LIGHT0)\n",
    "      glLightfv(GL_LIGHT0, GL_POSITION, [0, 10, 10, 1])\n",
    "      glLightfv(GL_LIGHT0, GL_AMBIENT, [0.1, 0.1, 0.1, 1])\n",
    "      glLightfv(GL_LIGHT0, GL_DIFFUSE, [1, 1, 1, 1])\n",
    "      \n",
    "      glColorMaterial(GL_FRONT_AND_BACK, GL_AMBIENT_AND_DIFFUSE)\n",
    "      glEnable(GL_COLOR_MATERIAL)\n",
    "\n",
    "      # Set up camera (you may want to make this adjustable)\n",
    "      gluLookAt(self.maze_size_x / 2, self.maze_size_y / 2, 10,  # Camera position (above the center of the maze)\n",
    "          self.maze_size_x / 2, self.maze_size_y / 2, 0,  # Look at point (center of the maze)\n",
    "          0, 1, 0)  # Up vector\n",
    "      \n",
    "      glMatrixMode(GL_PROJECTION)\n",
    "      glLoadIdentity()\n",
    "      gluPerspective(90, 1, 0.1, 100)  # Adjust field of view angle, aspect ratio, near and far planes\n",
    "      glMatrixMode(GL_MODELVIEW)\n",
    "      glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "        # Set the rendering function\n",
    "      glutDisplayFunc(self.render)\n",
    "      \n",
    "   def run_opengl(self):\n",
    "        # Set up the rendering context and callbacks\n",
    "        # but do NOT call glutMainLoop()\n",
    "        glutDisplayFunc(self.render)\n",
    "        glutIdleFunc(self.render)  # Update rendering in idle time\n",
    "\n",
    "   def render(self):\n",
    "      # Clear buffers\n",
    "      glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "      camera_distance = 0.5 # Distance from the camera to the car\n",
    "      camera_height = 1.5  # Height of the camera above the car\n",
    "      \n",
    "      # Assuming self.car_orientation is 'N' and you want to be behind the car (to the 'S')\n",
    "      if self.car_orientation == 'N':  # Car is facing North\n",
    "         camera_x = self.car_position[0]\n",
    "         camera_y = (self.maze_size_y - self.car_position[1] - 1) - camera_distance  # Move camera to South\n",
    "         camera_z = camera_height\n",
    "      elif self.car_orientation == 'S':  # Car is facing South\n",
    "         camera_x = self.car_position[0]\n",
    "         camera_y = (self.maze_size_y - self.car_position[1] - 1) + camera_distance  # Move camera to North\n",
    "         camera_z = camera_height\n",
    "      elif self.car_orientation == 'E':  # Car is facing East\n",
    "         camera_x = self.car_position[0] - camera_distance  # Move camera to West\n",
    "         camera_y = self.maze_size_y - self.car_position[1] - 1\n",
    "         camera_z = camera_height\n",
    "      elif self.car_orientation == 'W':  # Car is facing West\n",
    "         camera_x = self.car_position[0] + camera_distance  # Move camera to East\n",
    "         camera_y = self.maze_size_y - self.car_position[1] - 1\n",
    "         camera_z = camera_height\n",
    "\n",
    "      # The point where the camera should be pointed: the car's position\n",
    "      look_at_x = self.car_position[0]\n",
    "      look_at_y = self.maze_size_y - self.car_position[1] - 1\n",
    "      look_at_z = 1  # Assuming the car is at ground level (z=0)\n",
    "\n",
    "      # Set up the camera\n",
    "      glMatrixMode(GL_MODELVIEW)\n",
    "      glLoadIdentity()\n",
    "      gluLookAt(camera_x, camera_y, camera_z,  # Camera position (x, y, z)\n",
    "               look_at_x, look_at_y, look_at_z,  # Look at position (x, y, z)\n",
    "               0, 0, 2)  # Up vector (x, y, z), assuming Z is up\n",
    "\n",
    "      # Render the maze\n",
    "      for y in range(self.maze_size_y):\n",
    "         for x in range(self.maze_size_x):\n",
    "               if self.maze[y][x] == 1:\n",
    "                  self.draw_cube(x, y, color=(0.5, 0.5, 0.5))\n",
    "               elif (x, y) == self.goal:\n",
    "                  #set color to green\n",
    "                  self.draw_cube(x, y, color=(0.0, 1.0, 0.0))\n",
    "                  \n",
    "      # Render the car's sensor readings\n",
    "      car_x, car_y = self.car_position\n",
    "      #set sensor_color_directon with front being light blue, left being yellow and right being green\n",
    "      sensor_colors = {'front': (0.0, 1.0, 1.0), 'left': (1.0, 1.0, 0.0), 'right': (0.0, 1.0, 0.0)}\n",
    "      \n",
    "      # Render the sensors\n",
    "      for sensor in ['front', 'left', 'right']:\n",
    "         self.draw_sensor_line(car_x, car_y, self.sensor_readings[sensor], \n",
    "                                 sensor_colors[sensor], sensor)\n",
    "         \n",
    "      # Draw the car\n",
    "      car_x, car_y = self.car_position\n",
    "      self.draw_car(car_x, car_y, color=(1.0, 0.0, 0.0))\n",
    "      \n",
    "      # Swap buffers\n",
    "      glutSwapBuffers()\n",
    "      \n",
    "\n",
    "   def draw_cube(self, x, y, color):\n",
    "      # Set the color\n",
    "      glColor3fv(color)\n",
    "\n",
    "      # Draw a cube at position (x, y), flipping y coordinate\n",
    "      glPushMatrix()\n",
    "      glTranslate(x, self.maze_size_y - y - 1, 0)  # Adjust for vertical flipping\n",
    "      glScalef(2, 2, 5)  # Adjust the size of your cube\n",
    "      glutSolidCube(0.5)  # Adjust the size if needed\n",
    "      glPopMatrix()\n",
    "      \n",
    "   def get_sensor_rotation_angle(self, sensor_orientation):\n",
    "      print('direction: ', self.car_orientation)\n",
    "      # Rotation logic based on car's orientation and sensor's relative position\n",
    "      rotation_mapping = {\n",
    "         'N': {'front': 0, 'left': 90, 'right': -90},\n",
    "         'S': {'front': -90, 'left': 0, 'right': 180},\n",
    "         'E': {'front': 0, 'left': 90, 'right': -90},\n",
    "         'W': {'front': 180, 'left': -90, 'right': 90}\n",
    "      }\n",
    "\n",
    "\n",
    "      # Calculate total rotation angle\n",
    "      return rotation_mapping[self.car_orientation][sensor_orientation]\n",
    "\n",
    "   def draw_sensor_line(self, car_x, car_y, distance, color, sensor_orientation):\n",
    "      close_threshold = 0.5\n",
    "      glColor3fv((1.0, 0.0, 0.0) if distance <= close_threshold else color)\n",
    "\n",
    "      # Calculate rotation based on car's and sensor's orientation\n",
    "      rotation_angle = self.get_sensor_rotation_angle(sensor_orientation)\n",
    "\n",
    "      glPushMatrix()\n",
    "      glTranslate(car_x, self.maze_size_y - car_y - 1, 0.5)  # Adjust for vertical flipping\n",
    "      glRotatef(rotation_angle, 0, 0, 1)\n",
    "      glRotatef(90, 0, 1, 0)\n",
    "\n",
    "      # Draw sensor line\n",
    "      distance = min(distance, 0.5)  # Cap distance\n",
    "      glutSolidCylinder(0.05, distance, 5, 5)\n",
    "\n",
    "      glPopMatrix()\n",
    "\n",
    "   def draw_car(self, x, y, color):\n",
    "      # Set the color\n",
    "      glColor3fv(color)\n",
    "\n",
    "      # Draw a cube at position (x, y), flipping y coordinate\n",
    "      glPushMatrix()\n",
    "      glTranslate(x, self.maze_size_y - y - 1, 0)  # Adjust for vertical flipping\n",
    "      glScalef(1, 1, 1)  # Adjust the size of your cube\n",
    "      glutSolidCube(0.5)  # Adjust the size if needed\n",
    "      glPopMatrix()\n",
    "\n",
    "   def close_opengl(self):\n",
    "      # Close the OpenGL context\n",
    "      glutLeaveMainLoop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, replayCapacity, inputShape, outputShape):\n",
    "        ## Initialize replay memory\n",
    "        self.capacity = replayCapacity\n",
    "        self.memory = collections.deque(maxlen=self.capacity)\n",
    "        self.populated = False\n",
    "        ## Policiy model\n",
    "        self.inputShape = inputShape\n",
    "        self.outputShape = outputShape\n",
    "        self.policy_model = self.buildNetwork()\n",
    "\n",
    "        ## Target model\n",
    "        self.target_model = self.buildNetwork()\n",
    "        self.target_model.set_weights(self.policy_model.get_weights())\n",
    "\n",
    "    def addToReplayMemory(self, step):\n",
    "        self.step = step\n",
    "        self.memory.append(self.step)\n",
    "\n",
    "    def sampleFromReplayMemory(self, batchSize):\n",
    "        self.batchSize = batchSize\n",
    "        if self.batchSize > len(self.memory):\n",
    "            self.populated = False\n",
    "            return self.populated\n",
    "        else:\n",
    "            return random.sample(self.memory, self.batchSize)\n",
    "\n",
    "\n",
    "    def buildNetwork(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_shape=self.inputShape, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(self.outputShape, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['MeanSquaredError'])\n",
    "        return model\n",
    "\n",
    "    def policy_network_fit(self,batch, batchSize):\n",
    "        self.batchSize = batchSize\n",
    "        self.batch = batch\n",
    "\n",
    "\n",
    "    def policy_network_predict(self, state):\n",
    "        self.state = state\n",
    "        self.qPolicy = self.policy_model.predict(self.state)\n",
    "        return self.qPolicy\n",
    "\n",
    "    def target_network_predict(self, state):\n",
    "        self.state = state\n",
    "        self.qTarget = self.target_model.predict(self.state)\n",
    "        return self.qTarget\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_model.set_weights(self.policy_model.get_weights()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "env = RCMazeEnv()\n",
    "state = env.reset()\n",
    "\n",
    "env.init_opengl()\n",
    "env.run_opengl()\n",
    "\n",
    "REPLAY_MEMORY_CAPACITY = 20000\n",
    "POSSIBLE_ACTIONS = env.possible_actions\n",
    "\n",
    "# create DQN agent\n",
    "test_agent = DQNAgent(replayCapacity=REPLAY_MEMORY_CAPACITY, inputShape=state.shape, outputShape=len(POSSIBLE_ACTIONS))\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "test_agent.policy_model = load_model('./models/DQN_RCmaze_v2.h5')\n",
    "\n",
    "done = False\n",
    "rewards = []\n",
    "\n",
    "desired_fps = 5.0\n",
    "frame_duration = 1.0 / desired_fps\n",
    "\n",
    "last_time = time.time()\n",
    "done = False\n",
    "\n",
    "\n",
    "while not done:\n",
    "   current_time = time.time()\n",
    "   elapsed = current_time - last_time\n",
    "   if elapsed >= frame_duration:\n",
    "      \n",
    "      glutMainLoopEvent()\n",
    "      qValues = test_agent.policy_network_predict(np.array([state]))\n",
    "      action = np.argmax(qValues[0])\n",
    "      state, reward, done = env.step(action)\n",
    "      rewards.append(reward)\n",
    "      env.render()\n",
    "      \n",
    "      last_time = current_time\n",
    "      \n",
    "      if done:\n",
    "         print('done in ', len(rewards), 'steps')\n",
    "         break\n",
    "# env.close()\n",
    "print(sum(rewards))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
